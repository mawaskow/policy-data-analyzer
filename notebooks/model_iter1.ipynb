{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string, re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2019CVE 1713470_Chile', 'Decreto 51_Chile', 'Decreto 95_Chile', 'Decreto8_Chile', 'Decreto203_Chile', 'Ley 20412_Chile', 'LEY-SOBRE-CHILE', 'NormativaForestal_Chile', 'Programas de recuperacion_Chile', 'Resolution306_Chile', 'SUSTENTABILIDAD AGROAMBIENTAL_Chile', 'Constitution_ElSalvador', 'Decreto233_ElSalvador', 'Decreto272_Cafe', 'Decreto864_ApoyoCafe', 'educacion_ambiental_el_salvador', 'Ley de areas naturales protegidas_ElSalvador', 'Ley del medio ambiente_ElSalvador', 'Ley Especial Cafe_ElSalvador', 'Ley Forestal_ElSalvador', 'Ley Turismo_ElSalvador', 'LEY_GANADERO_ElSalvador', 'LeyAGROINDUSTRIA_ElSalvador', 'LeyElectricidad_ElSalvador', 'lncentivosSistemaAgroforestalCafe_Salvador', 'PREP_ElSalvador', 'Decreto_51_PINPEP_Guatemala', 'Decreto_109_Guatemala', 'Decreto2-2015_PROBOSQUE_Guatemala', 'Decreto101-96_Ley Forestal_Guatemal', 'gua60538', 'Resolucion_1.01-2007_Guatemala', 'Resolucion_1.2-98_Guatemala', 'Resolucion_1.30_Montos_Guatemala', 'Resolucion_2.43_Guatemala', 'Resolucion_4.28_PINPEP_Guatemala', 'CONAFOROperations_Mexico', 'CreditoGanadero_Mexico', 'LEY GENERAL DESARROLLO FORESTAL_Mexico', 'Ley_para_Restauracion_Michoacan_Mexico', 'LeyCiencia_Mexico', 'mex50556', 'Mexico_CONAFOR_ plan 2025', 'Michoacan_Mexico', 'ProgramaGanadero_Mexico', 'Sembrando Vida Brochure_Mexico', 'Sembrando Vida Operations_Mexico', 'Sembrando Vida Report', 'Sembrando Vida_Mexico', 'Decreto_MINAM_Peru', 'DECRETO008-2005Marco-del-Sistema-Nacional-de-Gestión-Ambiental', 'Decreto102-2001_Peru', 'LEGISLATIVOS-AMERICA-LATINA', 'Ley 29325  FISCALIZACIÓN AMBIENTAL', 'LEY_28054_Peru', 'Ley_Fauna_Silvestre_Peru', 'Ley2550_Peru', 'Ley30573 - Reestructuración Agraria Especial_Peru', 'Ley-General-Ambiente_Peru', 'Promocion del comercio algodonero', 'Regional_Junin_Peru', 'Regional_Puno_Peru', 'Resolucion047-2015-OEFA_Peru', 'Resolucion30516_Peru'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"..\")\n",
    "INTER_PATH = os.path.join(\"data\", \"interim\")\n",
    "with open(os.path.join(INTER_PATH, \"pdf_files.json\")) as json_file:\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "#data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spa_stopwords = set(stopwords.words('spanish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_freq_words(doc_list, stopwords_set, num_freq_words):\n",
    "    filtered_words = list()\n",
    "    for doc in doc_list:\n",
    "        tokens = [word.lower() for word in word_tokenize(doc)]\n",
    "        filtered_words.extend([word for word in tokens if word.isalpha() and word not in stopwords_set and len(word) > 1])\n",
    "    \n",
    "    return FreqDist(filtered_words).most_common(num_freq_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def docs_from_json(data):\n",
    "    doc_list = list()\n",
    "    for doc_json in data.values():\n",
    "        doc_list.append(doc_json[\"Text\"])\n",
    "    \n",
    "    return doc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = docs_from_json(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spa_stopwords.add('ley')\n",
    "spa_stopwords.add('artículo')\n",
    "freq_words_map = most_freq_words(all_docs, spa_stopwords, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('forestal', 3966),\n",
       " ('manejo', 3124),\n",
       " ('nacional', 3028),\n",
       " ('ambiental', 2808),\n",
       " ('forestales', 2738),\n",
       " ('recursos', 2668),\n",
       " ('desarrollo', 2060),\n",
       " ('actividades', 1887),\n",
       " ('naturales', 1886),\n",
       " ('fauna', 1870),\n",
       " ('áreas', 1621),\n",
       " ('silvestre', 1594),\n",
       " ('caso', 1578),\n",
       " ('ser', 1524),\n",
       " ('ambiente', 1491),\n",
       " ('uso', 1434),\n",
       " ('plan', 1389),\n",
       " ('presente', 1370),\n",
       " ('gestión', 1361),\n",
       " ('conservación', 1303),\n",
       " ('ambientales', 1303),\n",
       " ('servicios', 1302),\n",
       " ('así', 1298),\n",
       " ('especies', 1294),\n",
       " ('deberá', 1269),\n",
       " ('reglamento', 1228),\n",
       " ('aprovechamiento', 1201),\n",
       " ('acuerdo', 1166),\n",
       " ('programa', 1165),\n",
       " ('cambio', 1145),\n",
       " ('ministerio', 1134),\n",
       " ('información', 1102),\n",
       " ('general', 1081),\n",
       " ('sistema', 1067),\n",
       " ('protección', 1048),\n",
       " ('siguientes', 995),\n",
       " ('dentro', 972),\n",
       " ('cada', 966),\n",
       " ('productos', 961),\n",
       " ('plazo', 954),\n",
       " ('medio', 948),\n",
       " ('según', 934),\n",
       " ('decreto', 926),\n",
       " ('apoyo', 923),\n",
       " ('acciones', 917),\n",
       " ('regional', 916),\n",
       " ('autoridad', 908),\n",
       " ('planes', 902),\n",
       " ('evaluación', 883),\n",
       " ('serfor', 882)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_words_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_txt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-06967e1ee4c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_txt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfiltered_sents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misalpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspa_stopwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msents\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample_txt' is not defined"
     ]
    }
   ],
   "source": [
    "sents = [sent.lower() for sent in sent_tokenize(sample_txt)]\n",
    "filtered_sents = [\" \".join([word for word in sent.split() if word.isalpha() and word not in spa_stopwords]) for sent in sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'': 45, 'modificado letra': 17, 'reemplazado': 16, 'ministerio publicado': 15, 'promulgado publicado': 10, 'modificado': 10, 'sustituido letra': 10, 'reemplazado letra': 7, 'agregado letra': 5, 'agregado': 5, ...})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FreqDist(filtered_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Cleaning\n",
    "\n",
    "- 'CreditoGanadero_Mexico': not readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_spanish = set(stopwords.words('spanish')).union(set(['ley', 'artículo']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "puntuation = [p for p in set(string.punctuation) if p not in (\".\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_stopwords(df):\n",
    "    df = df.lower().replace(\"\\n\", \" \").replace(\"\\t\", \" \").strip(\" \")\n",
    "    df = \"\".join( c for c in df.split(\" \") if c not in puntuation)\n",
    "    df = \" \".join([w for w in df.split() if w not in stopwords_spanish])\n",
    "    #df = \" \".join([w for w in df.split() if w not in additional_stopwords])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Json to DF\n",
    "clean_docs = pd.DataFrame([])\n",
    "for doc_name, doc_json in data.items():\n",
    "    doc = pd.json_normalize(doc_json)\n",
    "    doc.insert(0, \"Document\", doc_name) \n",
    "    #print(doc)\n",
    "    clean_docs = clean_docs.append(doc, ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set label\n",
    "clean_docs.insert(11,'Label','Relevant')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = clean_docs.Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = [w.split() for w in corpus]\n",
    "\n",
    "all_flat_words = [ewords for words in all_words for ewords in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing all the stop words from the corpus\n",
    "all_flat_words_ns = [w for w in all_flat_words if w not in stopwords_spanish]\n",
    "\n",
    "#removing all duplicates\n",
    "set_nf = set(all_flat_words_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique vocabulary words in the text_description column of the dataframe: 79262\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of unique vocabulary words in the text_description column of the dataframe: %d\"%len(set_nf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing\n",
    "\n",
    "The following steps are performed:\n",
    "   - Converting all of the data into lower case.\n",
    "   - FInd the root of the words to further reduce the feature size\n",
    "\n",
    "to do: When the document have 'Keywords', the keywords are added to the description.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = SnowballStemmer('spanish')\n",
    "#porter=nltk.PorterStemmer()\n",
    "\n",
    "for each_row in clean_docs.itertuples():\n",
    "    #m1=map(lambda x: x , (str(each_row[4])+' '+str(each_row[10])).lower().split())\n",
    "    m1 = map(lambda x: x , (each_row[11]).lower().split())\n",
    "    #print(each_row[11])\n",
    "    #Using Porter Stemmer in NLTK, find root\n",
    "    m2 = map(lambda x: porter.stem(x), m1)\n",
    "    #pre-processed string is stored in new column\n",
    "    clean_docs.loc[each_row[0],'Desc'] = ' '.join(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New corpus\n",
    "corpus = clean_docs['Desc']\n",
    "#Initializing TFIDF vectorizer to conver the raw corpus to a matrix of TFIDF features \n",
    "# and also enabling the removal of stopwords\n",
    "vectorizer = TfidfVectorizer(stop_words=stopwords_spanish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating TFIDF features sparse matrix by fitting it on the specified corpus \n",
    "tfidf_matrix = vectorizer.fit_transform(corpus).todense()\n",
    "\n",
    "#Grabbing the name of the features.\n",
    "tfidf_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of TFIDF Features:  34617\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of TF-IDF Features: \", tfidf_matrix.shape[1])\n",
    "\n",
    "# There are  34,617 columns that will be used for training the classifier\n",
    "# These are much smaller than the total number of unique vocabulary words\n",
    "# (79,262) that previously calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_time_container={'b_naive_bayes':0,'mn_naive_bayes':0,'random_forest':0,'linear_svm':0}\n",
    "prediction_time_container={'b_naive_bayes':0,'mn_naive_bayes':0,'random_forest':0,'linear_svm':0}\n",
    "\n",
    "accuracy_container={'b_naive_bayes':0,'mn_naive_bayes':0,'random_forest':0,'linear_svm':0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers\n",
    "\n",
    "First, split our existing dataset into training and test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import sklearn.metrics\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and test data (70-30 ratio)\n",
    "\n",
    "#considering the TFIDF features as the input\n",
    "variables = tfidf_matrix\n",
    "#labels for the classifier\n",
    "labels = clean_docs.Label\n",
    "#splitting the data\n",
    "var_train, var_test, labels_train, labels_test = train_test_split(variables, labels, test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training Data: (44, 34617)\n",
      "Shape of Test Data: (20, 34617)\n"
     ]
    }
   ],
   "source": [
    "#analyzing the shape of the training and test data-set:\n",
    "print('Shape of Training Data: '+str(variables_train.shape))\n",
    "print('Shape of Test Data: '+str(variables_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes\n",
    "\n",
    "Naive Bayes is one of the most widely used classification algorithm in text mining applications. The main assumption is that all the features are independent of each other. The condition of independence may not be valid in many circumstances but as a base line model, its a good starting point.\n",
    "\n",
    "Naive Bayes uses the probabilities of each attribute belonging to each class to make a prediction. There are two forms of Naive Bayes:\n",
    "\n",
    "   1. Bernoulli, designed for boolean/binary features i.e. just considers the presence or absense of a feature.\n",
    "   2. Multinomial, which also considers the occurrence counts of the feature.\n",
    "\n",
    "We will apply both and then will assess their respective accuracy scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define classifier\n",
    "bnb_classifier = BernoulliNB()\n",
    "\n",
    "t0 = time()\n",
    "bnb_classifier = bnb_classifier.fit(var_train, labels_train)\n",
    "#Training the classifier on the training data\n",
    "training_time_container['b_naive_bayes'] = time()-t0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions\n",
    "bnb_predictions = bnb_classifier.predict(var_test)\n",
    "prediction_time_container['b_naive_bayes']=time()-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes Accuracy Score: 1.000000\n",
      "Training Time: 0.092194\n",
      "Prediction Time: 185.372773\n",
      "Confusion Matrix of Bernoulli Naive Bayes Classifier output: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0  100.0"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Metrics\n",
    "nb_ascore = sklearn.metrics.accuracy_score(labels_test, bnb_predictions)\n",
    "accuracy_container['b_naive_bayes'] = nb_ascore\n",
    "con_mat = pd.DataFrame(sklearn.metrics.confusion_matrix(labels_test, bnb_predictions))\n",
    "\n",
    "print(\"Bernoulli Naive Bayes Accuracy Score: %f\"%accuracy_container['b_naive_bayes'])\n",
    "print(\"Training Time: %f\"%training_time_container['b_naive_bayes'])\n",
    "print(\"Prediction Time: %f\"%prediction_time_container['b_naive_bayes'])\n",
    "print(\"Confusion Matrix of Bernoulli Naive Bayes Classifier output: \")\n",
    "con_mat.div(con_mat.sum(0), axis=1).round(2)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Relevant       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Metrics: \")\n",
    "print(sklearn.metrics.classification_report(labels_test,bnb_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes\n",
    "\n",
    "Bernoulli Naive Bayes only considers whether a feature is present or not. However, if we also take into account the occurrence weight or count of the feature as well (in our case, the TF-IDF weight of each feature), we can hypothesize that the performance of such classifier will be equally good, if not better. That is assumption for the Multi-nomial Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_bayes = MultinomialNB()\n",
    "t0 = time()\n",
    "mn_bayes_fit = mn_bayes.fit(var_train,labels_train)\n",
    "training_time_container['mn_naive_bayes'] = time()-t0\n",
    "t0 = time()\n",
    "\n",
    "prediction_mn = mn_bayes_fit.predict(variables_test)\n",
    "prediction_time_container['mn_naive_bayes'] = time()-t0\n",
    "mn_ascore = sklearn.metrics.accuracy_score(labels_test, prediction_mn) \n",
    "accuracy_container['mn_naive_bayes'] = mn_ascore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Multi-Nomial Naive Bayes: 1.000000\n",
      "Training Time: 0.027730s\n",
      "Prediction Time: 0.003846s\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score of Multi-Nomial Naive Bayes: %f\" %(mn_ascore))\n",
    "print(\"Training Time: %fs\"%training_time_container['mn_naive_bayes'])\n",
    "print(\"Prediction Time: %fs\"%prediction_time_container['mn_naive_bayes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier\n",
    "\n",
    "In Random Forest, a subset of the training data is fit on a number of decision trees. Random Forests have the characteristic to minimize variance if its there in the data-set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 0.306189s\n",
      "Prediction Time: 0.025298s\n",
      "Accuracy Score of Random Forests Classifier: \n",
      "1.0\n",
      "[[20]]\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(n_estimators=50)\n",
    "t0 = time()\n",
    "rf_classifier = rf_classifier.fit(var_train, labels_train)\n",
    "\n",
    "training_time_container['random_forest'] = time()-t0\n",
    "print(\"Training Time: %fs\"%training_time_container['random_forest'])\n",
    "\n",
    "t0 = time()\n",
    "rf_predictions = rf_classifier.predict(var_test)\n",
    "prediction_time_container['random_forest'] = time()-t0\n",
    "print(\"Prediction Time: %fs\"%prediction_time_container['random_forest'])\n",
    "\n",
    "accuracy_container['random_forest'] = sklearn.metrics.accuracy_score(labels_test, rf_predictions)\n",
    "print (\"Accuracy Score of Random Forests Classifier: \")\n",
    "print(accuracy_container['random_forest'])\n",
    "print(sklearn.metrics.confusion_matrix(labels_test, rf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 150 candidates, totalling 750 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   21.6s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:   43.3s\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed:  1.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor de la mejor métrica para el modelo de Random Forest: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 750 out of 750 | elapsed:  1.8min finished\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier()\n",
    "\n",
    "# Hyperparameters\n",
    "hyper_param_grid = {'n_estimators': [10, 50, 100], \n",
    "                     'max_depth': [5,10,20,50,100], \n",
    "                     'max_features': ['sqrt','log2'],\n",
    "                     'min_samples_split': [2,5,10,20,50]}\n",
    "\n",
    "# Gid search\n",
    "grid_search = GridSearchCV(classifier, \n",
    "                           hyper_param_grid, \n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 5, \n",
    "                           n_jobs = -1,\n",
    "                           verbose = 3)\n",
    "grid_search.fit(var_train, labels_train)\n",
    "\n",
    "# Best params\n",
    "grid_search.best_params_\n",
    "\n",
    "# Best score\n",
    "print('Valor de la mejor métrica para el modelo de Random Forest:', grid_search.best_score_ * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wri",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
