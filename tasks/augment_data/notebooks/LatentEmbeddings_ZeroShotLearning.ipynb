{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-Shot Learning Experiments: Latent Embeddings\n",
    "\n",
    "Using https://joeddav.github.io/blog/2020/05/29/ZSL.html#A-latent-embedding-approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load 5 countries' sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\"../../../\")\n",
    "from tasks.data_loader.src.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_labeled_sentences(excel_map):\n",
    "    result = {}\n",
    "    sent_num = 0\n",
    "    \n",
    "    for country, dataframe in excel_map.items():\n",
    "\n",
    "        new_sents_col = dataframe[\"Sentence\"].dropna()\n",
    "        new_labels_col= dataframe[\"Primary Instrument\"].dropna()\n",
    "        \n",
    "        sentences = list(new_sents_col.apply(lambda x: x.replace(\"\\n\", \"\").strip()))\n",
    "        label_col = new_labels_col.apply(lambda x: x.replace(\"(PES)\", \"\").replace(\"(Bond)\", \"\").strip())\n",
    "        labels = [[string.strip() for string in label.split(\", \")][0] for label in label_col]\n",
    "        result[country] = {}\n",
    "\n",
    "        for sent, label in zip(sentences, labels):\n",
    "            if sent_num not in result[country]:\n",
    "                result[country][sent_num] = {\"text\": sent, \"labels\": [label]}\n",
    "            else:\n",
    "                result[country][sent_num][\"text\"] = sent\n",
    "                result[country][sent_num][\"labels\"] = [label]\n",
    "            \n",
    "            sent_num += 1\n",
    "            \n",
    "    return result\n",
    "\n",
    "def sentences_from_model_output(model_preds):\n",
    "    return [preds[\"text\"] for preds in model_preds.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_excel = pd.read_excel(\"../input/WRI_Policy_Tags.xlsx\", engine=\"openpyxl\", sheet_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labeled_sentences = country_labeled_sentences(data_excel)\n",
    "label_names = ['Credit',\n",
    " 'Direct payment',\n",
    " 'Fine',\n",
    " 'General incentive',\n",
    " 'Guarantee',\n",
    " 'Supplies',\n",
    " 'Tax deduction',\n",
    " 'Technical assistance',\n",
    " 'Unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mexico_sents = sentences_from_model_output(all_labeled_sentences['Mexico'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mexico_labels = labels_from_model_output(all_labeled_sentences['Mexico'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_sents = dict()\n",
    "\n",
    "for sents in all_labeled_sentences.values():\n",
    "    labeled_sents.update(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sents = sentences_from_model_output(labeled_sents)\n",
    "all_labels = labels_from_model_output(labeled_sents)\n",
    "label_names = list(set(all_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sents[:2], all_labels[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write out latent embedding algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1. Take the top K most frequent words V in the vocabulary of a word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_nlp = spacy.load('es_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_as_str = \". \".join(mexico_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = es_nlp(sents_as_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all tokens that arent stop words or punctuations\n",
    "words = [token.text.lower() for token in doc if not token.is_stop and not token.is_punct and len(token.text) > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 most common tokens\n",
    "word_freq = Counter(words)\n",
    "common_words = word_freq.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_words = list(list(zip(*common_words))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2. Obtain embeddings for each word using word2vec, $\\Phi_{word}(V)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_embeddings = []\n",
    "\n",
    "for word in top_20_words:\n",
    "    doc = es_nlp(word)\n",
    "    vector = doc.vector\n",
    "    word2vec_embeddings.append(vector.reshape(1, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_embeddings[5].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3. Obtain embeddings for each word using S-BERT, $\\Phi_{sent}(V)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('xlm-r-100langs-bert-base-nli-stsb-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_embeddings = []\n",
    "\n",
    "for word in top_20_words:\n",
    "    vector = model.encode([word], convert_to_numpy=True)\n",
    "    sbert_embeddings.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_embeddings[5].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4. Learn a least-squares linear projection matrix Z with L2 regularization from $\\Phi_{sent}(V)$ to $\\Phi_{word}(V)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_sbert = np.vstack(sbert_embeddings)\n",
    "stacked_word2vec = np.vstack(word2vec_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_sbert.shape, stacked_word2vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Help from: https://stackoverflow.com/questions/27476933/numpy-linear-regression-with-regularization and https://www.kdnuggets.com/2016/11/linear-regression-least-squares-matrix-multiplication-concise-technical-overview.html\n",
    "# Multiple Linear Regression with OLS parameter estimation with L2 regularization term\n",
    "lamda = 0.01  # lambda = 0 is equivalent to OLS estimation without regularization\n",
    "Z = np.linalg.inv(stacked_sbert.T.dot(stacked_sbert) + lamda*np.eye(stacked_sbert.shape[1])).dot(stacked_sbert.T).dot(stacked_word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z, Z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5. Use $Z$ in our classification as an additional transformation to S-BERT embeddings\n",
    "\n",
    "$$ \\hat{c} = arg\\,min\\,cos(\\Phi_{sent}(x)Z, \\Phi_{sent}(c)Z)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Quien sera el presidente en 2020?'\n",
    "labels = ['negocios', 'cultura', 'politica']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_rep = torch.from_numpy(np.matmul(model.encode(sentence), Z)).reshape(1,300)\n",
    "label_reps = torch.from_numpy(np.matmul(model.encode(labels), Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_rep.shape, label_reps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = F.cosine_similarity(sentence_rep, label_reps)\n",
    "closest = similarities.argsort(descending=True)\n",
    "for ind in closest:\n",
    "    print(f'label: {labels[ind]} \\t similarity: {similarities[ind]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(closest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6. Build functions for the process!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_words(k, document, spacy_model, include_labels=None):\n",
    "    doc = spacy_model(document)\n",
    "    \n",
    "    # all tokens that arent stop words or punctuations and are longer than 3 letters\n",
    "    words = [token.text.lower() for token in doc if not token.is_stop and not token.is_punct and len(token.text) > 3]\n",
    "    \n",
    "    # k most common tokens\n",
    "    word_freq = Counter(words)\n",
    "    common_words = word_freq.most_common(k)\n",
    "    \n",
    "    result = list(list(zip(*common_words))[0])\n",
    "    \n",
    "    if include_labels:\n",
    "        result.extend(include_labels)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def top_k_word_embeddings(top_k_words, spacy_model):\n",
    "    word_embeddings = []\n",
    "\n",
    "    for word in top_k_words:\n",
    "        doc = spacy_model(word)\n",
    "        vector = doc.vector\n",
    "        word_embeddings.append(vector.reshape(1, vector.shape[0]))\n",
    "        \n",
    "    return word_embeddings\n",
    "\n",
    "\n",
    "def top_k_sbert_embeddings(top_k_words, sbert_model):\n",
    "    sbert_embeddings = []\n",
    "\n",
    "    for word in top_k_words:\n",
    "        vector = sbert_model.encode([word], convert_to_numpy=True)\n",
    "        sbert_embeddings.append(vector)\n",
    "    \n",
    "    return sbert_embeddings\n",
    "\n",
    "\n",
    "def least_squares_with_reg(X, y, lamda=0.01):\n",
    "    # Help from: https://stackoverflow.com/questions/27476933/numpy-linear-regression-with-regularization and https://www.kdnuggets.com/2016/11/linear-regression-least-squares-matrix-multiplication-concise-technical-overview.html\n",
    "    # Multiple Linear Regression with OLS parameter estimation with L2 regularization term. lambda = 0 is equivalent to OLS estimation without regularization\n",
    "    return np.linalg.inv(X.T.dot(X) + lamda*np.eye(X.shape[1])).dot(X.T).dot(y)\n",
    "\n",
    "\n",
    "def calc_proj_matrix(sentences, k, spacy_model, sbert_model, lamda=0.01, include_labels=None):\n",
    "    sents_as_str = \". \".join(sentences)\n",
    "    top_words = top_k_words(k, sents_as_str, spacy_model, include_labels)\n",
    "    word_emb = np.vstack(top_k_word_embeddings(top_words, spacy_model))\n",
    "    sent_emb = np.vstack(top_k_sbert_embeddings(top_words, sbert_model))\n",
    "    proj_matrix = least_squares_with_reg(sent_emb, word_emb, lamda)\n",
    "    \n",
    "    return proj_matrix\n",
    "\n",
    "def encode_sentence(sentence, model, Z):\n",
    "    sentence_rep = torch.from_numpy(np.matmul(model.encode(sentence), Z))\n",
    "    sentence_rep = sentence_rep.reshape(1, sentence_rep.shape[0])\n",
    "    return sentence_rep\n",
    "\n",
    "def encode_labels(labels, model, Z):\n",
    "    return torch.from_numpy(np.matmul(model.encode(labels), Z))\n",
    "\n",
    "def classify_sentence(sentence, labels, model, Z):\n",
    "    sentence_rep = encode_sentence(sentence, model, Z)\n",
    "    label_reps = encode_labels(labels, model, Z)\n",
    "    \n",
    "    similarities = F.cosine_similarity(sentence_rep, label_reps)\n",
    "    closest = similarities.argsort(descending=True)\n",
    "    \n",
    "    top_index = closest[0]\n",
    "    return labels[top_index], similarities[top_index]\n",
    "\n",
    "def classify_sentence_given_label_reps(sentence, label_names, label_reps, model, Z):\n",
    "    sentence_rep = encode_sentence(sentence, model, Z)\n",
    "    \n",
    "    similarities = F.cosine_similarity(sentence_rep, label_reps)\n",
    "    closest = similarities.argsort(descending=True)\n",
    "    \n",
    "    top_index = closest[0]\n",
    "    return label_names[top_index], similarities[top_index]\n",
    "\n",
    "def classify_all_sentences(all_sents, label_names, sbert_model, proj_matrix):\n",
    "    model_preds, model_scores = [], []\n",
    "    label_reps = encode_labels(label_names, sbert_model, proj_matrix)\n",
    "\n",
    "    for sent in tqdm(all_sents):\n",
    "        pred, score = classify_sentence_given_label_reps(sent, label_names, label_reps, sbert_model, proj_matrix)\n",
    "        model_preds.append(pred)\n",
    "        model_scores.append(score)\n",
    "        \n",
    "    return model_preds, model_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7. Time to play on our data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from tasks.evaluate_model.src.model_evaluator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_model = SentenceTransformer('xlm-r-100langs-bert-base-nli-stsb-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_preds, model_scores = [], []\n",
    "\n",
    "for mexico_sent in tqdm(mexico_sents):\n",
    "    pred, score = classify_sentence(mexico_sent, label_names, sbert_model, Z)\n",
    "    model_preds.append(pred)\n",
    "    model_scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = ModelEvaluator(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_multi_labels = labels_to_numeric(mexico_labels, label_names)\n",
    "num_multi_preds = labels_to_numeric(model_preds, label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_multi_labels[:10], num_multi_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_distribution(num_multi_labels, label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.evaluate(num_multi_labels, num_multi_preds, \n",
    "                   plot_cm=True, normalize=True, \n",
    "                   store=True, exp_name=\"multi_class_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.plot_precision_recall_curve(num_multi_labels, num_multi_preds, bin_class=False, all_classes=True, store=True, exp_name=\"multi_class_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to play around with\n",
    "- Labels\n",
    "    - [x] Mix credit and guarantee together \n",
    "    - [x] Take out general incentive and unknown \n",
    "    - [ ] Replace unknown with something else?\n",
    "- [x] Visualize embeddings \n",
    "- Embeddings\n",
    "    - [x] Include the labels in the Z matrix process\n",
    "    - [ ] Different values of lamda for projection matrix (for regulatization)\n",
    "    - [ ] Learn an additional least-squares projection matrix to the embeddings of any available labels from their corresponding data embeddings (as described in the *When some annotated data is available* section of the base article)\n",
    "    - Top k words \n",
    "        - [ ] Different values of k for top k words\n",
    "        - [ ] Use more words for k words, and use the stems of the word \n",
    "- [ ] Model type for sentence embeddings\n",
    "- [ ] Model type for word embeddings?\n",
    "- [ ] Fine tuning sentence model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup - Get projection matrix and define model\n",
    "sbert_model = SentenceTransformer('xlm-r-100langs-bert-base-nli-stsb-mean-tokens')\n",
    "proj_matrix = calc_proj_matrix(all_sents, 50, es_nlp, sbert_model, 0.1)\n",
    "all_sents = sentences_from_model_output(labeled_sents)\n",
    "all_labels = labels_from_model_output(labeled_sents)\n",
    "label_names = list(set(all_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1. Merge Credit and Guarantee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_labels(all_labels, labels_to_merge):\n",
    "    return [f\"{labels_to_merge[0]} & {labels_to_merge[1]}\" if label in labels_to_merge else label for label in all_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = merge_labels(all_labels, [\"Credit\", \"Guarantee\"]) \n",
    "label_names = list(set(all_labels))\n",
    "num_labels = labels_to_numeric(all_labels, label_names)\n",
    "plot_data_distribution(num_labels, label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_preds, model_scores = classify_all_sentences(all_sents, label_names, sbert_model, proj_matrix)\n",
    "num_preds = labels_to_numeric(model_preds, label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = ModelEvaluator(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.evaluate(num_labels, num_preds, \n",
    "                   plot_cm=True, normalize=True, \n",
    "                   store=True, exp_name=\"latent_emb_exp1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.plot_precision_recall_curve(num_labels, model_preds, bin_class=False, all_classes=True, store=True, exp_name=\"latent_emb_exp1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2. Get rid of Unknown and General incentive, and merge Credit and Guarantee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sents_maps = [sent for sent in labeled_sents.values() if sent['labels'][0] not in [\"General incentive\", \"Unknown\"]]\n",
    "all_sents = [sent['text'] for sent in filtered_sents_maps]\n",
    "all_labels = [sent['labels'][0] for sent in filtered_sents_maps]\n",
    "all_labels = merge_labels(all_labels, [\"Credit\", \"Guarantee\"]) \n",
    "label_names = list(set(all_labels))\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = labels_to_numeric(all_labels, label_names)\n",
    "plot_data_distribution(num_labels, label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_preds, model_scores = classify_all_sentences(all_sents, label_names, sbert_model, proj_matrix)\n",
    "num_preds = labels_to_numeric(model_preds, label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = ModelEvaluator(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.evaluate(num_labels, num_preds, \n",
    "                   plot_cm=True, normalize=True, \n",
    "                   store=True, exp_name=\"latent_emb_exp2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.plot_precision_recall_curve(num_labels, model_preds, bin_class=False, all_classes=True, store=True, exp_name=\"latent_emb_exp2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3. Visualizing data (Setup from experiment 2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import scprep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_model = SentenceTransformer('xlm-r-100langs-bert-base-nli-stsb-mean-tokens')\n",
    "proj_matrix = calc_proj_matrix(all_sents, 50, es_nlp, sbert_model, 0.01)\n",
    "all_sent_embs = np.vstack([encode_sentence(sent, sbert_model, proj_matrix) for sent in tqdm(all_sents)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_labels = labels_to_numeric(all_labels, label_names)\n",
    "df = pd.DataFrame()\n",
    "df[\"y\"] = np.array(numeric_labels)\n",
    "all_sent_embs.shape, len(df[\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_embeddings_2D(embs, numeric_labels, tsne_perplexity, pca_k_n_comps=None, seed=69420):\n",
    "    df = pd.DataFrame()\n",
    "    df[\"y\"] = np.array(numeric_labels)\n",
    "    num_labels = len(set(numeric_labels))\n",
    "    \n",
    "    # Data for plot 1\n",
    "    pca = PCA(n_components=2, random_state=seed)\n",
    "    pca_result = pca.fit_transform(embs)\n",
    "    df['pca-1'] = pca_result[:,0]\n",
    "    df['pca-2'] = pca_result[:,1] \n",
    "    \n",
    "    # Data for plot 2\n",
    "    tsne = TSNE(n_components=2, verbose=1, perplexity=tsne_perplexity, n_iter=1000, random_state=seed)\n",
    "    tsne_results = tsne.fit_transform(embs)\n",
    "    df[\"tsne-1\"] = tsne_results[:,0]\n",
    "    df[\"tsne-2\"] = tsne_results[:,1]\n",
    "    \n",
    "    # Actual plotting\n",
    "    plt.figure(figsize=(24, 4))\n",
    "    ax1 = plt.subplot(1, 3, 1)\n",
    "    sns.scatterplot(\n",
    "        x=\"pca-1\", y=\"pca-2\",\n",
    "        hue=df.y.tolist(),\n",
    "        palette=\"bright\",\n",
    "        data=df,\n",
    "        legend=False,\n",
    "        ax=ax1\n",
    "    ).set(title=\"PCA projection\")\n",
    "    \n",
    "    ax2 = plt.subplot(1, 3, 2)\n",
    "    sns.scatterplot(\n",
    "        x=\"tsne-1\", y=\"tsne-2\",\n",
    "        hue=df.y.tolist(),\n",
    "        palette=\"bright\",\n",
    "        data=df,\n",
    "        legend=False if pca_k_n_comps else \"auto\",\n",
    "        ax=ax2\n",
    "    ).set(title=\"t-SNE projection\")\n",
    "    \n",
    "    if pca_k_n_comps:\n",
    "        # Data for plot 3\n",
    "        pca_k = PCA(n_components=pca_k_n_comps, random_state=seed)\n",
    "        pca_k_result = pca_k.fit_transform(embs)\n",
    "        tsne = TSNE(n_components=tsne_n_comps, verbose=1, perplexity=tsne_perplexity, n_iter=1000, random_state=seed)\n",
    "        tsne_pca_results = tsne.fit_transform(pca_k_result)\n",
    "        df[f\"tsne-pca-{pca_k_n_comps}-1\"] = tsne_pca_results[:,0]\n",
    "        df[f\"tsne-pca-{pca_k_n_comps}-2\"] = tsne_pca_results[:,1]\n",
    "        \n",
    "        # Actual plotting\n",
    "        ax3 = plt.subplot(1, 3, 3)\n",
    "        sns.scatterplot(\n",
    "            x=f\"tsne-pca-{pca_k_n_comps}-1\", y=f\"tsne-pca-{pca_k_n_comps}-2\",\n",
    "            hue=df.y.tolist(),\n",
    "            palette=\"bright\",\n",
    "            data=df,\n",
    "            ax=ax3\n",
    "        ).set(title=\"t-SNE on PCA projection\")\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1.01, 1),borderaxespad=0)\n",
    "\n",
    "def visualize_PCA_embeddings_3D(embs, labels, n_comps, fname=None, seed=69420):\n",
    "    if n_comps < 3:\n",
    "        print(\"The number of PCA components has to be at least 3!\")\n",
    "        return\n",
    "    \n",
    "    n_labels = len(set(labels))\n",
    "    pca = PCA(n_components=n_comps, random_state=seed)\n",
    "    pca_result = pca.fit_transform(embs)\n",
    "    data = np.vstack([pca_result[:,0], pca_result[:,1], pca_result[:,2]]).T\n",
    "    colors = np.array(labels)\n",
    "    \n",
    "    return scprep.plot.rotate_scatter3d(data, c=colors, figsize=(10,8), title=f\"PCA {n_comps} components\", legend_anchor=(1.01, 1), filename=fname)\n",
    "\n",
    "def visualize_tSNE_embeddings_3D(embs, labels, n_comps=3, tsne_perplexity=50, fname=None, seed=69420):\n",
    "    \n",
    "    n_labels = len(set(labels))\n",
    "    tsne = TSNE(n_components=n_comps, verbose=1, perplexity=tsne_perplexity, n_iter=1000, random_state=seed)\n",
    "    tsne_result = tsne.fit_transform(embs)\n",
    "    data = np.vstack([tsne_result[:,0], tsne_result[:,1], tsne_result[:,2]]).T\n",
    "    colors = np.array(labels)\n",
    "    \n",
    "    return scprep.plot.rotate_scatter3d(data, c=colors, figsize=(10,8), title=f\"t-SNE {tsne_perplexity} perplexity\", legend_anchor=(1.01, 1), filename=fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_embeddings_2D(all_sent_embs, all_labels, pca_k_n_comps=50, tsne_perplexity=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_PCA_embeddings_3D(all_sent_embs, all_labels, 50, \"PCA_50_components.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_tSNE_embeddings_3D(all_sent_embs, all_labels, 3, tsne_perplexity=50, fname=\"tSNE_50_perplexity.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import phate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phate_operator = phate.PHATE(knn=4, decay=15, t=12)#(k=2, t=5000, n_pca=50, random_state=69420, knn_dist='cosine')\n",
    "tree_phate = phate_operator.fit_transform(all_sent_embs)\n",
    "phate.plot.scatter2d(phate_operator, c=all_labels, legend_anchor=(1.01, 1))\n",
    "phate.plot.rotate_scatter3d(phate_operator, c=all_labels, legend_anchor=(1.01, 1), filename=\"phate_knn=4_decay=15_t=12.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4. Include the labels in the Z matrix process (Setup from experiment 2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_matrix = calc_proj_matrix(all_sents, 50, es_nlp, sbert_model, 0.1, include_labels=label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_preds, model_scores = classify_all_sentences(all_sents, label_names, sbert_model, proj_matrix)\n",
    "num_preds = labels_to_numeric(model_preds, label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = ModelEvaluator(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.evaluate(num_labels, num_preds, \n",
    "                   plot_cm=True, normalize=True, \n",
    "                   store=True, exp_name=\"latent_emb_exp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.plot_precision_recall_curve(num_labels, model_preds, bin_class=False, all_classes=True, store=True, exp_name=\"latent_emb_exp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 5.  Fine tune sentence embedding model (Setup from experiment 2.)\n",
    "The FineTuning folder that contains the fine-tuned model is located on Google Drive under the folder WRI-LatinAmerica-Talent/Modeling/FineTuning. To execute the following code you should download this folder to tasks/augment_data/output/FineTuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model and obtain random sentence embedding\n",
    "model_save_path = \"../output/FineTuning\"\n",
    "load_model = SentenceTransformer(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple low-dim projection\n",
    "all_sent_embs = np.vstack([load_model.encode(sent) for sent in all_sents])\n",
    "visualize_embeddings(all_sent_embs, all_labels, tsne_perplexity=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projection matrix Z low-dim projection\n",
    "proj_matrix = calc_proj_matrix(all_sents, 50, es_nlp, load_model, 0.01)\n",
    "all_sent_embs = np.vstack([encode_sentence(sent, load_model, proj_matrix) for sent in all_sents])\n",
    "visualize_embeddings(all_sent_embs, all_labels, tsne_perplexity=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = labels_to_numeric(all_labels, label_names)\n",
    "plot_data_distribution(num_labels, label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify all sentences\n",
    "model_preds, model_scores = classify_all_sentences(all_sents, label_names, load_model, proj_matrix)\n",
    "num_preds = labels_to_numeric(model_preds, label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = ModelEvaluator(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.evaluate(num_labels, num_preds, \n",
    "                   plot_cm=True, normalize=True, \n",
    "                   store=True, exp_name=\"latent_emb_exp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.plot_precision_recall_curve(num_labels, model_preds, bin_class=False, all_classes=True, store=True, exp_name=\"latent_emb_exp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
