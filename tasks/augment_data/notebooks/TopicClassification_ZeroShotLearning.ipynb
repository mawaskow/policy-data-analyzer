{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-Shot Learning Experiments: Topic classification\n",
    "\n",
    "Using https://huggingface.co/zero-shot/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\"../../../\")\n",
    "from tasks.data_loader.src.utils import *\n",
    "from tasks.evaluate_model.src.model_evaluator import *\n",
    "from tasks.augment_data.src.zero_shot_classification.nli_topic_classifier import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load labeled sentences from Excel - One label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sents_excel = pd.read_excel(\"../input/WRI_Policy_Tags.xlsx\", engine=\"openpyxl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Text</th>\n",
       "      <th>Incentive Instrument</th>\n",
       "      <th>Land Use Type</th>\n",
       "      <th>Category</th>\n",
       "      <th>Unique Policy #</th>\n",
       "      <th>Key words</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "      <th>Unnamed: 19</th>\n",
       "      <th>Unnamed: 20</th>\n",
       "      <th>Unnamed: 21</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "      <th>Unnamed: 24</th>\n",
       "      <th>Unnamed: 25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019 ACUERDO por el que se emiten los Lineamie...</td>\n",
       "      <td>Generar empleo y garantizara la población camp...</td>\n",
       "      <td>Direct payment</td>\n",
       "      <td>Forest, Agriculture (Crop)</td>\n",
       "      <td>Incentive</td>\n",
       "      <td>1 (Sembrando Vida)</td>\n",
       "      <td>insumo, crédito, capacitación, asistencia técnica</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019 ACUERDO por el que se emiten los Lineamie...</td>\n",
       "      <td>Generar empleo y garantizara la población camp...</td>\n",
       "      <td>Technical assistance</td>\n",
       "      <td>Forest, Agriculture (Crop)</td>\n",
       "      <td>Incentive</td>\n",
       "      <td>1 (Sembrando Vida)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019 ACUERDO por el que se emiten los Lineamie...</td>\n",
       "      <td>Generar empleo y garantizara la población camp...</td>\n",
       "      <td>Credit</td>\n",
       "      <td>Forest, Agriculture (Crop)</td>\n",
       "      <td>Incentive</td>\n",
       "      <td>1 (Sembrando Vida)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019 ACUERDO por el que se emiten los Lineamie...</td>\n",
       "      <td>El Programa incentivará a los sujetos agrarios...</td>\n",
       "      <td>Direct payment</td>\n",
       "      <td>Forest, Agriculture (Crop)</td>\n",
       "      <td>Incentive</td>\n",
       "      <td>1 (Sembrando Vida)</td>\n",
       "      <td>incentivar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019 ACUERDO por el que se emiten los Lineamie...</td>\n",
       "      <td>El Programa incentivará a los sujetos agrarios...</td>\n",
       "      <td>Technical assistance</td>\n",
       "      <td>Forest, Agriculture (Crop)</td>\n",
       "      <td>Incentive</td>\n",
       "      <td>1 (Sembrando Vida)</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Document  \\\n",
       "0  2019 ACUERDO por el que se emiten los Lineamie...   \n",
       "1  2019 ACUERDO por el que se emiten los Lineamie...   \n",
       "2  2019 ACUERDO por el que se emiten los Lineamie...   \n",
       "3  2019 ACUERDO por el que se emiten los Lineamie...   \n",
       "4  2019 ACUERDO por el que se emiten los Lineamie...   \n",
       "\n",
       "                                                Text  Incentive Instrument  \\\n",
       "0  Generar empleo y garantizara la población camp...        Direct payment   \n",
       "1  Generar empleo y garantizara la población camp...  Technical assistance   \n",
       "2  Generar empleo y garantizara la población camp...                Credit   \n",
       "3  El Programa incentivará a los sujetos agrarios...        Direct payment   \n",
       "4  El Programa incentivará a los sujetos agrarios...  Technical assistance   \n",
       "\n",
       "                Land Use Type   Category     Unique Policy #  \\\n",
       "0  Forest, Agriculture (Crop)  Incentive  1 (Sembrando Vida)   \n",
       "1  Forest, Agriculture (Crop)  Incentive  1 (Sembrando Vida)   \n",
       "2  Forest, Agriculture (Crop)  Incentive  1 (Sembrando Vida)   \n",
       "3  Forest, Agriculture (Crop)  Incentive  1 (Sembrando Vida)   \n",
       "4  Forest, Agriculture (Crop)  Incentive  1 (Sembrando Vida)   \n",
       "\n",
       "                                           Key words  Unnamed: 7  Unnamed: 8  \\\n",
       "0  insumo, crédito, capacitación, asistencia técnica         NaN         NaN   \n",
       "1                                                NaN         NaN         NaN   \n",
       "2                                                NaN         NaN         NaN   \n",
       "3                                         incentivar         NaN         NaN   \n",
       "4                                               None         NaN         NaN   \n",
       "\n",
       "   Unnamed: 9  ...  Unnamed: 16  Unnamed: 17  Unnamed: 18  Unnamed: 19  \\\n",
       "0         NaN  ...          NaN          NaN          NaN          NaN   \n",
       "1         NaN  ...          NaN          NaN          NaN          NaN   \n",
       "2         NaN  ...          NaN          NaN          NaN          NaN   \n",
       "3         NaN  ...          NaN          NaN          NaN          NaN   \n",
       "4         NaN  ...          NaN          NaN          NaN          NaN   \n",
       "\n",
       "   Unnamed: 20  Unnamed: 21  Unnamed: 22  Unnamed: 23  Unnamed: 24  \\\n",
       "0          NaN          NaN          NaN          NaN          NaN   \n",
       "1          NaN          NaN          NaN          NaN          NaN   \n",
       "2          NaN          NaN          NaN          NaN          NaN   \n",
       "3          NaN          NaN          NaN          NaN          NaN   \n",
       "4          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "   Unnamed: 25  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sents_excel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try out which hypothesis template gives the \"best\" results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypothesis: This text is about {}.\n",
      "Labels and scores:\n",
      "('fine', 0.35791587829589844)\n",
      "('guarantee', 0.2378205507993698)\n",
      "('direct payment', 0.09230978041887283)\n",
      "('unknown', 0.07248454540967941)\n",
      "('supplies', 0.06786298006772995)\n",
      "('tax deduction', 0.06379210948944092)\n",
      "('credit', 0.06338527053594589)\n",
      "('technical assistance', 0.04442889615893364)\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Hypothesis: This text contains incentives about {}s\n",
      "Labels and scores:\n",
      "('fine', 0.6989411115646362)\n",
      "('guarantee', 0.11369836330413818)\n",
      "('supplies', 0.054176971316337585)\n",
      "('technical assistance', 0.04837031662464142)\n",
      "('direct payment', 0.03908627852797508)\n",
      "('credit', 0.028751058503985405)\n",
      "('unknown', 0.014763382263481617)\n",
      "('tax deduction', 0.002212527673691511)\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Hypothesis: This text contains information about {}s\n",
      "Labels and scores:\n",
      "('fine', 0.4065122604370117)\n",
      "('guarantee', 0.3340264856815338)\n",
      "('supplies', 0.09895601868629456)\n",
      "('direct payment', 0.06099799647927284)\n",
      "('technical assistance', 0.05057215318083763)\n",
      "('credit', 0.02970729023218155)\n",
      "('unknown', 0.01410584058612585)\n",
      "('tax deduction', 0.005121999885886908)\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Hypothesis: This text contains {}\n",
      "Labels and scores:\n",
      "('supplies', 0.364990770816803)\n",
      "('credit', 0.2678076922893524)\n",
      "('fine', 0.11938323080539703)\n",
      "('technical assistance', 0.09764397144317627)\n",
      "('guarantee', 0.06084869056940079)\n",
      "('unknown', 0.04192768409848213)\n",
      "('direct payment', 0.03464805707335472)\n",
      "('tax deduction', 0.012749902904033661)\n",
      "-----------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_sent = 'Generar empleo y garantizara la población campesina el bienestar y su participación e incorporación en el desarrollo nacional, y fomentará la actividad agropecuaria y forestal para el óptimo uso de la tierra, con obras de infraestructura, insumos, créditos, servicios de capacitación y asistencia técnica'\n",
    "test_labels = ['direct payment', 'technical assistance', 'credit']\n",
    "all_labels = [\"direct payment\", \"tax deduction\", \"credit\", \"guarantee\", \"technical assistance\", \"supplies\", \"fine\", \"unknown\"]\n",
    "hyp_template_list = ['This text is about {}.', 'This text contains incentives about {}s', \n",
    "                     \"This text contains information about {}s\", \"This text contains {}\"]\n",
    "\n",
    "results = []\n",
    "for hyp in hyp_template_list:\n",
    "    result = classify_sentence(test_sent, all_labels,\n",
    "                        hyp, classifier, allow_multi_class=False, all_probs=True)\n",
    "    \n",
    "    print(f\"Hypothesis: {hyp}\")\n",
    "    print(f\"Labels and scores:\")\n",
    "    for pretty in result:\n",
    "        print(pretty)\n",
    "    print(\"-----------------------------------------------------------\\n\")\n",
    "    results.append(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load labeled sentences from 5 countries (Excel file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_excel = pd.read_excel(\"../input/allcountries_policytags.xlsx\", engine=\"openpyxl\", sheet_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Original Text</th>\n",
       "      <th>Relevant Sentences (for Environment, Incentives, Land Type)</th>\n",
       "      <th>Relevant Phrases (for Environment, Incentives, Land Type)</th>\n",
       "      <th>Incentive Instrument</th>\n",
       "      <th>Land Use Type</th>\n",
       "      <th>Category</th>\n",
       "      <th>Unique Policy #</th>\n",
       "      <th>Key words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019 ACUERDO por el que se emiten los Lineamie...</td>\n",
       "      <td>Generar empleo y garantizara la población camp...</td>\n",
       "      <td>Generar empleo y garantizara la población camp...</td>\n",
       "      <td>garantizara la población campesina el bienesta...</td>\n",
       "      <td>Direct payment (PES), Credit, Technical assist...</td>\n",
       "      <td>Forest, Agriculture (Crop)</td>\n",
       "      <td>Incentive</td>\n",
       "      <td>1 (Sembrando Vida)</td>\n",
       "      <td>insumo, crédito, capacitación, asistencia técnica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019 ACUERDO por el que se emiten los Lineamie...</td>\n",
       "      <td>\\nEl Programa incentivará a los sujetos agrari...</td>\n",
       "      <td>\\nEl Programa incentivará a los sujetos agrari...</td>\n",
       "      <td>incentivará a los sujetos agrarios a establece...</td>\n",
       "      <td>Direct payment (PES), Credit, Technical assist...</td>\n",
       "      <td>Forest, Agriculture (Crop)</td>\n",
       "      <td>Incentive</td>\n",
       "      <td>1 (Sembrando Vida)</td>\n",
       "      <td>incentivar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019 ACUERDO por el que se emiten los Lineamie...</td>\n",
       "      <td>Los sujetos agrarios beneficiados por el progr...</td>\n",
       "      <td>Los sujetos agrarios beneficiados por el progr...</td>\n",
       "      <td>Los sujetos agrarios beneficiados por el progr...</td>\n",
       "      <td>Supplies, Technical assistance</td>\n",
       "      <td>Forest, Agriculture (Crop)</td>\n",
       "      <td>Incentive</td>\n",
       "      <td>1 (Sembrando Vida)</td>\n",
       "      <td>apoyo económico, apoyos en especie, insumos, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019 ACUERDO por el que se emiten los Lineamie...</td>\n",
       "      <td>El sujeto de derecho, recibirá un apoyo económ...</td>\n",
       "      <td>El sujeto de derecho, recibirá un apoyo económ...</td>\n",
       "      <td>recibirá un apoyo económico de $5,000.00 (Cin...</td>\n",
       "      <td>Direct payment (PES)</td>\n",
       "      <td>Forest, Agriculture (Crop)</td>\n",
       "      <td>Incentive</td>\n",
       "      <td>1 (Sembrando Vida)</td>\n",
       "      <td>pesos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019 ACUERDO por el que se emiten los Lineamie...</td>\n",
       "      <td>El sujeto de derecho, recibirá en especie las ...</td>\n",
       "      <td>El sujeto de derecho, recibirá en especie las ...</td>\n",
       "      <td>recibirá en especie las plantas necesarias par...</td>\n",
       "      <td>Supplies</td>\n",
       "      <td>Forest, Agriculture (Crop)</td>\n",
       "      <td>Incentive</td>\n",
       "      <td>1 (Sembrando Vida)</td>\n",
       "      <td>recibir</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Document  \\\n",
       "0  2019 ACUERDO por el que se emiten los Lineamie...   \n",
       "1  2019 ACUERDO por el que se emiten los Lineamie...   \n",
       "2  2019 ACUERDO por el que se emiten los Lineamie...   \n",
       "3  2019 ACUERDO por el que se emiten los Lineamie...   \n",
       "4  2019 ACUERDO por el que se emiten los Lineamie...   \n",
       "\n",
       "                                       Original Text  \\\n",
       "0  Generar empleo y garantizara la población camp...   \n",
       "1  \\nEl Programa incentivará a los sujetos agrari...   \n",
       "2  Los sujetos agrarios beneficiados por el progr...   \n",
       "3  El sujeto de derecho, recibirá un apoyo económ...   \n",
       "4  El sujeto de derecho, recibirá en especie las ...   \n",
       "\n",
       "  Relevant Sentences (for Environment, Incentives, Land Type)   \\\n",
       "0  Generar empleo y garantizara la población camp...             \n",
       "1  \\nEl Programa incentivará a los sujetos agrari...             \n",
       "2  Los sujetos agrarios beneficiados por el progr...             \n",
       "3  El sujeto de derecho, recibirá un apoyo económ...             \n",
       "4  El sujeto de derecho, recibirá en especie las ...             \n",
       "\n",
       "  Relevant Phrases (for Environment, Incentives, Land Type)   \\\n",
       "0  garantizara la población campesina el bienesta...           \n",
       "1  incentivará a los sujetos agrarios a establece...           \n",
       "2  Los sujetos agrarios beneficiados por el progr...           \n",
       "3   recibirá un apoyo económico de $5,000.00 (Cin...           \n",
       "4  recibirá en especie las plantas necesarias par...           \n",
       "\n",
       "                                Incentive Instrument  \\\n",
       "0  Direct payment (PES), Credit, Technical assist...   \n",
       "1  Direct payment (PES), Credit, Technical assist...   \n",
       "2                     Supplies, Technical assistance   \n",
       "3                              Direct payment (PES)    \n",
       "4                                         Supplies     \n",
       "\n",
       "                Land Use Type   Category     Unique Policy #  \\\n",
       "0  Forest, Agriculture (Crop)  Incentive  1 (Sembrando Vida)   \n",
       "1  Forest, Agriculture (Crop)  Incentive  1 (Sembrando Vida)   \n",
       "2  Forest, Agriculture (Crop)  Incentive  1 (Sembrando Vida)   \n",
       "3  Forest, Agriculture (Crop)  Incentive  1 (Sembrando Vida)   \n",
       "4  Forest, Agriculture (Crop)  Incentive  1 (Sembrando Vida)   \n",
       "\n",
       "                                           Key words  \n",
       "0  insumo, crédito, capacitación, asistencia técnica  \n",
       "1                                         incentivar  \n",
       "2  apoyo económico, apoyos en especie, insumos, h...  \n",
       "3                                              pesos  \n",
       "4                                            recibir  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_excel['Mexico '].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_sents_map = {}\n",
    "mexico_df = data_excel['Mexico ']\n",
    "mexico_df[\"Relevant Sentences (for Environment, Incentives, Land Type) \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentences\n",
    "mexico_df[\"Relevant Sentences (for Environment, Incentives, Land Type) \"] = mexico_df[\"Relevant Sentences (for Environment, Incentives, Land Type) \"].apply(lambda x: x.replace(\"\\n\", \"\").strip())\n",
    "mexico_sents = list(mexico_df[\"Relevant Sentences (for Environment, Incentives, Land Type) \"])\n",
    "\n",
    "# Labels\n",
    "mexico_df['Incentive Instrument'] = mexico_df['Incentive Instrument'].apply(lambda x: x.replace(\"(PES)\", \"\").replace(\"(Bond)\", \"\").strip())\n",
    "mexico_labels = [[string.strip() for string in label.split(\", \")][0] for label in mexico_df['Incentive Instrument']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mexico_sents[0], set(mexico_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_labeled_sentences(excel_map):\n",
    "    result = {}\n",
    "    for country, dataframe in excel_map.items():\n",
    "\n",
    "        new_sents_col = dataframe[\"Relevant Sentences (for Environment, Incentives, Land Type) \"].dropna()\n",
    "        new_labels_col= dataframe[\"Incentive Instrument\"].dropna()\n",
    "        \n",
    "        sentences = list(new_sents_col.apply(lambda x: x.replace(\"\\n\", \"\").strip()))\n",
    "        label_col = new_labels_col.apply(lambda x: x.replace(\"(PES)\", \"\").replace(\"(Bond)\", \"\").strip())\n",
    "        labels = [[string.strip() for string in label.split(\", \")][0] for label in label_col]\n",
    "        result[country] = {}\n",
    "\n",
    "        for i, (sent, label) in enumerate(zip(sentences, labels)):\n",
    "            if i not in result[country]:\n",
    "                result[country][i] = {\"text\": sent, \"labels\": [label]}\n",
    "            else:\n",
    "                result[country][i][\"text\"] = sent\n",
    "                result[country][i][\"labels\"] = [label]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_sents_map = country_labeled_sentences(data_excel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Sentence analysis by country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Mexico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_sents_map[\"Mexico \"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = [\"Direct payment\", \"Tax deduction\", \"Credit\", \"Guarantee\", \"Technical assistance\", \"Supplies\", \"Fine\", \"Unknown\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We want to have the labels both as numbers and as text (for plotting/evaluating purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mexico_labels = labels_from_model_output(excel_sents_map[\"Mexico \"])\n",
    "num_mexico_labels = labels_to_numeric(mexico_labels, label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_distribution(num_mexico_labels, label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, scores = classify_sentences_topic(excel_sents_map[\"Mexico \"], label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_preds = labels_to_numeric(preds, label_names)\n",
    "preds[:10], scores[:10], num_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = ModelEvaluator(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.evaluate(num_mexico_labels, num_preds, \n",
    "                   plot_cm=True, normalize=True, \n",
    "                   store=True, exp_name=\"multi_class_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.plot_precision_recall_curve(num_mexico_labels, num_preds, bin_class=False, all_classes=True, store=True, exp_name=\"../output/mexico_multi_class_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load labeled sentences from 5 countries (JSON file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"../input/allcountries_tagged_sents.json\"\n",
    "data = load_file(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out badly parsed sentences - with 1 character or empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_ids = []\n",
    "for document, content in data.items():\n",
    "    for section in content.values():\n",
    "        for sid, sentence in section['sentences'].items():\n",
    "            if 0 <= len(sentence['text']) <= 1:\n",
    "                print(sentence['text'])\n",
    "                missing_ids.append(sid)\n",
    "\n",
    "print(len(missing_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_sents_from_dataset(ids, dataset):\n",
    "    filtered_dataset = {}\n",
    "    \n",
    "    for docid, document in dataset.items():\n",
    "        filtered_dataset[docid] = {}\n",
    "        for secid, section in document.items():\n",
    "            filtered_dataset[docid][secid] = {3}\n",
    "            filtered_dataset[docid][secid]['tags'] = section['tags']\n",
    "            filtered_dataset[docid][secid]['sentences'] = {}\n",
    "            for sentid, sentence in section['sentences'].items():\n",
    "                if sentid not in ids:\n",
    "                    filtered_dataset[docid][secid]['sentences'][sentid] = sentence\n",
    "            \n",
    "    return filtered_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = remove_sents_from_dataset(missing_ids, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_map = labeled_sentences_from_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_map['10']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels_from_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = [\"not incentives\", \"incentives\"]\n",
    "binary_labels = list(map(lambda x: \"incentives\" if x != \"Unknown\" else \"not incentives\", labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_labels.count(\"incentives\"), binary_labels.count(\"not incentives\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bin_labels = labels_to_numeric(binary_labels, label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bin_labels[180:190]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_distribution(num_bin_labels, label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_model_preds, bin_scores = classify_sentences_topic(dataset_map,label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_preds = labels_to_numeric(bin_model_preds, label_names)\n",
    "bin_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = ModelEvaluator(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.update(num_bin_labels, bin_preds)\n",
    "print(\"Recall per class:\", evaluator.recall)\n",
    "print(\"Average weighted precision:\", evaluator.avg_precision[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.evaluate(num_bin_labels, bin_preds, \n",
    "                   plot_cm=True, normalize=True, \n",
    "                   store=True, exp_name=\"binary_class_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.plot_precision_recall_curve(num_bin_labels, bin_scores, bin_class=True, store=True, exp_name=\"binary_class_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = [\"Direct payment\", \"Tax deduction\", \"Credit\", \"Guarantee\", \"Technical assistance\", \"Supplies\", \"Fine\", \"Unknown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_model_preds, multi_scores = classify_sentences_topic(dataset_map, label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = ModelEvaluator(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_model_preds[:10], labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make label names from dataset match label names from prediction (a.k.a make all Direct payments be the same)\n",
    "updated_labels = []\n",
    "for label in labels:\n",
    "    if \"(\" in label:\n",
    "        updated_labels.append(\"Direct payment\")\n",
    "    else:\n",
    "        updated_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_multi_labels = labels_to_numeric(updated_labels, label_names)\n",
    "num_multi_preds = labels_to_numeric(multi_model_preds, label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.evaluate(num_multi_labels, num_multi_preds, \n",
    "                   plot_cm=True, normalize=True, \n",
    "                   store=True, exp_name=\"multi_class_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.plot_precision_recall_curve(num_multi_labels, num_multi_preds, bin_class=False, all_classes=True, store=True, exp_name=\"multi_class_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tangent: Separate mutliple labels into a list from JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../input/tagged_sentences_all.json\", \"r\") as fjson: \n",
    "    jsents = json.load(fjson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(jsents), jsents.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_tags_dict = {}\n",
    "new_json = {}\n",
    "\n",
    "for keydoc, document in jsents.items():\n",
    "    new_json[keydoc] = {}\n",
    "    for keysec, section in document.items():\n",
    "        new_json[keydoc][keysec] = {}\n",
    "        new_json[keydoc][keysec]['tags'] = section['tags']\n",
    "        new_json[keydoc][keysec]['sentences'] = {}\n",
    "        for sentid, sentence in section['sentences'].items():\n",
    "            new_labels = [label.strip() for label in sentence['labels'].split(\", \")]\n",
    "\n",
    "            updated_labels = []\n",
    "            for label in new_labels:\n",
    "                if \"(\" in label:\n",
    "                    updated_labels.append(\"Direct payment\")\n",
    "                else:\n",
    "                    updated_labels.append(label)\n",
    "            new_json[keydoc][keysec]['sentences'][sentid] = {'text': sentence['text'], 'labels': updated_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_json), new_json.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"allcountries_tagged_sents.json\", \"w\") as wjson:\n",
    "    json.dump(new_json, wjson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_file(\"allcountries_tagged_sents.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_map = labeled_sentences_from_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_map['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_labels = labels_from_dataset(data)\n",
    "dataset_labels[:10], set(dataset_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_labels = numeric_labels_from_dataset(data)\n",
    "numeric_labels[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wri-env",
   "language": "python",
   "name": "wri-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
