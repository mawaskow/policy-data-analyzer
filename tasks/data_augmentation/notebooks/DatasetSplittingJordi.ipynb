{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DatasetSplittingJordi.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4UNMkgIvDXl",
        "outputId": "713ca5d5-8ed9-4e09-a4a2-8117c8442138"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGPfude9amX0"
      },
      "source": [
        "### Building datasets\n",
        "\n",
        "This piece of code below has been used to build the test splits and the datasets for the fine tuning. Don't execute it unless you kow what you want :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPFFoEUQvpMu"
      },
      "source": [
        "def labels_from_dataset(dataset, label):\n",
        "    labels = []\n",
        "\n",
        "    for sentence in dataset.values():\n",
        "        labels.append(sentence[label])\n",
        "\n",
        "    return labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdD2Da9fnRqb"
      },
      "source": [
        "rater = \"Rater3\"\n",
        "set_of_labels = All\n",
        "set_of_labels_string = \"All\"\n",
        "\n",
        "dataset_fname = \"/content/drive/MyDrive/Official Folder of WRI Latin America Project/WRI-LatinAmerica-Talent/Cristina_Policy_Files/Tagged_sentence_lists/{}_labeled.json\".format(rater)\n",
        "dataset = load_file(dataset_fname)\n",
        "dataset_map = labeled_sentences_from_dataset(dataset) # Labels AND sentences\n",
        "# dataset_map_target_labels =  select_labels(dataset_map, set_of_labels) # Adjust to the labels you want to use for your analysis. In the cell above you have three pre-defined sets.\n",
        "# train_sents = sentences_from_dataset(dataset_map_target_labels) # Just sentences\n",
        "# train_labels = labels_from_dataset(dataset_map_target_labels, \"labels\") # Just labels. \n",
        "\n",
        "train_sents = sentences_from_dataset(dataset_map) # Just sentences\n",
        "train_labels = labels_from_dataset(dataset_map, \"incentive\") # Just labels."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sQIjw0Yx7xV",
        "outputId": "cb5e3588-f322-4c17-955a-86cce2194345"
      },
      "source": [
        "len(train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1526"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tasMxprPDgfU",
        "outputId": "13a402e7-6f1b-438c-d508-0c9a528345d2"
      },
      "source": [
        "# # The rest:\n",
        "label_names = unique_labels(train_labels)\n",
        "numeric_labels = labels2numeric(train_labels, label_names)\n",
        "label_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Supplies',\n",
              " 'Technical assistance',\n",
              " 'Direct payment',\n",
              " 'Fine',\n",
              " 'Tax deduction',\n",
              " 'Credit']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-KrPd8YR0m5"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train_sents, train_labels, test_size=0.2, stratify=train_labels, random_state=69420)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmGglxNwyU5s"
      },
      "source": [
        "# import csv\n",
        "path = \"/content/drive/MyDrive/Official Folder of WRI Latin America Project/WRI-LatinAmerica-Talent/Cristina_Policy_Files/Tagged_sentence_lists/datasets/\"\n",
        "\n",
        "filename = \"dataset_{}_incentive_sentences.csv\".format(rater)\n",
        "file = path + filename\n",
        "with open(file, 'w') as myfile:\n",
        "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
        "    wr.writerow(X_train)\n",
        "\n",
        "filename = \"dataset_{}_incentive_labels.csv\".format(rater)\n",
        "file = path + filename\n",
        "with open(file, 'w') as myfile:\n",
        "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
        "    wr.writerow(y_train)\n",
        "\n",
        "filename = \"testset_{}_incentive_sentences.csv\".format(rater)\n",
        "file = path + filename\n",
        "with open(file, 'w') as myfile:\n",
        "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
        "    wr.writerow(X_test)\n",
        "\n",
        "filename = \"testset_{}_incentive_labels.csv\".format(rater)\n",
        "file = path + filename\n",
        "with open(file, 'w') as myfile:\n",
        "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
        "    wr.writerow(y_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cySx76TVSc0o"
      },
      "source": [
        "# import csv\n",
        "path = \"/content/drive/MyDrive/Official Folder of WRI Latin America Project/WRI-LatinAmerica-Talent/Cristina_Policy_Files/Tagged_sentence_lists/datasets/\"\n",
        "\n",
        "filename = \"dataset_{}_{}_sentences.csv\".format(rater, set_of_labels_string)\n",
        "file = path + filename\n",
        "with open(file, 'w') as myfile:\n",
        "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
        "    wr.writerow(X_train)\n",
        "\n",
        "filename = \"dataset_{}_{}_labels.csv\".format(rater, set_of_labels_string)\n",
        "file = path + filename\n",
        "with open(file, 'w') as myfile:\n",
        "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
        "    wr.writerow(y_train)\n",
        "\n",
        "filename = \"testset_{}_{}_sentences.csv\".format(rater, set_of_labels_string)\n",
        "file = path + filename\n",
        "with open(file, 'w') as myfile:\n",
        "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
        "    wr.writerow(X_test)\n",
        "\n",
        "filename = \"testset_{}_{}_labels.csv\".format(rater, set_of_labels_string)\n",
        "file = path + filename\n",
        "with open(file, 'w') as myfile:\n",
        "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
        "    wr.writerow(y_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APO7hnHqpBg_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}