{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_dict = {'Credit' : 'Credit', 'Direct' : 'Direct payment', 'Fine' : 'Fine', 'General' : 'Unknown', \n",
    "               'Guarantee' : 'Credit', 'Supplies' : 'Supplies', 'Tax' : 'Tax deduction', \n",
    "               'Technical' : 'Technical assistance', 'Unknown' : 'Unknown', 'Other' : 'Unknown', 'Nan' : 'Unknown' }\n",
    "\n",
    "incentive_dict = {'Incentive' : 'Incentive', 'Disincentive' : 'Incentive', 'Unknown' : 'not_Incentive', 'Nan' : 'not_Incentive'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_df(df, reference_column_to_drop_na):\n",
    "    df.dropna(subset = [reference_column_to_drop_na], inplace = True)\n",
    "    df.dropna(axis=1, how='all', inplace = True)\n",
    "    df.replace(np.nan, 'Nan', regex=True, inplace = True)\n",
    "    return df\n",
    "\n",
    "def process_new_labels(filename, reference_column_to_drop_na, policy):\n",
    "    df_temp = pd.concat(pd.read_excel(filename, engine='openpyxl', sheet_name = None, skiprows=[0]), ignore_index = True)\n",
    "    df_temp = clean_df(df_temp, reference_column_to_drop_na)\n",
    "    df_temp.insert(0, \"Document\", df_temp.apply(lambda row: row.Sentence_Id.split(\"_\")[0], axis = 1))\n",
    "    df_temp.loc[df_temp['Is_policy'] == 0, 'Is_policy'] = \"Nan\"\n",
    "    df_temp.loc[df_temp['Is_policy'] == 1, 'Is_policy'] = policy\n",
    "    if \"Other_instrument\"in df_temp.columns:\n",
    "        df_temp['Is_policy'] = np.where(df_temp['Is_policy'] == \"Nan\", df_temp['Other_instrument'], df_temp['Is_policy'])\n",
    "    df_temp.loc[df_temp['Is_incentive'] == 0, 'Is_incentive'] = \"Unknown\"\n",
    "    df_temp.loc[df_temp['Is_incentive'] == 1, 'Is_incentive'] = \"Incentive\"\n",
    "    return df_temp\n",
    "\n",
    "def label_cleaning(dictionaryionary, label):\n",
    "    flag = 1\n",
    "    \n",
    "    for key in dictionaryionary:\n",
    "#         print(key, \"----\", label)\n",
    "        if key in label:\n",
    "            return dictionaryionary[key]\n",
    "            flag = 0\n",
    "            break\n",
    "    if flag == 1:\n",
    "#         print(label)\n",
    "        return label\n",
    "\n",
    "def merge_excel_to_list_new(filename):\n",
    "    flag = False\n",
    "    \n",
    "    for policy in policy_dict:\n",
    "        if policy in filename:\n",
    "            policy_instrument = policy\n",
    "            flag = True\n",
    "    if flag:\n",
    "#         print(filename)\n",
    "        df = process_new_labels(filename, \"Is_incentive\", policy_instrument)\n",
    "        List = df[[\"Document\", \"Sentence_Id\", \"Sentence\", \"Is_policy\", \"Is_incentive\"]].values.tolist()\n",
    "    \n",
    "    return List\n",
    "\n",
    "def merge_excel_to_list_old(filename):\n",
    "    df = pd.concat(pd.read_excel(filename, engine='openpyxl', sheet_name = None), ignore_index = True)\n",
    "    df = clean_df(df, \"Document\")\n",
    "    df = df[[\"Document\", \"Sentence\", \"Primary_Instrument\", \"Category\"]]\n",
    "    data = df.values.tolist()\n",
    "    \n",
    "    return data\n",
    "    \n",
    "\n",
    "def list_new_labels_to_dict(List, Dictionary, rater):\n",
    "    i = 0\n",
    "    for item in List:\n",
    "        if item[0] in Dictionary:\n",
    "            if item[1] in Dictionary[item[0]][\"Seccion unica\"][\"sentences\"]:\n",
    "                if Dictionary[item[0]][\"Seccion unica\"][\"sentences\"][item[1]][\"labels\"] == \"Unknown\":\n",
    "                    if label_cleaning(policy_dict, item [3]) != \"Unknown\":\n",
    "                        i += 1\n",
    "#                             print(rater, \"--\", item[1], Dictionary[item[0]][\"Seccion unica\"][\"sentences\"][item[1]][\"text\"], label_cleaning(policy_dict, item [3]))\n",
    "                        Dictionary[item[0]][\"Seccion unica\"][\"sentences\"][item[1]][\"labels\"] = label_cleaning(policy_dict, item [3])\n",
    "\n",
    "            else:\n",
    "                i += 1\n",
    "                Dictionary[item[0]][\"Seccion unica\"][\"sentences\"][item[1]] = {\"text\" : item[2], \"labels\" : label_cleaning(policy_dict, item [3]), \"incentive\": label_cleaning(incentive_dict, item [4])}\n",
    "        else:\n",
    "            i += 1\n",
    "            Dictionary[item[0]] = {\"Seccion unica\" : {\"tags\" : [], \"sentences\" : {}}}\n",
    "            Dictionary[item[0]][\"Seccion unica\"][\"sentences\"][item[1]] = {\"text\" : item[2], \"labels\" : label_cleaning(policy_dict, item [3]), \"incentive\": label_cleaning(incentive_dict, item [4])}\n",
    "#     print(rater, \" -- \", i)\n",
    "    return Dictionary\n",
    "\n",
    "def list_old_labels_to_dict(List):\n",
    "    Dictionary = {}\n",
    "    i = 0\n",
    "    for item in List:\n",
    "        if item[0] in Dictionary:\n",
    "            i += 1\n",
    "            Dictionary[item[0]][\"Seccion unica\"][\"sentences\"][str(i)] = {\"text\" : item[1], \"labels\" : label_cleaning(policy_dict, item [2]), \"incentive\": label_cleaning(incentive_dict, item [3])}\n",
    "        else:\n",
    "            i += 1\n",
    "            Dictionary[item[0]] = {\"Seccion unica\" : {\"tags\" : [], \"sentences\" : {}}}\n",
    "            Dictionary[item[0]][\"Seccion unica\"][\"sentences\"][str(i)] = {\"text\" : item[1], \"labels\" : label_cleaning(policy_dict, item [2]), \"incentive\": label_cleaning(incentive_dict, item [3])}\n",
    "            \n",
    "    return Dictionary\n",
    "\n",
    "def save_dictionary(path, dictionary, rater, old_merge = False, test = False):\n",
    "    if old_merge:\n",
    "        filename = \"{}/{}_combined_labeled.json\".format(rater, rater)\n",
    "    elif old_merge == False and test == False:\n",
    "        filename = \"{}/{}_single_labeled.json\".format(rater, rater)\n",
    "    elif old_merge == False and test == True:\n",
    "        filename = \"{}/{}_single_labeled_test.json\".format(rater, rater)\n",
    "        \n",
    "    file = path / filename\n",
    "    with open(file, 'w') as fp:\n",
    "        json.dump(dictionary, fp)\n",
    "        \n",
    "def load_dictionary(file):\n",
    "    with open(file, 'r') as f:\n",
    "        dictionary = json.load(f)\n",
    "    return dictionary\n",
    "        \n",
    "def wraping_up(base_path, rater, only_rater):\n",
    "    data_path = base_path.glob('**/')\n",
    "    for path in data_path:\n",
    "#         results_list = []\n",
    "        dictionary = {}    \n",
    "        path_in_str = str(path)\n",
    "#         print(path_in_str)\n",
    "        if rater in path_in_str:\n",
    "#             print(path_in_str)\n",
    "            for file_obj in Path(path_in_str).glob('*.xlsx'):\n",
    "                file = str(file_obj)\n",
    "                if \"Unique\" in file:\n",
    "#                     print(file)\n",
    "                    results_list = merge_excel_to_list_new(file)\n",
    "                    dictionary_new_labels = list_new_labels_to_dict(results_list, dictionary, rater)\n",
    "                else:\n",
    "                    dictionary_old_labels = list_old_labels_to_dict(merge_excel_to_list_old(file))\n",
    "            j = 0        \n",
    "            for key1 in dictionary_new_labels:\n",
    "                for key2 in dictionary_new_labels[key1][\"Seccion unica\"][\"sentences\"]:\n",
    "                    j += 1\n",
    "#             print(rater, \" - all\", j)\n",
    "            if only_rater:\n",
    "                save_dictionary(base_path, dictionary_new_labels, rater, False, False)\n",
    "                save_dictionary(base_path, dictionary_old_labels, rater, False, True)\n",
    "            else:\n",
    "                merged_dict = {**dictionary_old_labels, **dictionary_new_labels}\n",
    "                save_dictionary(base_path, merged_dict, rater, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raters = [\"Rater1\", \"Rater2\", \"Rater3\"]\n",
    "only_raters = [True, False]\n",
    "# base_path = Path(\"C:/Users/jordi/Google Drive/Els_meus_documents/projectes/CompetitiveIntelligence/WRI/Notebooks/Data/Final_input_data/\")\n",
    "base_path = Path(\"C:/Users/user/Google Drive/Els_meus_documents/projectes/CompetitiveIntelligence/WRI/Notebooks/Data/Final_input_data/\")\n",
    "\n",
    "for rater in raters:\n",
    "    for only_rater in only_raters:\n",
    "        wraping_up(base_path, rater, only_rater)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = base_path.glob('**/')\n",
    "\n",
    "all_sents = {}\n",
    "rater1 = {}\n",
    "rater2 = {}\n",
    "rater3 = {}\n",
    "\n",
    "# First we build a dictionary with all the sentences that are in the three databases.\n",
    "# We also build a dictionary for each rater\n",
    "i = 0\n",
    "for path in data_path:\n",
    "    for file_obj in path.glob('*.json'):\n",
    "        file = str(file_obj)\n",
    "        if \"Rater\" in file and \"single\" in file and \"test\" not in file:\n",
    "            print(file)\n",
    "#             print(i)\n",
    "            dictionary = load_dictionary(file)\n",
    "            new_dict = {}\n",
    "            for value in dictionary.values():\n",
    "                for sentences in value.values():\n",
    "                    for sent in sentences['sentences']:\n",
    "#                         i += 1\n",
    "                        all_sents[sent] = sentences['sentences'][sent]\n",
    "                        new_dict[sent] = sentences['sentences'][sent]\n",
    "        if \"Rater1\" in file:\n",
    "            rater1 = new_dict\n",
    "        elif \"Rater2\" in file:\n",
    "            rater2 = new_dict          \n",
    "        elif \"Rater3\" in file:\n",
    "            rater3 = new_dict\n",
    "            \n",
    "print(len(rater1), \" -- \", len(rater2), \" -- \", len(rater3))\n",
    "\n",
    "# Next we loop for the dictionary to find the elements that meet the criteria of the different merges.\n",
    "\n",
    "incentive = \"labels\" #write \"labels\" if you want to work with policy instruments, write \"incentive\" to work with is_incentive\n",
    "merge1 = {}\n",
    "merge2 = {}\n",
    "merge3 = {}\n",
    "classifier = \"labels\" #If you want to classify by is_incentive\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "k = 0\n",
    "l = 0\n",
    "m = 0\n",
    "n = 0\n",
    "# First we look for sentences that all three raters have labeled the same\n",
    "for sent in all_sents:\n",
    "    i += 1\n",
    "    if sent in rater1 and sent in rater2 and sent in rater3:\n",
    "        j += 1\n",
    "        if rater1[sent][\"labels\"] == rater2[sent][\"labels\"] and rater2[sent][\"labels\"] == rater3[sent][\"labels\"]:\n",
    "            k += 1\n",
    "            if rater1[sent][\"labels\"] != 'Unknown':\n",
    "                merge3[sent] = rater1[sent]\n",
    "\n",
    "#Now we look for the sentences that at least two raters have labeled the same\n",
    "for sent in all_sents:\n",
    "    if sent in rater1 and sent in rater2:\n",
    "        l += 1\n",
    "        if rater1[sent][\"labels\"] == rater2[sent][\"labels\"]:\n",
    "            if rater1[sent][\"labels\"] != 'Unknown':\n",
    "                m += 1\n",
    "                merge2[sent] = rater1[sent]\n",
    "    elif sent in rater1 and sent in rater3:\n",
    "        l += 1\n",
    "        if rater1[sent][\"labels\"] == rater3[sent][\"labels\"]:\n",
    "            if rater1[sent][\"labels\"] != 'Unknown':\n",
    "                m += 1\n",
    "                merge2[sent] = rater1[sent]\n",
    "    elif sent in rater2 and sent in rater3:\n",
    "        l += 1\n",
    "        if rater2[sent][\"labels\"] == rater3[sent][\"labels\"]:\n",
    "            if rater2[sent][\"labels\"] != 'Unknown':\n",
    "                m += 1\n",
    "                merge2[sent] = rater2[sent]\n",
    "            \n",
    "# Finally we build a dataset containing the sentences that at least one of the labelers have labeled with a label different from \"Unknown\"\n",
    "for sent in all_sents:\n",
    "    label = {}\n",
    "    if sent in rater3 and rater3[sent][\"labels\"] != 'Unknown':\n",
    "#         label[rater3[sent][\"labels\"]] = \"rater3\"\n",
    "        merge1[sent] = rater3[sent]\n",
    "    elif sent in rater2 and rater2[sent][\"labels\"] != 'Unknown':\n",
    "#         label[rater2[sent][\"labels\"]] = \"rater2\"\n",
    "        merge1[sent] = rater2[sent]\n",
    "    elif sent in rater1 and rater1[sent][\"labels\"] != 'Unknown':\n",
    "#         label[rater1[sent][\"labels\"]] = \"rater1\"\n",
    "        merge1[sent] = rater1[sent]\n",
    "#     else:\n",
    "#         merge1[sent] = all_sents[sent]\n",
    "\n",
    "print(f\"In the all-sentences dict there are {i} sentences\")\n",
    "print(f\"In the three raters lists there are {j} common sentences\")\n",
    "print(f\"In the three raters lists there are {k} common sentences which are rated identically\")\n",
    "print(f\"There are {l} sentences which are comon to at lest two rater's datasets\")\n",
    "print(f\"There are {m} sentences which are labeled identical in at least two rater's datasets\")\n",
    "print(len(merge3))\n",
    "print(len(merge2))\n",
    "print(len(merge1))\n",
    "\n",
    "merges = {\"Merge1\" : merge1, \"Merge2\" : merge2, \"Merge3\" : merge3}\n",
    "for merge in merges:\n",
    "    all_sents = []\n",
    "    all_labels = []\n",
    "    for sent in merges[merge]:\n",
    "        all_sents.append(merges[merge][sent][\"text\"])\n",
    "        all_labels.append(merges[merge][sent][\"labels\"])\n",
    "\n",
    "    print(merge, len(all_sents))\n",
    "    \n",
    "    test_perc = 0.2\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(all_sents, all_labels, test_size=test_perc, stratify=all_labels, random_state=69420)\n",
    "\n",
    "    print(len(X_train), \" - \", len(X_test))\n",
    "\n",
    "    path = \"C:/Users/user/Google Drive/Els_meus_documents/projectes/CompetitiveIntelligence/WRI/Notebooks/Data/Final_input_data/Merges/\"\n",
    "\n",
    "    filename = \"dataset_{}_policy_sentences.csv\".format(merge)\n",
    "    file = path + filename\n",
    "    with open(file, 'w', newline='', encoding='utf-8') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerows(zip(X_train))\n",
    "\n",
    "    filename = \"dataset_{}_policy_labels.csv\".format(merge)\n",
    "    file = path + filename\n",
    "    with open(file, 'w', newline='', encoding='utf-8') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerows(zip(y_train))\n",
    "\n",
    "    filename = \"testset_{}_policy_sentences.csv\".format(merge)\n",
    "    file = path + filename\n",
    "    with open(file, 'w', newline='', encoding='utf-8') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerows(zip(X_test))\n",
    "\n",
    "    filename = \"testset_{}_policy_labels.csv\".format(merge)\n",
    "    file = path + filename\n",
    "    with open(file, 'w', newline='', encoding='utf-8') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerows(zip(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data for binary classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_sents elements 1326\n",
      "565  --  1312  --  911\n",
      "Rater1\n",
      "Incentive 267  -- not_Incentive 298  -- Others 0\n",
      "452  -  113\n",
      "Rater2\n",
      "Incentive 772  -- not_Incentive 540  -- Others 0\n",
      "1049  -  263\n",
      "Rater3\n",
      "Incentive 440  -- not_Incentive 471  -- Others 0\n",
      "728  -  183\n"
     ]
    }
   ],
   "source": [
    "raters = [\"Rater1\", \"Rater2\", \"Rater3\"]\n",
    "# base_path = Path(\"C:/Users/jordi/Google Drive/Els_meus_documents/projectes/CompetitiveIntelligence/WRI/Notebooks/Data/Final_input_data/\")\n",
    "base_path = Path(\"C:/Users/user/Google Drive/Els_meus_documents/projectes/CompetitiveIntelligence/WRI/Notebooks/Data/Final_input_data/\")\n",
    "\n",
    "data_path = base_path.glob('**/')\n",
    "\n",
    "all_sent = {}\n",
    "rater1 = {}\n",
    "rater2 = {}\n",
    "rater3 = {}\n",
    "\n",
    "# First we build a dictionary with all the sentences that are in the three databases.\n",
    "# We also build a dictionary for each rater\n",
    "i = 0\n",
    "for path in data_path:\n",
    "    for file_obj in path.glob('*.json'):\n",
    "        file = str(file_obj)\n",
    "#         print(file)\n",
    "        if \"Rater\" in file and \"single\" in file and \"test\" not in file: #TODO: Adjust when needed\n",
    "#             print(file)\n",
    "#             print(i)\n",
    "            dictionary = load_dictionary(file)\n",
    "            new_dict = {}\n",
    "            for value in dictionary.values():\n",
    "                for sentences in value.values():\n",
    "                    for sent in sentences['sentences']:\n",
    "#                         i += 1\n",
    "                        all_sent[sent] = sentences['sentences'][sent]\n",
    "                        new_dict[sent] = sentences['sentences'][sent]\n",
    "            if \"Rater1\" in file:\n",
    "                rater1 = new_dict\n",
    "            elif \"Rater2\" in file:\n",
    "                rater2 = new_dict          \n",
    "            elif \"Rater3\" in file:\n",
    "                rater3 = new_dict\n",
    "print(\"all_sents elements\", len(all_sent))\n",
    "print(len(rater1), \" -- \", len(rater2), \" -- \", len(rater3))\n",
    "raters = {\"Rater1\" : rater1, \"Rater2\" : rater2, \"Rater3\": rater3}\n",
    "\n",
    "for rater in raters:\n",
    "    unknown = 0\n",
    "    known = 0\n",
    "    bugs = 0\n",
    "    all_sents = []\n",
    "    all_labels = []\n",
    "    for sent in raters[rater]:\n",
    "        all_sents.append(raters[rater][sent][\"text\"])\n",
    "        all_labels.append(raters[rater][sent][\"incentive\"])\n",
    "        if raters[rater][sent][\"incentive\"] == \"not_Incentive\":\n",
    "            unknown += 1\n",
    "        elif raters[rater][sent][\"incentive\"] == \"Incentive\":\n",
    "            known += 1\n",
    "        else:\n",
    "            bugs += 1\n",
    "\n",
    "    test_perc = 0.2\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(all_sents, all_labels, test_size=test_perc, stratify=all_labels, random_state=69420)\n",
    "    \n",
    "    print(rater)\n",
    "    print(\"Incentive\", unknown, \" -- not_Incentive\", known, \" -- Others\", bugs)\n",
    "    print(len(X_train), \" - \", len(X_test))       \n",
    "\n",
    "    path = \"C:/Users/user/Google Drive/Els_meus_documents/projectes/CompetitiveIntelligence/WRI/Notebooks/Data/Final_input_data/Binary/\"\n",
    "\n",
    "    filename = \"dataset_{}_incentive_sentences.csv\".format(rater)\n",
    "    file = path + filename\n",
    "    with open(file, 'w', newline='', encoding='utf-8') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerows(zip(X_train))\n",
    "\n",
    "    filename = \"dataset_{}_incentive_labels.csv\".format(rater)\n",
    "    file = path + filename\n",
    "    with open(file, 'w', newline='', encoding='utf-8') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerows(zip(y_train))\n",
    "\n",
    "    filename = \"testset_{}_incentive_sentences.csv\".format(rater)\n",
    "    file = path + filename\n",
    "    with open(file, 'w', newline='', encoding='utf-8') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerows(zip(X_test))\n",
    "\n",
    "    filename = \"testset_{}_incentive_labels.csv\".format(rater)\n",
    "    file = path + filename\n",
    "    with open(file, 'w', newline='', encoding='utf-8') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerows(zip(y_test))\n",
    "\n",
    "        \n",
    "# # For the merged dataset\n",
    "# rater = \"Merged\"\n",
    "# all_sents = []\n",
    "# all_labels = []\n",
    "# for sent in all_sent:\n",
    "#     all_sents.append(all_sent[sent][\"text\"])\n",
    "#     all_labels.append(all_sent[sent][\"incentive\"])\n",
    "\n",
    "# print(len(all_sents))\n",
    "    \n",
    "# test_perc = 0.2\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(all_sents, all_labels, test_size=test_perc, stratify=all_labels, random_state=69420)\n",
    "\n",
    "# print(len(X_train), \" - \", len(X_test))\n",
    "\n",
    "# path = \"C:/Users/user/Google Drive/Els_meus_documents/projectes/CompetitiveIntelligence/WRI/Notebooks/Data/Final_input_data/Binary/\"\n",
    "\n",
    "# filename = \"dataset_{}_incentive_sentences.csv\".format(rater)\n",
    "# file = path + filename\n",
    "# with open(file, 'w', newline='', encoding='utf-8') as myfile:\n",
    "#     wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "#     wr.writerows(zip(X_train))\n",
    "\n",
    "# filename = \"dataset_{}_incentive_labels.csv\".format(rater)\n",
    "# file = path + filename\n",
    "# with open(file, 'w', newline='', encoding='utf-8') as myfile:\n",
    "#     wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "#     wr.writerows(zip(y_train))\n",
    "\n",
    "# filename = \"testset_{}_incentive_sentences.csv\".format(rater)\n",
    "# file = path + filename\n",
    "# with open(file, 'w', newline='', encoding='utf-8') as myfile:\n",
    "#     wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "#     wr.writerows(zip(X_test))\n",
    "\n",
    "# filename = \"testset_{}_incentive_labels.csv\".format(rater)\n",
    "# file = path + filename\n",
    "# with open(file, 'w', newline='', encoding='utf-8') as myfile:\n",
    "#     wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "#     wr.writerows(zip(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
