{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GoogleColabFineTuneEmbeddingModel.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"77416ef1b857412fa8672423085fd6ef":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8179bee0272043da88a2875621ff32fb","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_91a50a07cd454f23915953f36246ceee","IPY_MODEL_9d1e224c18354831bfa64a8e351168c0"]}},"8179bee0272043da88a2875621ff32fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"91a50a07cd454f23915953f36246ceee":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0caae83d9c7141409da5854c88666975","_dom_classes":[],"description":"Epoch: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":2,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c73c1ce1249d4bc1a02c3f26993332a3"}},"9d1e224c18354831bfa64a8e351168c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8ce9a10a5aa84201951fc9c3bbd21a9d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2/2 [00:46&lt;00:00, 23.50s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7310c5b2f5bf4533bc683f613a6045bf"}},"0caae83d9c7141409da5854c88666975":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c73c1ce1249d4bc1a02c3f26993332a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8ce9a10a5aa84201951fc9c3bbd21a9d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7310c5b2f5bf4533bc683f613a6045bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2c4d53ec4f48481f98417f8cbd0ab272":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_af603f4600204e6ba06e985c2b36dd29","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e0d19f17e45d411b834152ecdadf481d","IPY_MODEL_a1034ed7832944d38c8909a5ae5e0792"]}},"af603f4600204e6ba06e985c2b36dd29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e0d19f17e45d411b834152ecdadf481d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_04a7b8b0cdd9436885cb70798c2d0dce","_dom_classes":[],"description":"Iteration: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":77,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":77,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9be6bea6302c4734b8a5677ce17ceb86"}},"a1034ed7832944d38c8909a5ae5e0792":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8691e8ca35ee41eaa1cfaf488bba9e85","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 77/77 [01:00&lt;00:00,  1.28it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8645596491e7407c96959a67997d010c"}},"04a7b8b0cdd9436885cb70798c2d0dce":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9be6bea6302c4734b8a5677ce17ceb86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8691e8ca35ee41eaa1cfaf488bba9e85":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8645596491e7407c96959a67997d010c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1deb6dd36c2e46ac826cc02f6302d18a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3f0536cf46ad45b0a9584fd39b9dbef6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e42f8a4c3f364cbc9c7cd4388db535d7","IPY_MODEL_ba9167b6660540cfa78ec809c95f4b1d"]}},"3f0536cf46ad45b0a9584fd39b9dbef6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e42f8a4c3f364cbc9c7cd4388db535d7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f3a4a6d2ee224bfb8b57f8be405d6c4d","_dom_classes":[],"description":"Iteration: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":77,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":77,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5fc403b9becb443584635d70a42cc5ed"}},"ba9167b6660540cfa78ec809c95f4b1d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b13b5be85d3b4c9f82b0b463f02636ce","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 77/77 [00:32&lt;00:00,  2.38it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_05e466cd25cb4316b695c94515cd318f"}},"f3a4a6d2ee224bfb8b57f8be405d6c4d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5fc403b9becb443584635d70a42cc5ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b13b5be85d3b4c9f82b0b463f02636ce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"05e466cd25cb4316b695c94515cd318f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"bk0XWLfMvDXU"},"source":["# Note\n","This notebook can be run on google colab for improved performance. The code changes necessary for running on this system are commented over the code."]},{"cell_type":"markdown","metadata":{"id":"edvxyOpnvDXj"},"source":["## Data preprocessing"]},{"cell_type":"code","metadata":{"id":"Ml7Gd4VgxW1d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610711750831,"user_tz":-60,"elapsed":126510,"user":{"displayName":"Jordi Planas","photoUrl":"","userId":"02408961736589621402"}},"outputId":"3e7d084c-a430-46ef-9d9e-d39377712915"},"source":["! pip install \\\n","  scprep\\\n","  spacy==2.3.2 \\\n","  sentence_transformers==0.4.0 \\\n","  phate==1.0.4 && \\\n","  python -m spacy download es_core_news_lg"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting scprep\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/17/41/f2d4728a5c4d762b5e7424e80fd6297ad53c58bc666d1cc8236827462b8c/scprep-1.0.11-py3-none-any.whl (100kB)\n","\u001b[K     |████████████████████████████████| 102kB 8.2MB/s \n","\u001b[?25hCollecting spacy==2.3.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/b5/c7a92c7ce5d4b353b70b4b5b4385687206c8b230ddfe08746ab0fd310a3a/spacy-2.3.2-cp36-cp36m-manylinux1_x86_64.whl (9.9MB)\n","\u001b[K     |████████████████████████████████| 10.0MB 27.5MB/s \n","\u001b[?25hCollecting sentence_transformers==0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/9a/62beeb5501b70ab48b9e5bb92de290f00a661a1caa075c4aae56d452aaa0/sentence-transformers-0.4.0.tar.gz (65kB)\n","\u001b[K     |████████████████████████████████| 71kB 10.1MB/s \n","\u001b[?25hCollecting phate==1.0.4\n","  Downloading https://files.pythonhosted.org/packages/c6/62/b98433d2b220ad1f106dde89d2e6d753d66b9cc3a914e1245c94556edad8/phate-1.0.4-py3-none-any.whl\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scprep) (4.4.2)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from scprep) (1.19.5)\n","Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scprep) (0.22.2.post1)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from scprep) (1.4.1)\n","Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.6/dist-packages (from scprep) (1.1.5)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.3.2) (3.0.5)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy==2.3.2) (1.0.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.3.2) (2.23.0)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.3.2) (0.4.1)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.3.2) (2.0.5)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.3.2) (0.8.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.3.2) (4.41.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy==2.3.2) (51.1.1)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.3.2) (1.0.5)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy==2.3.2) (1.1.3)\n","Collecting thinc==7.4.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/ae/ef3ae5e93639c0ef8e3eb32e3c18341e511b3c515fcfc603f4b808087651/thinc-7.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n","\u001b[K     |████████████████████████████████| 2.1MB 48.5MB/s \n","\u001b[?25hRequirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.3.2) (1.0.5)\n","Collecting transformers<5.0.0,>=3.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/40/866cbfac4601e0f74c7303d533a9c5d4a53858bd402e08e3e294dd271f25/transformers-4.2.1-py3-none-any.whl (1.8MB)\n","\u001b[K     |████████████████████████████████| 1.8MB 45.1MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from sentence_transformers==0.4.0) (1.7.0+cu101)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from sentence_transformers==0.4.0) (3.2.5)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/67/e42bd1181472c95c8cda79305df848264f2a7f62740995a46945d9797b67/sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 48.1MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.6/dist-packages (from phate==1.0.4) (3.2.2)\n","Collecting tasklogger>=1.0\n","  Downloading https://files.pythonhosted.org/packages/5d/6b/cb2a724eff19829a0ada0217f403f54fca1e48c7de6fc3383e0a8b8fa121/tasklogger-1.0.0-py3-none-any.whl\n","Collecting Deprecated\n","  Downloading https://files.pythonhosted.org/packages/76/a1/05d7f62f956d77b23a640efc650f80ce24483aa2f85a09c03fb64f49e879/Deprecated-1.2.10-py2.py3-none-any.whl\n","Collecting s-gd2>=1.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8d/4a/f7115c055aa088fd5ce4547923832c9e8644243262f920d207b089c6093e/s_gd2-1.8-cp36-cp36m-manylinux2010_x86_64.whl (415kB)\n","\u001b[K     |████████████████████████████████| 419kB 60.5MB/s \n","\u001b[?25hCollecting graphtools>=1.3.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dc/99/cc0d01f15c40656047caae88bbd3909ff535c116f2bba9e914423c8140e9/graphtools-1.5.2-py3-none-any.whl (45kB)\n","\u001b[K     |████████████████████████████████| 51kB 9.1MB/s \n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from phate==1.0.4) (0.16.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.1->scprep) (1.0.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.25->scprep) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.25->scprep) (2018.9)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy==2.3.2) (3.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.2) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.2) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.2) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.2) (1.24.3)\n","Collecting tokenizers==0.9.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 42.5MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 49.1MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<5.0.0,>=3.1.0->sentence_transformers==0.4.0) (20.8)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers<5.0.0,>=3.1.0->sentence_transformers==0.4.0) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<5.0.0,>=3.1.0->sentence_transformers==0.4.0) (2019.12.20)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers<5.0.0,>=3.1.0->sentence_transformers==0.4.0) (0.8)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->sentence_transformers==0.4.0) (3.7.4.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence_transformers==0.4.0) (1.15.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->phate==1.0.4) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->phate==1.0.4) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->phate==1.0.4) (1.3.1)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from Deprecated->phate==1.0.4) (1.12.1)\n","Collecting pygsp>=0.5.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/89/2f4aa73cccf12bec5179ac5d52a68b508120c838b7e5d456f5ea0c8beade/PyGSP-0.5.1-py2.py3-none-any.whl (1.8MB)\n","\u001b[K     |████████████████████████████████| 1.8MB 43.0MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy==2.3.2) (3.4.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence_transformers==0.4.0) (7.1.2)\n","Building wheels for collected packages: sentence-transformers, sacremoses\n","  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sentence-transformers: filename=sentence_transformers-0.4.0-cp36-none-any.whl size=102655 sha256=015049c36d356764c7106372b2726868aa51cb91644a9e8fee3b6beefc451a00\n","  Stored in directory: /root/.cache/pip/wheels/ff/76/65/50258d8b7930e909ea2f5bd006a23d520a16765af13ab45bb3\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=3aae1650a4b311a99982dc9f0b02030d839e2c81674659d68e72aee2b8cee493\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sentence-transformers sacremoses\n","Installing collected packages: scprep, thinc, spacy, tokenizers, sacremoses, transformers, sentencepiece, sentence-transformers, tasklogger, Deprecated, s-gd2, pygsp, graphtools, phate\n","  Found existing installation: thinc 7.4.0\n","    Uninstalling thinc-7.4.0:\n","      Successfully uninstalled thinc-7.4.0\n","  Found existing installation: spacy 2.2.4\n","    Uninstalling spacy-2.2.4:\n","      Successfully uninstalled spacy-2.2.4\n","Successfully installed Deprecated-1.2.10 graphtools-1.5.2 phate-1.0.4 pygsp-0.5.1 s-gd2-1.8 sacremoses-0.0.43 scprep-1.0.11 sentence-transformers-0.4.0 sentencepiece-0.1.95 spacy-2.3.2 tasklogger-1.0.0 thinc-7.4.1 tokenizers-0.9.4 transformers-4.2.1\n","Collecting es_core_news_lg==2.3.1\n","\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_lg-2.3.1/es_core_news_lg-2.3.1.tar.gz (573.1MB)\n","\u001b[K     |████████████████████████████████| 573.1MB 1.3MB/s \n","\u001b[?25hRequirement already satisfied: spacy<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from es_core_news_lg==2.3.1) (2.3.2)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (1.0.5)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (2.0.5)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (1.0.0)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (1.1.3)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (4.41.1)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (3.0.5)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (1.0.5)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (0.8.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (2.23.0)\n","Requirement already satisfied: thinc==7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (7.4.1)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (1.19.5)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (0.4.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (51.1.1)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (3.3.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (3.0.4)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (3.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->es_core_news_lg==2.3.1) (3.7.4.3)\n","Building wheels for collected packages: es-core-news-lg\n","  Building wheel for es-core-news-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for es-core-news-lg: filename=es_core_news_lg-2.3.1-cp36-none-any.whl size=573139082 sha256=26d12f0297d24be4bb79b634a38aef889071450ba872623c615b7ef64c49edf7\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-8s6e9c42/wheels/48/59/33/558e7f48e924c6cac0cbd3679ee7c84f5ae02964c335232e5a\n","Successfully built es-core-news-lg\n","Installing collected packages: es-core-news-lg\n","Successfully installed es-core-news-lg-2.3.1\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('es_core_news_lg')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iH3dg-EV3JMY"},"source":["<span style=\"color:red\"><strong>WARNING!</strong></span> Once you installed the packages in the previous cell you must restart your runtime and then import the library and load the model"]},{"cell_type":"code","metadata":{"id":"i1eWkGLcx_yi","executionInfo":{"status":"ok","timestamp":1610711781405,"user_tz":-60,"elapsed":11694,"user":{"displayName":"Jordi Planas","photoUrl":"","userId":"02408961736589621402"}}},"source":["import spacy\n","spacy.prefer_gpu()\n","es_nlp = spacy.load('es_core_news_lg')"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EFkH4jX4MMZX"},"source":["For development work, in case you want to update the files in your GitHub branch by rerunning the clone, you first have to empty the folder."]},{"cell_type":"code","metadata":{"id":"TVeFAuzRLxy8"},"source":["!rm -rf policy-data-analyzer/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ykyZ81KN7tfr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610711795202,"user_tz":-60,"elapsed":10254,"user":{"displayName":"Jordi Planas","photoUrl":"","userId":"02408961736589621402"}},"outputId":"cc796173-658a-4aa6-ab61-fd9b71d97553"},"source":["# Define branch to clone\n","! branch_name='#50_dfq_sbert_fine_tuning' && \\\n","  git clone --branch $branch_name https://github.com/wri-dssg/policy-data-analyzer.git"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Cloning into 'policy-data-analyzer'...\n","remote: Enumerating objects: 425, done.\u001b[K\n","remote: Counting objects: 100% (425/425), done.\u001b[K\n","remote: Compressing objects: 100% (263/263), done.\u001b[K\n","remote: Total 2827 (delta 261), reused 306 (delta 161), pack-reused 2402\u001b[K\n","Receiving objects: 100% (2827/2827), 126.64 MiB | 28.98 MiB/s, done.\n","Resolving deltas: 100% (1419/1419), done.\n","Checking out files: 100% (843/843), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"R4UNMkgIvDXl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610711843409,"user_tz":-60,"elapsed":41326,"user":{"displayName":"Jordi Planas","photoUrl":"","userId":"02408961736589621402"}},"outputId":"0a72b302-dabb-4904-f7f1-c1181ca42f00"},"source":["import pandas as pd\n","import sys\n","import os\n","from sklearn.model_selection import train_test_split\n","from sentence_transformers import SentencesDataset, SentenceTransformer, InputExample, losses\n","from sentence_transformers.evaluation import LabelAccuracyEvaluator\n","from torch import nn, Tensor\n","from typing import Iterable, Dict\n","from torch.utils.data import DataLoader\n","import math\n","\n","os.chdir(\"policy-data-analyzer\") #If you run this cell more than once, comment out this line because you are ready in this folder and you will get an error\n","from tasks.data_loader.src.utils import *\n","from tasks.data_augmentation.src.zero_shot_classification.latent_embeddings_classifier import *\n","from tasks.evaluate_model.src.model_evaluator import *\n","from tasks.data_visualization.src.plotting import *\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"P4l8oGqlvDXs"},"source":["## Fine-tuning the embedding model on the labeled data"]},{"cell_type":"markdown","metadata":{"id":"8KxOPUcovDXu"},"source":["### Something we can try out:\n","https://www.sbert.net/examples/training/data_augmentation/README.html#extend-to-your-own-datasets\n","\n","### Links:\n","https://github.com/UKPLab/sentence-transformers/issues/350\n","\n","https://omoindrot.github.io/triplet-loss"]},{"cell_type":"markdown","metadata":{"id":"_chNEXckvDXu"},"source":["### Possible tasks for fine-tuning:\n","1) Given a pair of sentence embeddings, do they belong to the same category (binary)?\n","\n","2) Given a sentence and a category embedding, does the sentence belong to the category (binary)?\n","\n","3) Given a sentence embedding, use a classifier to predict its category (multiclass) [https://github.com/UKPLab/sentence-transformers/blob/master/examples/training/nli/training_nli.py](https://github.com/UKPLab/sentence-transformers/blob/master/examples/training/nli/training_nli.py)\n","\n","4) Use a triplet loss approach such that sentences (texts) that have the same labels will become close in vector space, while sentences with a different label will be further away [https://github.com/UKPLab/sentencetransformers/blob/master/examples/training/other/training_batch_hard_trec_continue_training.py](https://github.com/UKPLab/sentencetransformers/blob/master/examples/training/other/training_batch_hard_trec_continue_training.py)\n","   \n","#### In this notebook **task number 3** is used to fine-tune the model."]},{"cell_type":"code","metadata":{"id":"lEhL0mw8vDXv"},"source":["# Train test split stratified\n","X_train, X_test, y_train, y_test = train_test_split(all_sents, all_labels, test_size=0.15, stratify=all_labels, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"swPfKIanvDXv"},"source":["# Define model to fine-tune\n","model = SentenceTransformer('stsb-xlm-r-multilingual')\n","# model = SentenceTransformer('xlm-r-100langs-bert-base-nli-stsb-mean-tokens')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YZ5dP4S8vDXw"},"source":["class SoftmaxClassifier(nn.Module):\n","    \"\"\"\n","    This loss adds a softmax classifier on top of the output of the transformer network. \n","    It takes a sentence embedding and learns a mapping between it and the corresponding category.\n","    :param model: SentenceTransformer model\n","    :param sentence_embedding_dimension: Dimension of your sentence embeddings\n","    :param num_labels: Number of different labels\n","    \"\"\"\n","    def __init__(self,\n","                 model: SentenceTransformer,\n","                 sentence_embedding_dimension: int,\n","                 num_labels: int):\n","        super(SoftmaxClassifier, self).__init__()\n","        self.model = model\n","        self.num_labels = num_labels\n","        self.classifier = nn.Linear(sentence_embedding_dimension, num_labels)\n","\n","    def forward(self, sentence_features: Iterable[Dict[str, Tensor]], labels: Tensor):\n","        # Get batch sentence embeddings\n","        features = self.model(sentence_features[0])['sentence_embedding']\n","        \n","        # Get batch loss\n","        output = self.classifier(features)\n","        loss_fct = nn.CrossEntropyLoss()\n","\n","        if labels is not None:\n","            loss = loss_fct(output, labels.view(-1))\n","            return loss\n","        else:\n","            return features, output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XWsN0NMTvDXx"},"source":["# Load data samples into batches\n","train_batch_size = 16\n","label2int = dict(zip(label_names, range(len(label_names))))\n","train_samples = []\n","for sent, label in zip(X_train, y_train):\n","    label_id = label2int[label]\n","    train_samples.append(InputExample(texts=[sent], label=label_id))\n","train_dataset = SentencesDataset(train_samples, model=model)\n","train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n","\n","# Define the way the loss is computed\n","classifier = SoftmaxClassifier(model=model, sentence_embedding_dimension=model.get_sentence_embedding_dimension(), num_labels=len(label2int))\n","\n","# Configure the dev set evaluator - still need to test whether this works\n","dev_samples = []\n","for sent, label in zip(X_test, y_test):\n","    label_id = label2int[label]\n","    dev_samples.append(InputExample(texts=[sent], label=label_id))\n","dev_dataset = SentencesDataset(dev_samples, model=model)\n","dev_dataloader = DataLoader(dev_dataset, shuffle=True, batch_size=train_batch_size)\n","dev_evaluator = LabelAccuracyEvaluator(dataloader=dev_dataloader, softmax_model=classifier, name='lae-dev')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wog9dImLvDXy"},"source":["# Configure the training\n","num_epochs = 1\n","warmup_steps = math.ceil(len(train_dataset) * num_epochs / train_batch_size * 0.1)  # 10% of train data for warm-up\n","model_save_path = \"../../output/FineTuning\"\n","# model_save_path = \"/content/drive/MyDrive/WRI-LatinAmerica-Talent/Modeling/FineTuning\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"awzBPX5IvDXz"},"source":["# Train the model\n","model.fit(train_objectives=[(train_dataloader, classifier)],\n","          evaluator=dev_evaluator,\n","          epochs=num_epochs,\n","          evaluation_steps=1000,\n","          warmup_steps=warmup_steps,\n","          output_path=model_save_path\n","          )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fVsBh96ivDX0"},"source":["# Load the saved model and obtain random sentence embedding\n","load_model = SentenceTransformer(model_save_path)\n","load_model.encode(all_sents[0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ot37jC2mxuGK"},"source":["## Run fine tuning experiments"]},{"cell_type":"code","metadata":{"id":"6WhMprt8l6PO","executionInfo":{"status":"ok","timestamp":1610711844062,"user_tz":-60,"elapsed":650,"user":{"displayName":"Jordi Planas","photoUrl":"","userId":"02408961736589621402"}}},"source":["class SoftmaxClassifier(nn.Module):\n","    \"\"\"\n","    This loss adds a softmax classifier on top of the output of the transformer network. \n","    It takes a sentence embedding and learns a mapping between it and the corresponding category.\n","    :param model: SentenceTransformer model\n","    :param sentence_embedding_dimension: Dimension of your sentence embeddings\n","    :param num_labels: Number of different labels\n","    \"\"\"\n","    def __init__(self,\n","                 model: SentenceTransformer,\n","                 sentence_embedding_dimension: int,\n","                 num_labels: int):\n","        super(SoftmaxClassifier, self).__init__()\n","        self.model = model\n","        self.num_labels = num_labels\n","        self.classifier = nn.Linear(sentence_embedding_dimension, num_labels)\n","\n","    def forward(self, sentence_features: Iterable[Dict[str, Tensor]], labels: Tensor):\n","        # Get batch sentence embeddings\n","        features = self.model(sentence_features[0])['sentence_embedding']\n","        \n","        # Get batch loss\n","        output = self.classifier(features)\n","        loss_fct = nn.CrossEntropyLoss()\n","\n","        if labels is not None:\n","            loss = loss_fct(output, labels.view(-1))\n","            return loss\n","        else:\n","            return features, output"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"86SvEGSAHRp7"},"source":["<span style=\"color:red\"><strong>WARNING!</strong></span> Reading from Excel.  This path is deprecated. The two cells below should not be run from this version on"]},{"cell_type":"code","metadata":{"id":"F75W2lmqxtSX"},"source":["# Reading data from excel\n","data_excel = pd.read_excel(\"/content/drive/MyDrive/WRI-LatinAmerica-Talent/Cristina_Policy_Files/WRI_Policy_Tags.xlsx\", engine=\"openpyxl\", sheet_name=None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dIhBjg01x3z0"},"source":["# Formatting the data\n","all_labeled_sentences = country_labeled_sentences(data_excel)\n","labeled_sents = dict()\n","for sents in all_labeled_sentences.values():\n","    labeled_sents.update(sents)\n","\n","# Fitlering out General Incentive and Unknown sentences\n","filtered_sents_maps = [sent for sent in labeled_sents.values() if sent['labels'][0] not in [\"General incentive\", \"Unknown\", \"Other\"]]\n","all_sents = [sent['text'] for sent in filtered_sents_maps]\n","all_labels = [sent['labels'][0] for sent in filtered_sents_maps]\n","all_labels = merge_labels(all_labels, [\"Credit\", \"Guarantee\"])\n","label_names = list(set(all_labels))\n","numeric_labels = labels2numeric(all_labels, label_names)\n","label_names"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KHLfOdQXnUhn"},"source":["Reading files from JSON"]},{"cell_type":"code","metadata":{"id":"sSVbw0YjHibv","executionInfo":{"status":"ok","timestamp":1610711870441,"user_tz":-60,"elapsed":647,"user":{"displayName":"Jordi Planas","photoUrl":"","userId":"02408961736589621402"}}},"source":["# This is the dictionary used to transform policy instrument labels into numeric codes. BEWARE that we have a new category which is 0. This new category might represent unknown incentive or no incentive!!!\n","policy_dict = {'Credit' : 'Credit',\n"," 'Direct' : 'Direct payment',\n"," 'Fine' : 'Fine',\n"," 'General' : 'Unknown', \n"," 'Guarantee' : 'Credit', \n"," 'Supplies' : 'Supplies', \n"," 'Tax' : 'Tax deduction', \n"," 'Technical' : 'Technical assistance', \n"," 'Unknown' : 'Unknown', \n"," 'Other' : 'Unknown', \n"," 'Nan' : 'Unknown' }\n"," \n","Three_most_common = ['Credit', 'Direct payment', 'Fine']\n","All_but_unknown = ['Credit', 'Direct payment', 'Fine', 'Supplies', 'Tax deduction', 'Technical assistance']\n","All = ['Credit', 'Direct payment', 'Fine', 'Supplies', 'Tax deduction', 'Technical assistance', 'Unknown']\n","\n","# This is the dictionary used to transform is_incentive labels into numeric codes.\n","incentive_dict = {'Incentive' : 'Incentive', \n","'Disincentive' : 'Incentive', \n","'Unknown' : 'not_Incentive', \n","'Nan' : 'not_Incentive'}"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"fdD2Da9fnRqb","executionInfo":{"status":"ok","timestamp":1610711882406,"user_tz":-60,"elapsed":2335,"user":{"displayName":"Jordi Planas","photoUrl":"","userId":"02408961736589621402"}}},"source":["#THIS IS THE PREFERRED PATH\n","# If the json is in the format that includes headers and other titles:\n","#TODO: Adapt/choose the path according to your system configuration\n","\n","rater = \"Rater2\" # TODO: Change accordingly to what is the dataset you want to analyze\n","\n","# dataset_fname = \"C:/Users/user/Google Drive/Els_meus_documents/projectes/CompetitiveIntelligence/WRI/Notebooks/Data/Final_input_data\"\n","# dataset_fname = \"/content/drive/MyDrive/WRI-LatinAmerica-Talent/Cristina_Policy_Files/Tagged_sentence_lists/Rater_3_labeled.json\"\n","dataset_fname = \"/content/drive/MyDrive/Official Folder of WRI Latin America Project/WRI-LatinAmerica-Talent/Cristina_Policy_Files/Tagged_sentence_lists/{}_labeled.json\".format(rater)\n","\n","dataset = load_file(dataset_fname)\n","dataset_map = labeled_sentences_from_dataset(dataset) # Labels AND sentences\n","dataset_map_target_labels =  select_labels(dataset_map, All_but_unknown) # Adjust to the labels you want to use for your analysis. In the cell above you have three pre-defined sets.\n","all_sents = sentences_from_dataset(dataset) # Just sentences\n","all_labels = labels_from_dataset(dataset, \"labels\") # Just labels. Use \"labels\" if you want to retrieve policy instrument tags\n","                                                    # Use \"incentive\" if you want to retrieve is_incentive tags."],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"HshsYQTYDDc3","colab":{"base_uri":"https://localhost:8080/","height":231},"executionInfo":{"status":"error","timestamp":1610711598562,"user_tz":-60,"elapsed":1159,"user":{"displayName":"Jordi Planas","photoUrl":"","userId":"02408961736589621402"}},"outputId":"d11d1ec8-bb4e-458e-b503-e5b7deed5fed"},"source":["# If the json is in the format where it only contains sentences and labels\n","#TODO: Adapt/choose the path according to your system configuration\n","\n","rater = \"Rater2\" # TODO: Change accordingly to what is the dataset you want to analyze\n","\n","dataset_fname = \"/content/drive/MyDrive/Official Folder of WRI Latin America Project/WRI-LatinAmerica-Talent/Cristina_Policy_Files/Tagged_sentence_lists/{}_labeled_sentences.json\".format(rater)\n","dataset_fname = \"/content/drive/MyDrive/WRI-LatinAmerica-Talent/Cristina_Policy_Files/Tagged_sentence_lists/Rater_3_labeled_sentences.json\"\n","\n","\n","dataset = load_file(dataset_fname) \n","dataset_map = labels_from_model_output(dataset) # Labels AND sentences\n","all_sents = sentences_from_model_output(dataset) # Just sentences\n","all_labels = labels_from_model_output(dataset, \"labels\") # Just labels. Use \"labels\" if you want to retrieve policy instrument tags\n","                                                    # Use \"incentive\" if you want to retrieve is_incentive tags."],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-451cc09ec261>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mdataset_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels_from_model_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Labels AND sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mall_sents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentences_from_model_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Just sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'load_file' is not defined"]}]},{"cell_type":"code","metadata":{"id":"tasMxprPDgfU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610711892964,"user_tz":-60,"elapsed":644,"user":{"displayName":"Jordi Planas","photoUrl":"","userId":"02408961736589621402"}},"outputId":"9918cb9b-c912-4834-9cbc-8b72fb4b43d1"},"source":["# The rest:\n","label_names = unique_labels(all_labels)\n","numeric_labels = labels2numeric(all_labels, label_names)\n","label_names"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Technical assistance',\n"," 'Direct payment',\n"," 'Supplies',\n"," 'Credit',\n"," 'Tax deduction',\n"," 'Unknown',\n"," 'Fine']"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"1sNGrOvI2zF0","executionInfo":{"status":"ok","timestamp":1610711898685,"user_tz":-60,"elapsed":651,"user":{"displayName":"Jordi Planas","photoUrl":"","userId":"02408961736589621402"}}},"source":["import time\n","import cupy"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pssz_1ZzOEPY"},"source":["def least_squares_with_reg(X, y, lamda=0.01):\r\n","    # Help from: https://stackoverflow.com/questions/27476933/numpy-linear-regression-with-regularization and https://www.kdnuggets.com/2016/11/linear-regression-least-squares-matrix-multiplication-concise-technical-overview.html\r\n","    # Multiple Linear Regression with OLS parameter estimation with L2 regularization term. lambda = 0 is equivalent to OLS estimation without regularization\r\n","    print(\"** X shape:\", X.shape, \"-- X shape[1]\", X.shape[1], \" -- y shape:\", y.shape)\r\n","    print(\"** np.eye:\", np.eye(X.shape[1]))\r\n","    print(\"** np.linalg: \", np.linalg.inv(X.T.dot(X) + lamda * np.eye(X.shape[1])))\r\n","    print(\"**dimensions of XT:\", (X.T).shape)\r\n","    print(\"**dimensions of y:\", y.shape)\r\n","    print(\"** dimensions of np.lialg:\", (np.linalg.inv(X.T.dot(X) + lamda * np.eye(X.shape[1])).dot(X.T)).shape)\r\n","    print(\"** dot(X.T)\", (X.T).dot(y))\r\n","    return np.linalg.inv(X.T.dot(X) + lamda * np.eye(X.shape[1])).dot(X.T).dot(y)\r\n","\r\n","\r\n","def calc_proj_matrix(sentences, k, spacy_model, sbert_model, lamda=0.01, include_labels=None):\r\n","    sents_as_str = \". \".join(sentences)\r\n","    top_words = top_k_words(k, sents_as_str, spacy_model, include_labels)\r\n","    word_emb = np.vstack(top_k_word_embeddings(top_words, spacy_model))\r\n","    sent_emb = np.vstack(top_k_sbert_embeddings(top_words, sbert_model))\r\n","    proj_matrix = least_squares_with_reg(sent_emb, word_emb, lamda)\r\n","\r\n","    return proj_matrix"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l9ycZoZ5yU0d","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["77416ef1b857412fa8672423085fd6ef","8179bee0272043da88a2875621ff32fb","91a50a07cd454f23915953f36246ceee","9d1e224c18354831bfa64a8e351168c0","0caae83d9c7141409da5854c88666975","c73c1ce1249d4bc1a02c3f26993332a3","8ce9a10a5aa84201951fc9c3bbd21a9d","7310c5b2f5bf4533bc683f613a6045bf","2c4d53ec4f48481f98417f8cbd0ab272","af603f4600204e6ba06e985c2b36dd29","e0d19f17e45d411b834152ecdadf481d","a1034ed7832944d38c8909a5ae5e0792","04a7b8b0cdd9436885cb70798c2d0dce","9be6bea6302c4734b8a5677ce17ceb86","8691e8ca35ee41eaa1cfaf488bba9e85","8645596491e7407c96959a67997d010c","1deb6dd36c2e46ac826cc02f6302d18a","3f0536cf46ad45b0a9584fd39b9dbef6","e42f8a4c3f364cbc9c7cd4388db535d7","ba9167b6660540cfa78ec809c95f4b1d","f3a4a6d2ee224bfb8b57f8be405d6c4d","5fc403b9becb443584635d70a42cc5ed","b13b5be85d3b4c9f82b0b463f02636ce","05e466cd25cb4316b695c94515cd318f"]},"executionInfo":{"status":"error","timestamp":1610712001170,"user_tz":-60,"elapsed":96411,"user":{"displayName":"Jordi Planas","photoUrl":"","userId":"02408961736589621402"}},"outputId":"c6c71e71-00bf-46c0-d97a-6a7be533c07d"},"source":["model_names = ['distiluse-base-multilingual-cased-v2', 'stsb-xlm-r-multilingual', 'paraphrase-xlm-r-multilingual-v1', 'quora-distilbert-multilingual']\n","\n","# Train test split stratified\n","all_test_perc = [0.15, 0.2, 0.25, 0.3]\n","\n","# Output setup\n","output = {}\n","\n","for test_perc in all_test_perc:\n","  output[f\"test_perc={test_perc}\"] = {}\n","  X_train, X_test, y_train, y_test = train_test_split(all_sents, all_labels, test_size=test_perc, stratify=all_labels, random_state=69420)\n","\n","  # Load data samples into batches\n","  train_batch_size = 16\n","  label2int = dict(zip(label_names, range(len(label_names))))\n","  train_samples = []\n","  for sent, label in zip(X_train, y_train):\n","      label_id = label2int[label]\n","      train_samples.append(InputExample(texts=[sent], label=label_id))\n","\n","  # Configure the dev set evaluator - still need to test whether this works\n","  dev_samples = []\n","  for sent, label in zip(X_test, y_test):\n","      label_id = label2int[label]\n","      dev_samples.append(InputExample(texts=[sent], label=label_id))\n","  \n","  for model_name in model_names:\n","    # Setup\n","    model_preds = []\n","    model_scores = []\n","    output[f\"test_perc={test_perc}\"][model_name] = []\n","    \n","    # Train set config\n","    model = SentenceTransformer(model_name)\n","    train_dataset = SentencesDataset(train_samples, model=model)\n","    train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n","    \n","    # Define the way the loss is computed\n","    classifier = SoftmaxClassifier(model=model, sentence_embedding_dimension=model.get_sentence_embedding_dimension(), num_labels=len(label2int))\n","    \n","    # Dev set config\n","    dev_dataset = SentencesDataset(dev_samples, model=model)\n","    dev_dataloader = DataLoader(dev_dataset, shuffle=True, batch_size=train_batch_size)\n","    dev_evaluator = LabelAccuracyEvaluator(dataloader=dev_dataloader, softmax_model=classifier, name='lae-dev')\n","\n","    # Configure the training\n","    max_num_epochs = 10\n","        \n","    for num_epochs in range(1, max_num_epochs + 2, 2):\n","        print(\"Num epochs:\", num_epochs)\n","        \n","        warmup_steps = math.ceil(len(train_dataset) * num_epochs / train_batch_size * 0.1)  # 10% of train data for warm-up\n","        model_deets = f\"model={model_name}_test-perc={test_perc}_n-epoch={num_epochs}\"\n","        model_save_path = f\"/content/drive/MyDrive/WRI-LatinAmerica-Talent/Modeling/Exp2/FineTuning_{model_deets}\"\n","        \n","\n","        # Train the model\n","        start = time.time()\n","        model.fit(train_objectives=[(train_dataloader, classifier)],\n","                  evaluator=dev_evaluator,\n","                  epochs=2, # We always tune on an extra epoch to see the performance gain\n","                  evaluation_steps=1000,\n","                  warmup_steps=warmup_steps,\n","                  output_path=model_save_path\n","                  )\n","        \n","        end = time.time()\n","        hours, rem = divmod(end-start, 3600)\n","        minutes, seconds = divmod(rem, 60)\n","        print(\"Time taken for fine-tuning:\", \"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n","        \n","        ### Classify sentences\n","        # Projection matrix Z low-dim projection\n","        print(\"Classifying sentences...\")\n","        proj_matrix = cupy.asnumpy(calc_proj_matrix(all_sents, 50, es_nlp, model, 0.01))\n","        all_sent_embs = encode_all_sents(all_sents, model, proj_matrix)\n","        all_label_embs = encode_labels(label_names, model, proj_matrix)\n","        visualize_embeddings_2D(np.vstack(all_sent_embs), all_labels, tsne_perplexity=50, store_name=f\"{model_save_path}/{model_deets}\")\n","        model_preds, model_scores = calc_all_cos_similarity(all_sent_embs, all_label_embs, label_names)\n","        \n","        ### Evaluate the model\n","        numeric_preds = labels2numeric(model_preds, label_names)\n","        evaluator = ModelEvaluator(label_names, y_true=numeric_labels, y_pred=numeric_preds)\n","        \n","        output[f\"test_perc={test_perc}\"][model_name].append({\"num_epochs\": num_epochs, \"avg_f1\": evaluator.avg_f1.tolist()})\n","        \n","        evaluator.plot_confusion_matrix(color_map='Blues', exp_name=f\"{model_save_path}/{model_deets}\")"],"execution_count":10,"outputs":[{"output_type":"stream","text":["100%|██████████| 504M/504M [00:17<00:00, 28.7MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Num epochs: 1\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"77416ef1b857412fa8672423085fd6ef","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Epoch', max=2.0, style=ProgressStyle(description_width='i…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2c4d53ec4f48481f98417f8cbd0ab272","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Iteration', max=77.0, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Evaluating:   0%|          | 0/14 [00:00<?, ?it/s]\u001b[A\n","Evaluating:  14%|█▍        | 2/14 [00:00<00:00, 14.78it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Evaluating:  29%|██▊       | 4/14 [00:00<00:00, 14.72it/s]\u001b[A\n","Evaluating:  43%|████▎     | 6/14 [00:00<00:00, 15.95it/s]\u001b[A\n","Evaluating:  57%|█████▋    | 8/14 [00:00<00:00, 16.46it/s]\u001b[A\n","Evaluating:  71%|███████▏  | 10/14 [00:00<00:00, 16.66it/s]\u001b[A\n","Evaluating: 100%|██████████| 14/14 [00:00<00:00, 16.97it/s]\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1deb6dd36c2e46ac826cc02f6302d18a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Iteration', max=77.0, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Evaluating:   0%|          | 0/14 [00:00<?, ?it/s]\u001b[A\n","Evaluating:  14%|█▍        | 2/14 [00:00<00:00, 14.94it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Evaluating:  29%|██▊       | 4/14 [00:00<00:00, 15.26it/s]\u001b[A\n","Evaluating:  43%|████▎     | 6/14 [00:00<00:00, 15.01it/s]\u001b[A\n","Evaluating:  57%|█████▋    | 8/14 [00:00<00:00, 14.90it/s]\u001b[A\n","Evaluating:  71%|███████▏  | 10/14 [00:00<00:00, 15.22it/s]\u001b[A\n","Evaluating: 100%|██████████| 14/14 [00:00<00:00, 17.09it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Time taken for fine-tuning: 00:00:48.65\n","Classifying sentences...\n"],"name":"stdout"},{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-4f29b3e760d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# Projection matrix Z low-dim projection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Classifying sentences...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mproj_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcupy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc_proj_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_sents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mes_nlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mall_sent_embs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_all_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_sents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproj_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mall_label_embs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproj_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/policy-data-analyzer/tasks/data_augmentation/src/zero_shot_classification/latent_embeddings_classifier.py\u001b[0m in \u001b[0;36mcalc_proj_matrix\u001b[0;34m(sentences, k, spacy_model, sbert_model, lamda, include_labels)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mword_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_k_word_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspacy_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0msent_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_k_sbert_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msbert_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mproj_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleast_squares_with_reg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mproj_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/policy-data-analyzer/tasks/data_augmentation/src/zero_shot_classification/latent_embeddings_classifier.py\u001b[0m in \u001b[0;36mleast_squares_with_reg\u001b[0;34m(X, y, lamda)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# Help from: https://stackoverflow.com/questions/27476933/numpy-linear-regression-with-regularization and https://www.kdnuggets.com/2016/11/linear-regression-least-squares-matrix-multiplication-concise-technical-overview.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# Multiple Linear Regression with OLS parameter estimation with L2 regularization term. lambda = 0 is equivalent to OLS estimation without regularization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlamda\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mcupy/core/core.pyx\u001b[0m in \u001b[0;36mcupy.core.core.ndarray.__array__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mcupy/core/core.pyx\u001b[0m in \u001b[0;36mcupy.core.core.ndarray.astype\u001b[0;34m()\u001b[0m\n","\u001b[0;32mcupy/core/_kernel.pyx\u001b[0m in \u001b[0;36mcupy.core._kernel.ufunc.__call__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mcupy/core/_kernel.pyx\u001b[0m in \u001b[0;36mcupy.core._kernel.ufunc._get_ufunc_kernel\u001b[0;34m()\u001b[0m\n","\u001b[0;32mcupy/core/_kernel.pyx\u001b[0m in \u001b[0;36mcupy.core._kernel._get_ufunc_kernel\u001b[0;34m()\u001b[0m\n","\u001b[0;32mcupy/core/_kernel.pyx\u001b[0m in \u001b[0;36mcupy.core._kernel._get_kernel_params\u001b[0;34m()\u001b[0m\n","\u001b[0;32mcupy/core/_scalar.pyx\u001b[0m in \u001b[0;36mcupy.core._scalar.get_typename\u001b[0;34m()\u001b[0m\n","\u001b[0;32mcupy/core/_scalar.pyx\u001b[0m in \u001b[0;36mcupy.core._scalar.get_typename\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: <class 'numpy.object_'>"]}]},{"cell_type":"code","metadata":{"id":"Qxpumbs3ABkz"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IyJSG6SIaECl","outputId":"6719cb8c-1aec-412d-ed84-7e117d925000"},"source":["output.keys()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['distiluse-base-multilingual-cased-v2', 'stsb-xlm-r-multilingual', 'paraphrase-xlm-r-multilingual-v1', 'quora-distilbert-multilingual'])"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"code","metadata":{"id":"e65BceczaDwI"},"source":["new_json = {}\n","\n","for key in output.keys():\n","  new_json[key] = {}\n","  for subkey in output[key].keys():\n","    new_json[key][subkey] = []\n","    for element in output[key][subkey]:\n","      el_copy = {\"avg_f1\": element[\"avg_f1\"].tolist(), \"num_epochs\": element[\"num_epochs\"]}\n","      new_json[key][subkey].append(el_copy)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"40gn7pZUHO4c"},"source":["import json\n","with open(\"/content/drive/MyDrive/WRI-LatinAmerica-Talent/Modeling/FineTuningResults.json\", \"w\") as f:\n","  json.dump(new_json, f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uwxoji8ka-7N"},"source":[""],"execution_count":null,"outputs":[]}]}