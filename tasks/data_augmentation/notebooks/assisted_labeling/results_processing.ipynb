{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "changing-europe",
   "metadata": {},
   "source": [
    "# Processing the results of assited labeling\n",
    "\n",
    "The assited labeling notebook yields several csv files one for each query. As the process have been parallelized, we have as many copies as threads we have run. So there is the need for merging the results in one single excel file per policy instrument.\n",
    "\n",
    "TODO: this code is highly inefficient for large amount of data, probably due to the way the file is open and handled. Better alternatives should be worked out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-blink",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import codecs\n",
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "from openpyxl import load_workbook\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-dating",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mighty-deployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aws_credentials(path, filename):\n",
    "    file = path + filename\n",
    "    with open(file, 'r') as dict:\n",
    "        key_dict = json.load(dict)\n",
    "    for key in key_dict:\n",
    "        KEY = key\n",
    "        SECRET = key_dict[key]\n",
    "    return KEY, SECRET\n",
    "\n",
    "def read_csv_from_s3(s3_object, columns):\n",
    "    pre_labeled = []\n",
    "    try:\n",
    "        for i, row in enumerate(csv.DictReader(codecs.getreader(\"utf-8\")(s3_object.get()['Body']))):\n",
    "            list_row = []\n",
    "            for column in columns:\n",
    "                list_row.append(row[column])\n",
    "            list_row.insert(0, i)\n",
    "            pre_labeled.append(list_row)\n",
    "    except:\n",
    "        print(f\"Problem with the file {obj.key}\")\n",
    "        pass\n",
    "    return pre_labeled\n",
    "\n",
    "def export_list_as_excel(file, list_to_save, name_of_sheet):\n",
    "    df = pd.DataFrame(list_to_save)\n",
    "    book = load_workbook(file)\n",
    "    writer = pd.ExcelWriter(file, engine='openpyxl', mode = \"a\")\n",
    "    writer.book = book\n",
    "    writer.sheets = {ws.title: ws for ws in book.worksheets}\n",
    "    print(name_of_sheet)\n",
    "    if name_of_sheet not in writer.sheets:\n",
    "        df.to_excel(writer, sheet_name = name_of_sheet, index=False, header=False)\n",
    "    else:\n",
    "        df.to_excel(writer, sheet_name = name_of_sheet, startrow=writer.sheets[name_of_sheet].max_row, index=False, header=False)\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-mercy",
   "metadata": {},
   "source": [
    "## Connecting to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-cancer",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/jordi/Documents/claus/\"\n",
    "# path = \"/home/propietari/Documents/claus/\"\n",
    "filename = \"AWS_S3_keys_wri.json\"\n",
    "aws_id, aws_secret = aws_credentials(path, filename)\n",
    "region = 'us-east-1'\n",
    "\n",
    "bucket = 'wri-nlp-policy'\n",
    "\n",
    "s3 = boto3.resource(\n",
    "    service_name = 's3',\n",
    "    region_name = region,\n",
    "    aws_access_key_id = aws_id,\n",
    "    aws_secret_access_key = aws_secret\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "massive-bosnia",
   "metadata": {},
   "source": [
    "## Loading the policy instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-arctic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define queries\n",
    "path = \"../../input/\"\n",
    "filename = \"English_queries.xlsx\"\n",
    "file = path + filename\n",
    "df = pd.read_excel(file, engine='openpyxl', sheet_name = \"Hoja1\", usecols = \"A:C\")\n",
    "\n",
    "policy_intrument = {}\n",
    "for index, row in df.iterrows():\n",
    "    policy_intrument[row['Policy instrument']] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deluxe-spokesman",
   "metadata": {},
   "source": [
    "## Loading csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-blank",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../output/\"\n",
    "filename = \"pre_labeled_English.xlsx\"\n",
    "file = path + filename\n",
    "\n",
    "columns = [\"sentence_id\", \"similarity_score\", \"text\"]\n",
    "for i, obj in enumerate(s3.Bucket(bucket).objects.all().filter(Prefix=\"english_documents/assisted_labeling/\")):\n",
    "    if not obj.key.endswith(\"/\"):# and i < 3:\n",
    "        for item in policy_intrument:\n",
    "            if item in obj.key:\n",
    "                export_list_as_excel(file, read_csv_from_s3(obj, columns), item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-chorus",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "261.997px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
