{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "632cbf7f",
   "metadata": {},
   "source": [
    "# EDA for the HSSC paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e6706c",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Table-of-Questions\" data-toc-modified-id=\"Table-of-Questions-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Table of Questions</a></span></li><li><span><a href=\"#Library-imports\" data-toc-modified-id=\"Library-imports-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Library imports</a></span></li><li><span><a href=\"#Data-imports\" data-toc-modified-id=\"Data-imports-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data imports</a></span></li><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Functions</a></span></li><li><span><a href=\"#Data-tranformations\" data-toc-modified-id=\"Data-tranformations-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Data tranformations</a></span><ul class=\"toc-item\"><li><span><a href=\"#Date-from-string-to-date-format\" data-toc-modified-id=\"Date-from-string-to-date-format-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Date from string to date-format</a></span></li></ul></li><li><span><a href=\"#Analysis\" data-toc-modified-id=\"Analysis-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Analysis</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sentence-length\" data-toc-modified-id=\"Sentence-length-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Sentence length</a></span></li><li><span><a href=\"#Number-of-incentives\" data-toc-modified-id=\"Number-of-incentives-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Number of incentives</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571eb250",
   "metadata": {},
   "source": [
    "## Table of Questions\n",
    "[Sentence length](#Sentence-length)\n",
    "  * Is there any pattern in the distribution of sentence length?\n",
    "  * Is there any insight that we can draw from the analysis of the distribution of sentence length in relation with the sentence splitting process?\n",
    "  \n",
    "[Number of incentives](#Number-of-incentives)  \n",
    "  * What is the absolute number of incentives?\n",
    "  * What is the ratio of documents with incentives?\n",
    "  * What is the average number of incentives per document?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d4f098",
   "metadata": {},
   "source": [
    "## Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c10619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from datetime import datetime as dt\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74b20e4",
   "metadata": {},
   "source": [
    "## Data imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794d89d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names of the columns in the database\n",
    "col_names = [\"id\", \"country\", \"pub lication_source\", \"issuing_institution\", \"doc_type\", \"date\", \"doc_title\", \"summary\",\n",
    "            \"url\", \"num_sents\", \"min_sent_len\", \"max_sent_len\", \"avg_sent_len\", \"num_incentives_sbert\", \"supplies_sbert\",\n",
    "            \"loan_sbert\", \"fine_sbert\", \"direct_payment_sbert\", \"technical_assistance_sbert\", \"tax_benefit_sbert\",\n",
    "            \"num_incentives_bert\", \"supplies_bert\", \"loan_bert\", \"fine_bert\", \"direct_payment_bert\", \"technical_assistance_bert\",\n",
    "            \"tax_benefit_bert\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88ec1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the two csv files and merging them toghether in a single dataframe.\n",
    "in_path = \"../input/\"\n",
    "files = [f\"{in_path}spanish_metadata.csv\", f\"{in_path}english_metadata.csv\"]\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for filename in files:\n",
    "    df_temp = pd.read_csv(filename, index_col=None, header=None)\n",
    "    dfs.append(df_temp)\n",
    "\n",
    "df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "df.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f206737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute it only if yo want to save the contents of the whole database into an excel file\n",
    "out_path = \"../output/\"\n",
    "file_name =  \"metadata.xlsx\"\n",
    "df.to_excel(f\"{out_path}{file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17556cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute it only if you want to visualize the first 5 rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697edc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute it only of you want to ave a summary of the main descriptive statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f260e5b",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b424061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To transform dd/mm/yyyy dates in string format to yyyy/mm/dd or viceversa\n",
    "def reorder_date(string):\n",
    "    elements = string.split(\"/\")\n",
    "    return(f\"{elements[2]}/{elements[1]}/{elements[0]}\")\n",
    "        \n",
    "# To standardize all dates in string format and convert them to datetime format\n",
    "def standardize_date(string):\n",
    "    string = string.replace(\"-\", \"/\").strip()\n",
    "    if re.search(r\"[\\d]{2}/[\\d]{2}/[\\d]{4}\", string):\n",
    "        string = reorder_date(string)\n",
    "    try:\n",
    "        date = dt.strptime(string, '%Y/%m/%d')\n",
    "        return date\n",
    "    except:\n",
    "        print(f\"{string}\")\n",
    "\n",
    "# To calculate the confidence interval of a series of values\n",
    "# The significance values can be only 0.05 or 0.01\n",
    "# The two available methods are \"ci_normal\", \"ci_not_normal\" and \"2xs\"\n",
    "def confidence_interval(significance_value, method, list_of_values):\n",
    "    methods = {\"ci_normal\" : 0, \"ci_not_normal\" : 0, \"2xs\" : 0}\n",
    "    significances = {0.05 : 0, 0.01 : 0}\n",
    "    z_values = {0.05 : 1.92, 0.01 : 2.58}\n",
    "    t_values_n10 = {0.05 : 2.92, 0.01 : 6.96}\n",
    "    t_values_n20 = {0.05 : 2.05, 0.01 : 3.36}\n",
    "    s = np.std(list_of_values)\n",
    "    \n",
    "    if method not in methods:\n",
    "        print(f\"ERROR! The method is not properly spelled or it is not available.\\nPlease select one of: \\\"ci_normal\\\", \\\"ci_not_normal\\\" or \\\"2xs\\\"\")\n",
    "        return\n",
    "    if significance_value not in significances:\n",
    "        print(f\"ERROR! ThThe choosen significance value is not available.\\nPlease select one of: 0.05 or 0.01\")\n",
    "        return\n",
    "    elif method == \"2xs\":\n",
    "        return(2*s)\n",
    "    else:\n",
    "        if method == \"ci_normal\" or len(list_of_values) > 20:\n",
    "            z = z_values[significance_value]\n",
    "        if method == \"ci_not_normal\" and len(list_of_values) <= 20:\n",
    "            if len(list_of_values) <= 10:\n",
    "                z = t_values_n10[significance_value]\n",
    "            elif len(list_of_values) <= 20:\n",
    "                z = t_values_n20[significance_value]\n",
    "        return(s * z / np.sqrt(len(list_of_values)))\n",
    "            \n",
    "            \n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "def bins_labels(bins, **kwargs):\n",
    "    bin_w = (max(bins) - min(bins)) / (len(bins) - 1)\n",
    "    labels = [int(x) for x in bins[1:] - 1]\n",
    "    labels = [int(x) for x in bins[1:]]\n",
    "    plt.xticks(np.arange(min(bins)+bin_w/2, max(bins), bin_w), labels, **kwargs)\n",
    "#     plt.xlim(bins[0], bins[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1e07f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confidence_interval(0.05, \"2xs\", df[\"num_sents\"]))\n",
    "print(confidence_interval(0.05, \"ci_normal\", df[\"num_sents\"]))\n",
    "print(confidence_interval(0.05, \"ci_not_normal\", df[\"num_sents\"]))\n",
    "print(confidence_interval(0.05, \"ci_not_normal\", df[\"num_sents\"][0:10]))\n",
    "print(confidence_interval(0.05, \"ci_not_normal\", df[\"num_sents\"][0:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ee0654",
   "metadata": {},
   "source": [
    "## Data tranformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e210d0bd",
   "metadata": {},
   "source": [
    "### Date from string to date-format\n",
    "The format of the date is not homogeneous on the date column\\\n",
    "The date is of type *string* which is not good for calculations\n",
    "\n",
    "In the next couple of cells we will:\n",
    "* Add a new column with the date in format datetime\n",
    "* Standardize the date column to yyyy-mm-dd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1713ba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inserting a new column called \"date_time\" containing the date as datetime type to easy calculations\n",
    "df.insert(6, \"date_time\", df['date'].map(standardize_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5211ce8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the date values to standardize them in the format yyyy-mm-dd\n",
    "df[\"date\"] = df[\"date_time\"].dt.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a13db9",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "This is the main section, it will be structured in subsections, one for each question that we want to solve using the data.\\\n",
    "We will use it as a common place with private secctions so that nobody modifies the code of anyone else.\\\n",
    "For this, what we are going to do is to share the whole notebook, but assign each of the subsections of section 4 only to one person. So, nobody should modify the code of any section which is not theirs. Of course, we can review other's people code and discuss it but do not modify it.\\\n",
    "We can proceed as follows.\n",
    "1. When you have a new research question, start a new section (level 3 meaning three \"#\").\n",
    "2. Choose a title.\n",
    "3. Put your name under the title.\n",
    "4. State the research question as clearly as you can below your name.\n",
    "\n",
    "See one example in the next cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dde25c",
   "metadata": {},
   "source": [
    "### Sentence length\n",
    "**Jordi Planas**\\\n",
    "* Is there any pattern in the distribution of sentence length?\\\n",
    "* Is there any insight that we can draw from the analysis of the distribution of sentence length in relation with the sentence splitting process?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a61f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_1 = \"num_sents\"\n",
    "var_2 = \"avg_sent_len\"\n",
    "\n",
    "print(f\"The document with most sentences has {df[var_1].max()} sentences\\nThe document with least sentences has {df[var_1].min()} sentences\")\n",
    "print(f\"The document with the largest average sentence length has an average sentence length of {df[var_2].max()} characters\")\n",
    "print(f\"The document with the shortest sentence length has an average sentence length of {df[var_2].min()} characters\")\n",
    "print(f\"There are {len(df[df.num_sents == 0])} documents with 0 sentences\")\n",
    "print(f\"There are {len(df[df.avg_sent_len == 0])} documents with an average sentence length equal to 0\")\n",
    "\n",
    "# As there are 5 documents with 0 sentences, we replace the num_sents value by 1 to avoid zero division\n",
    "# We also replace the all the five values of \"avg_sent_len\" from 0 to 1\n",
    "df[var_1].replace({0 : 1}, inplace = True)\n",
    "df[var_2].replace({0 : 1}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19fb032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of the log-log of number of sentences vs average length of sentence\n",
    "# Sorting is needed when later we want to plat the area between the confidence intervals\n",
    "sorted_df = df.sort_values(var_1)\n",
    "x = np.log10(sorted_df[var_1])\n",
    "y = np.log10(sorted_df[var_2])\n",
    "plt.scatter(x, y , c='DarkBlue')\n",
    "plt.title(f'Average sentence length vs number of sentences')\n",
    "\n",
    "# Fitting and drawing the trend line (polynomial power 1)\n",
    "z = np.polyfit(x, y, 1)\n",
    "y_hat = np.poly1d(z)(x)\n",
    "\n",
    "plt.plot(x, y_hat, \"r--\", lw=1)\n",
    "\n",
    "# Plotting the equation of the line and the r2\n",
    "text = f\"$y={z[0]:0.3f}\\;x{z[1]:+0.3f}$\\n$R^2 = {r2_score(y,y_hat):0.3f}$\"\n",
    "plt.gca().text(0.50, 0.95, text,transform=plt.gca().transAxes,\n",
    "     fontsize=14, verticalalignment='top') \n",
    "\n",
    "# Calculating the confidence interval and plotting it at 0.99 confidence (for this confidence value the t value is 2.58)\n",
    "ci = confidence_interval(0.05, \"2xs\", y)\n",
    "plt.fill_between(x, (y_hat-ci), (y_hat+ci), color='r', alpha=.5)\n",
    "print(f\"Confidence interval as two std is {ci}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49af89c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = \"simple_transformers\"\n",
    "lower = 1\n",
    "set_bins = 20\n",
    "bin_size = 1\n",
    "font_size = 30\n",
    "x_label = \"number of incentives\"\n",
    "y_label = \"Number of douments\"\n",
    "upper = (bin_size * set_bins) + lower\n",
    "\n",
    "if Model == \"BERT\":\n",
    "    series = df_1[(df_1[\"number_of_incentives\"] >= lower) & (df_1[\"number_of_incentives\"] <= upper_limit)].number_of_incentives\n",
    "else:\n",
    "    series = df_2[(df_2[\"number_of_incentives\"] >= lower) & (df_2[\"number_of_incentives\"] <= upper_limit)].number_of_incentives\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 15))\n",
    "counts, bins, patches = ax.hist(series, bins = num_bins, facecolor='#ffae00', edgecolor='gray')\n",
    "\n",
    "ax.set_title(f'Number of incentives per document\\n{language} dataset\\n{Model}')\n",
    "plt.rc('font', size=font_size)  \n",
    "bins_labels(bins, fontsize=font_size, rotation=90)\n",
    "plt.xlabel(x_label, labelpad = 30)\n",
    "plt.ylabel(y_label, labelpad = 30)\n",
    "# ax.set_xticks(bins + 1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3353627d",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_1 = \"n_sentences\"\n",
    "var_2 = \"avg_sent_length\"\n",
    "n_sentences = pd.Series(dictionary[\"avg_sent_length\"])\n",
    "\n",
    "n_sentences.plot.hist(grid=True, bins=10, rwidth=0.9,\n",
    "                       color='#607c8e')\n",
    "print(f\"The longest sentence has {max(n_sentences)} characters\")\n",
    "print(f\"The shortest sentence has {min(n_sentences)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42e0915",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower = 65\n",
    "set_bins = 20\n",
    "bin_size = 60\n",
    "font_size = 30\n",
    "x_label = \"Length of sentence in characters\"\n",
    "y_label = \"Number of douments\"\n",
    "upper = (bin_size * set_bins) + lower\n",
    "# fig_width = (3 * set_bins * bin_size) / 20\n",
    "n_sentences_ = n_sentences[(n_sentences >= lower) & (n_sentences <= upper)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 15))\n",
    "counts, bins, patches = ax.hist(n_sentences_, bins = set_bins, facecolor='#ffae00', edgecolor='gray')\n",
    "\n",
    "# ax = n_sentences_.plot.hist(grid=True, bins=bins, rwidth=0.9, color='#ffae00')\n",
    "ax.set_title(f'Average sentence length sentences\\n{language} dataset')\n",
    "plt.rc('font', size=font_size)  \n",
    "bins_labels(bins, fontsize=font_size, rotation=90)\n",
    "plt.xlabel(x_label, labelpad = 30)\n",
    "plt.ylabel(y_label, labelpad = 30)\n",
    "# ax.set_xticks(bins + 1)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6205b8e8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbadd97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60c77ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_size = 20\n",
    "max_value = 220\n",
    "\n",
    "cm = 1/2.54  # centimeters in inches\n",
    "fig, axs = plt.subplots(4, 3, constrained_layout = True, figsize=(35*cm, 35*cm))\n",
    "counter = 0\n",
    "col = -1\n",
    "row = 0\n",
    "\n",
    "for i in range(0, max_value, range_size):\n",
    "#     print(i)\n",
    "    col += 1\n",
    "    counter += 1\n",
    "#     print(f\"({row}, {col})\")\n",
    "        \n",
    "    n_sentences_ = n_sentences[(n_sentences >= i) & (n_sentences < i + 20)]\n",
    "#     print(f\"min: {min(n_sentences_)} -- max: {max(n_sentences_)}\")\n",
    "\n",
    "\n",
    "    axs[row, col].hist(n_sentences_, bins=10, color='#607c8e')#rwidth=0.9,\n",
    "    axs[row, col].set_title('Number of sentences per document')\n",
    "#     axs[row, col].plt.xlabel('Counts')\n",
    "#     axs[row, col].plt.ylabel('Number of sentences')\n",
    "#     axs[row, col].plt.grid(axis='y', alpha=0.75)\n",
    "    \n",
    "    if counter % 3 == 0:\n",
    "        col = -1\n",
    "        row += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0994f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beb924e",
   "metadata": {},
   "source": [
    "### Number of incentives\n",
    "**Jordi Planas**\n",
    "* What is the absolute number of incentives?\n",
    "* What is the ratio of documents with incentives?\n",
    "* What is the average number of incentives per document?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ce9a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {df.num_incentives_sbert.sum()} sentences refering to incentives using SBERT\")\n",
    "print(f\"There are {df.num_incentives_bert.sum()} sentences refering to incentives using BERT\")\n",
    "print(f\"There are {len(df[df.num_incentives_sbert != 0])} documents containing at least one incentive with SBERT\")\n",
    "print(f\"The percentage of documents containing SBERT incentives is {len(df[df.num_incentives_sbert != 0])/len(df)}\")\n",
    "print(f\"There are {len(df[df.num_incentives_bert != 0])} documents containing at least one incentive with BERT\")\n",
    "print(f\"The percentage of documents containing BERT incentives is {len(df[df.num_incentives_bert != 0])/len(df)}\")\n",
    "print(f\"The median number of incentives in documents containing at least one incentive is {df[df.num_incentives_sbert != 0].num_incentives_sbert.median()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b099ef0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
