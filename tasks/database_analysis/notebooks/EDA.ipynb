{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74bb1332",
   "metadata": {},
   "source": [
    "# EDA for the HSSC paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fed81d",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Table-of-Questions\" data-toc-modified-id=\"Table-of-Questions-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Table of Questions</a></span></li><li><span><a href=\"#Library-imports\" data-toc-modified-id=\"Library-imports-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Library imports</a></span></li><li><span><a href=\"#Data-imports\" data-toc-modified-id=\"Data-imports-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data imports</a></span></li><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Functions</a></span></li><li><span><a href=\"#Data-tranformations\" data-toc-modified-id=\"Data-tranformations-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Data tranformations</a></span><ul class=\"toc-item\"><li><span><a href=\"#Date-from-string-to-date-format\" data-toc-modified-id=\"Date-from-string-to-date-format-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Date from string to date-format</a></span></li><li><span><a href=\"#Replace-0s-by-1s-to-avoid-zero-division\" data-toc-modified-id=\"Replace-0s-by-1s-to-avoid-zero-division-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Replace 0s by 1s to avoid zero division</a></span></li></ul></li><li><span><a href=\"#Analysis\" data-toc-modified-id=\"Analysis-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Analysis</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sentence-length\" data-toc-modified-id=\"Sentence-length-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Sentence length</a></span></li><li><span><a href=\"#Number-of-incentives\" data-toc-modified-id=\"Number-of-incentives-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Number of incentives</a></span></li><li><span><a href=\"#Types-of-incentives\" data-toc-modified-id=\"Types-of-incentives-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Types of incentives</a></span></li><li><span><a href=\"#Stats-by-country\" data-toc-modified-id=\"Stats-by-country-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>Stats by country</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc9fda8",
   "metadata": {},
   "source": [
    "## Table of Questions\n",
    "[Sentence length](#Sentence-length)\n",
    "  * Is there any pattern in the distribution of sentence length?\n",
    "  * Is there any insight that we can draw from the analysis of the distribution of sentence length in relation with the sentence splitting process?\n",
    "  \n",
    "[Number of incentives](#Number-of-incentives)  \n",
    "  * What is the absolute number of incentives?\n",
    "  * What is the ratio of documents with incentives?\n",
    "  * What is the average number of incentives per document?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3dfec9",
   "metadata": {},
   "source": [
    "## Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e250f98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from collections import defaultdict as dd\n",
    "from datetime import datetime as dt\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba41c018",
   "metadata": {},
   "source": [
    "## Data imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "826c58d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names of the columns in the database\n",
    "col_names = [\"id\", \"country\", \"pub lication_source\", \"issuing_institution\", \"doc_type\", \"date\", \"doc_title\", \"summary\",\n",
    "            \"url\", \"num_sents\", \"min_sent_len\", \"max_sent_len\", \"avg_sent_len\", \"num_incentives_sbert\", \"supplies_sbert\",\n",
    "            \"loan_sbert\", \"fine_sbert\", \"direct_payment_sbert\", \"technical_assistance_sbert\", \"tax_benefit_sbert\",\n",
    "            \"num_incentives_bert\", \"supplies_bert\", \"loan_bert\", \"fine_bert\", \"direct_payment_bert\", \"technical_assistance_bert\",\n",
    "            \"tax_benefit_bert\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e22720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the two csv files and merging them toghether in a single dataframe.\n",
    "in_path = \"../input/\"\n",
    "files = [f\"{in_path}spanish_metadata.csv\", f\"{in_path}english_metadata.csv\"]\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for filename in files:\n",
    "    df_temp = pd.read_csv(filename, index_col=None, header=None)\n",
    "    dfs.append(df_temp)\n",
    "\n",
    "df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "df.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9426e415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute it only if yo want to save the contents of the whole database into an excel file\n",
    "out_path = \"../output/\"\n",
    "file_name =  \"metadata.xlsx\"\n",
    "df.to_excel(f\"{out_path}{file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3208501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute it only if you want to visualize the first 5 rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a204e8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute it only of you want to ave a summary of the main descriptive statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fdeadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of sentences\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab62c7c6",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a56d8b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To transform dd/mm/yyyy dates in string format to yyyy/mm/dd or viceversa\n",
    "def reorder_date(string):\n",
    "    elements = string.split(\"/\")\n",
    "    return(f\"{elements[2]}/{elements[1]}/{elements[0]}\")\n",
    "        \n",
    "# To standardize all dates in string format and convert them to datetime format\n",
    "def standardize_date(string):\n",
    "    string = string.replace(\"-\", \"/\").strip()\n",
    "    if re.search(r\"[\\d]{2}/[\\d]{2}/[\\d]{4}\", string):\n",
    "        string = reorder_date(string)\n",
    "    try:\n",
    "        date = dt.strptime(string, '%Y/%m/%d')\n",
    "        return date\n",
    "    except:\n",
    "        print(f\"{string}\")\n",
    "\n",
    "# To calculate the confidence interval of a series of values\n",
    "# The significance values can be only 0.05 or 0.01\n",
    "# The two available methods are \"ci_normal\", \"ci_not_normal\" and \"2xs\"\n",
    "def confidence_interval(significance_value, method, list_of_values):\n",
    "    methods = {\"ci_normal\" : 0, \"ci_not_normal\" : 0, \"2xs\" : 0}\n",
    "    significances = {0.05 : 0, 0.01 : 0}\n",
    "    z_values = {0.05 : 1.92, 0.01 : 2.58}\n",
    "    t_values_n10 = {0.05 : 2.92, 0.01 : 6.96}\n",
    "    t_values_n20 = {0.05 : 2.05, 0.01 : 3.36}\n",
    "    s = np.std(list_of_values)\n",
    "    \n",
    "    if method not in methods:\n",
    "        print(f\"ERROR! The method is not properly spelled or it is not available.\\nPlease select one of: \\\"ci_normal\\\", \\\"ci_not_normal\\\" or \\\"2xs\\\"\")\n",
    "        return\n",
    "    if significance_value not in significances:\n",
    "        print(f\"ERROR! The choosen significance value is not available.\\nPlease select one of: 0.05 or 0.01\")\n",
    "        return\n",
    "    elif method == \"2xs\":\n",
    "        return(2*s)\n",
    "    else:\n",
    "        if method == \"ci_normal\" or len(list_of_values) > 20:\n",
    "            z = z_values[significance_value]\n",
    "        if method == \"ci_not_normal\" and len(list_of_values) <= 20:\n",
    "            if len(list_of_values) <= 10:\n",
    "                z = t_values_n10[significance_value]\n",
    "            elif len(list_of_values) <= 20:\n",
    "                z = t_values_n20[significance_value]\n",
    "        return(s * z / np.sqrt(len(list_of_values)))\n",
    "            \n",
    "            \n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "def bins_labels(bins, **kwargs):\n",
    "    bin_w = (max(bins) - min(bins)) / (len(bins) - 1)\n",
    "    labels = [int(x) for x in bins[1:] - 1]\n",
    "    labels = [int(x) for x in bins[1:]]\n",
    "    plt.xticks(np.arange(min(bins)+bin_w/2, max(bins), bin_w), labels, **kwargs)\n",
    "#     plt.xlim(bins[0], bins[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb6c844",
   "metadata": {},
   "source": [
    "## Data tranformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df8be3d",
   "metadata": {},
   "source": [
    "### Date from string to date-format\n",
    "The format of the date is not homogeneous on the date column\\\n",
    "The date is of type *string* which is not good for calculations\n",
    "\n",
    "In the next couple of cells we will:\n",
    "* Add a new column with the date in format datetime\n",
    "* Standardize the date column to yyyy-mm-dd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6068acc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inserting a new column called \"date_time\" containing the date as datetime type to easy calculations\n",
    "df.insert(6, \"date_time\", df['date'].map(standardize_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cd22657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the date values to standardize them in the format yyyy-mm-dd\n",
    "df[\"date\"] = df[\"date_time\"].dt.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2f0f31",
   "metadata": {},
   "source": [
    "### Replace 0s by 1s to avoid zero division\n",
    "\n",
    "* As there are 5 documents with 0 sentences, we replace the num_sents value by 1 to avoid zero division\n",
    "* We also replace all five values of \"avg_sent_len\" from 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "174c2141",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"num_sents\"].replace({0 : 1}, inplace = True)\n",
    "df[\"avg_sent_len\"].replace({0 : 1}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d12cf0",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "This is the main section, it will be structured in subsections, one for each question that we want to solve using the data.\\\n",
    "We will use it as a common place with private secctions so that nobody modifies the code of anyone else.\\\n",
    "For this, what we are going to do is to share the whole notebook, but assign each of the subsections of section 4 only to one person. So, nobody should modify the code of any section which is not theirs. Of course, we can review other's people code and discuss it but do not modify it.\\\n",
    "We can proceed as follows.\n",
    "1. When you have a new research question, start a new section (level 3 meaning three \"#\").\n",
    "2. Choose a title.\n",
    "3. Put your name under the title.\n",
    "4. State the research question as clearly as you can below your name.\n",
    "\n",
    "See one example in the next cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7714ffa",
   "metadata": {},
   "source": [
    "### Sentence length\n",
    "**Jordi Planas**\\\n",
    "* Is there any pattern in the distribution of sentence length?\\\n",
    "* Is there any insight that we can draw from the analysis of the distribution of sentence length in relation with the sentence splitting process?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddeb35fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_1 = \"num_sents\"\n",
    "var_2 = \"avg_sent_len\"\n",
    "\n",
    "print(f\"The document with most sentences has {df[var_1].max()} sentences\\nThe document with least sentences has {df[var_1].min()} sentences\")\n",
    "print(f\"The document with the largest average sentence length has an average sentence length of {df[var_2].max()} characters\")\n",
    "print(f\"The document with the shortest sentence length has an average sentence length of {df[var_2].min()} characters\")\n",
    "print(f\"There are {len(df[df.num_sents == 0])} documents with 0 sentences\")\n",
    "print(f\"There are {len(df[df.avg_sent_len == 0])} documents with an average sentence length equal to 0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f99d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of the log-log of number of sentences vs average length of sentence\n",
    "# Sorting is needed when later we want to plat the area between the confidence intervals\n",
    "sorted_df = df.sort_values(var_1)\n",
    "x = np.log10(sorted_df[var_1])\n",
    "y = np.log10(sorted_df[var_2])\n",
    "plt.scatter(x, y , c='DarkBlue')\n",
    "plt.title(f'Average sentence length vs number of sentences')\n",
    "\n",
    "# Fitting and drawing the trend line (polynomial power 1)\n",
    "z = np.polyfit(x, y, 1)\n",
    "y_hat = np.poly1d(z)(x)\n",
    "\n",
    "plt.plot(x, y_hat, \"r--\", lw=1)\n",
    "\n",
    "# Plotting the equation of the line and the r2\n",
    "text = f\"$y={z[0]:0.3f}\\;x{z[1]:+0.3f}$\\n$R^2 = {r2_score(y,y_hat):0.3f}$\"\n",
    "plt.gca().text(0.50, 0.95, text,transform=plt.gca().transAxes,\n",
    "     fontsize=14, verticalalignment='top') \n",
    "\n",
    "# Calculating the confidence interval and plotting it at 0.99 confidence (for this confidence value the t value is 2.58)\n",
    "ci = confidence_interval(0.05, \"2xs\", y)\n",
    "plt.fill_between(x, (y_hat-ci), (y_hat+ci), color='r', alpha=.5)\n",
    "print(f\"Confidence interval as two std is {ci}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e8c22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = \"simple_transformers\"\n",
    "lower = 1\n",
    "set_bins = 20\n",
    "bin_size = 1\n",
    "font_size = 30\n",
    "x_label = \"number of incentives\"\n",
    "y_label = \"Number of douments\"\n",
    "upper = (bin_size * set_bins) + lower\n",
    "\n",
    "if Model == \"BERT\":\n",
    "    series = df_1[(df_1[\"number_of_incentives\"] >= lower) & (df_1[\"number_of_incentives\"] <= upper_limit)].number_of_incentives\n",
    "else:\n",
    "    series = df_2[(df_2[\"number_of_incentives\"] >= lower) & (df_2[\"number_of_incentives\"] <= upper_limit)].number_of_incentives\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 15))\n",
    "counts, bins, patches = ax.hist(series, bins = num_bins, facecolor='#ffae00', edgecolor='gray')\n",
    "\n",
    "ax.set_title(f'Number of incentives per document\\n{language} dataset\\n{Model}')\n",
    "plt.rc('font', size=font_size)  \n",
    "bins_labels(bins, fontsize=font_size, rotation=90)\n",
    "plt.xlabel(x_label, labelpad = 30)\n",
    "plt.ylabel(y_label, labelpad = 30)\n",
    "# ax.set_xticks(bins + 1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396019f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_1 = \"n_sentences\"\n",
    "var_2 = \"avg_sent_length\"\n",
    "n_sentences = pd.Series(dictionary[\"avg_sent_length\"])\n",
    "\n",
    "n_sentences.plot.hist(grid=True, bins=10, rwidth=0.9,\n",
    "                       color='#607c8e')\n",
    "print(f\"The longest sentence has {max(n_sentences)} characters\")\n",
    "print(f\"The shortest sentence has {min(n_sentences)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db01cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower = 65\n",
    "set_bins = 20\n",
    "bin_size = 60\n",
    "font_size = 30\n",
    "x_label = \"Length of sentence in characters\"\n",
    "y_label = \"Number of douments\"\n",
    "upper = (bin_size * set_bins) + lower\n",
    "# fig_width = (3 * set_bins * bin_size) / 20\n",
    "n_sentences_ = n_sentences[(n_sentences >= lower) & (n_sentences <= upper)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 15))\n",
    "counts, bins, patches = ax.hist(n_sentences_, bins = set_bins, facecolor='#ffae00', edgecolor='gray')\n",
    "\n",
    "# ax = n_sentences_.plot.hist(grid=True, bins=bins, rwidth=0.9, color='#ffae00')\n",
    "ax.set_title(f'Average sentence length sentences\\n{language} dataset')\n",
    "plt.rc('font', size=font_size)  \n",
    "bins_labels(bins, fontsize=font_size, rotation=90)\n",
    "plt.xlabel(x_label, labelpad = 30)\n",
    "plt.ylabel(y_label, labelpad = 30)\n",
    "# ax.set_xticks(bins + 1)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd79c74b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62da7c31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f3af0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_size = 20\n",
    "max_value = 220\n",
    "\n",
    "cm = 1/2.54  # centimeters in inches\n",
    "fig, axs = plt.subplots(4, 3, constrained_layout = True, figsize=(35*cm, 35*cm))\n",
    "counter = 0\n",
    "col = -1\n",
    "row = 0\n",
    "\n",
    "for i in range(0, max_value, range_size):\n",
    "#     print(i)\n",
    "    col += 1\n",
    "    counter += 1\n",
    "#     print(f\"({row}, {col})\")\n",
    "        \n",
    "    n_sentences_ = n_sentences[(n_sentences >= i) & (n_sentences < i + 20)]\n",
    "#     print(f\"min: {min(n_sentences_)} -- max: {max(n_sentences_)}\")\n",
    "\n",
    "\n",
    "    axs[row, col].hist(n_sentences_, bins=10, color='#607c8e')#rwidth=0.9,\n",
    "    axs[row, col].set_title('Number of sentences per document')\n",
    "#     axs[row, col].plt.xlabel('Counts')\n",
    "#     axs[row, col].plt.ylabel('Number of sentences')\n",
    "#     axs[row, col].plt.grid(axis='y', alpha=0.75)\n",
    "    \n",
    "    if counter % 3 == 0:\n",
    "        col = -1\n",
    "        row += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45593f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bdee34",
   "metadata": {},
   "source": [
    "### Number of incentives\n",
    "**Jordi Planas**\n",
    "* What is the absolute number of incentives?\n",
    "* What is the ratio of documents with incentives?\n",
    "* What is the average number of incentives per document?\n",
    "* What is the ration of incentive sentences over all the sentences? This is an important number to determine how many non-labeled sentences we should check in order to have a powerful FOR (False Omission Rate) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a058e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 101015 sentences refering to incentives using SBERT\n",
      "There are 117059 sentences refering to incentives using BERT\n",
      "There are 9308 documents containing at least one incentive with SBERT\n",
      "The percentage of documents containing SBERT incentives is 0.4185063621240052\n",
      "There are 9221 documents containing at least one incentive with BERT\n",
      "The percentage of documents containing BERT incentives is 0.41459466750595747\n",
      "The median number of incentives in documents containing at least one incentive is 3.0\n",
      "The counts of the different incentives are id                            765d4ea2383aaf45bb29bf75feadea6e06a80fd206dafc...\n",
      "country                       El SalvadorEl SalvadorEl SalvadorEl SalvadorEl...\n",
      "pub lication_source           Diario OficialDiario OficialDiario OficialDiar...\n",
      "date                          2015-01-272018-02-012017-08-212014-10-082012-0...\n",
      "doc_title                     ORDENANZA REGULADORA DE USOS DE SUELO Y ACTUAC...\n",
      "url                           https://www.jurisprudencia.gob.sv/DocumentosBo...\n",
      "num_sents                                                               3879033\n",
      "min_sent_len                                                            1450240\n",
      "max_sent_len                                                           32961022\n",
      "avg_sent_len                                                            5834691\n",
      "num_incentives_sbert                                                     101015\n",
      "supplies_sbert                                                             4150\n",
      "loan_sbert                                                                20920\n",
      "fine_sbert                                                                11037\n",
      "direct_payment_sbert                                                      43116\n",
      "technical_assistance_sbert                                                14297\n",
      "tax_benefit_sbert                                                          7495\n",
      "num_incentives_bert                                                      117059\n",
      "supplies_bert                                                              6426\n",
      "loan_bert                                                                 25015\n",
      "fine_bert                                                                 11614\n",
      "direct_payment_bert                                                       53026\n",
      "technical_assistance_bert                                                 14178\n",
      "tax_benefit_bert                                                           6800\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {df.num_incentives_sbert.sum()} sentences refering to incentives using SBERT\")\n",
    "print(f\"There are {df.num_incentives_bert.sum()} sentences refering to incentives using BERT\")\n",
    "print(f\"There are {len(df[df.num_incentives_sbert != 0])} documents containing at least one incentive with SBERT\")\n",
    "print(f\"The percentage of documents containing SBERT incentives is {len(df[df.num_incentives_sbert != 0])/len(df)}\")\n",
    "print(f\"There are {len(df[df.num_incentives_bert != 0])} documents containing at least one incentive with BERT\")\n",
    "print(f\"The percentage of documents containing BERT incentives is {len(df[df.num_incentives_bert != 0])/len(df)}\")\n",
    "print(f\"The median number of incentives in documents containing at least one incentive is {df[df.num_incentives_sbert != 0].num_incentives_sbert.median()}\")\n",
    "print(f\"The counts of the different incentives are {df.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fd269ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ratio of labelled sentences for SBERT is 2.6%\n",
      "The ratio of labelled sentences for SBERT is 3.0%\n"
     ]
    }
   ],
   "source": [
    "# Ratio of labelled sentences over all the sentences\n",
    "print(f\"The ratio of labelled sentences for SBERT is {round(df.num_incentives_sbert.sum()/df.num_sents.sum(), 3) *100}%\")\n",
    "print(f\"The ratio of labelled sentences for SBERT is {round(df.num_incentives_bert.sum()/df.num_sents.sum(), 3) *100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab730c67",
   "metadata": {},
   "source": [
    "### Types of incentives\n",
    "**Daniel**\n",
    "- What's the incentive type distribution?\n",
    "- How do different countries compare in the types of incentives they use?\n",
    "    - At the country level\n",
    "    - At the continent level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92c03e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns with incentive numbers only\n",
    "incentive_types = [\"supplies\", \"loan\", \"fine\", \"direct_payment\", \"technical_assistance\", \"tax_benefit\"]\n",
    "models = [\"bert\", \"sbert\"]\n",
    "bert_cols = [f\"{incentive_type}_bert\" for incentive_type in incentive_types]\n",
    "sbert_cols = [f\"{incentive_type}_sbert\" for incentive_type in incentive_types]\n",
    "incentive_cols = [f\"{incentive_type}_{model}\" for incentive_type in incentive_types for model in models]\n",
    "\n",
    "def get_incentive_counts_df(df, perc=False):\n",
    "    # BERT and SBERT as separate columns, and incentive types as index\n",
    "    bert_incentives = df[bert_cols].sum().to_frame().rename(dict(zip(bert_cols, incentive_types))).rename({0: \"bert\"}, axis=1)\n",
    "    sbert_incentives = df[sbert_cols].sum().to_frame().rename(dict(zip(sbert_cols, incentive_types))).rename({0: \"s-bert\"}, axis=1)\n",
    "    \n",
    "    incentives_counts_df = pd.concat([bert_incentives, sbert_incentives], axis=1)\n",
    "    if perc:\n",
    "        return (100*incentives_counts_df / incentives_counts_df.sum())\n",
    "    return incentives_counts_df\n",
    "\n",
    "incentives_counts_df = get_incentive_counts_df(df)\n",
    "incentives_counts_perc_df = get_incentive_counts_df(df, perc=True)\n",
    "incentives_counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628f7f74",
   "metadata": {},
   "source": [
    "Incentive type distribution accross all countries, for both models, in percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738f500c",
   "metadata": {},
   "outputs": [],
   "source": [
    "incentives_counts_perc_df.plot.bar(title=\"Incentive type distribution accross all countries\", xlabel=\"Incentive type\", ylabel=\"Incentive percentage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e589662",
   "metadata": {},
   "source": [
    "Difference in labeling between both models - i.e BERT identifies 2276 more supplies than S-BERT, and S-BERT identifies 695 more tax_benefit than BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542a58d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(incentives_counts_df[\"bert\"] - incentives_counts_df[\"s-bert\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2844906b",
   "metadata": {},
   "source": [
    "Same calculation as before but in percentages i.e BERT identifies 1.38% more supplies than S-BERT, and S-BERT identifies 1.61% more tax_benefit than BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7806c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(incentives_counts_perc_df[\"bert\"] - incentives_counts_perc_df[\"s-bert\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb42bf15",
   "metadata": {},
   "source": [
    "**NOTE**: It would be interesting to see what each model labeled for the same sentence, for the sentences that are different. For example\n",
    "1. Are the sentences labeled as \"supplies\" by BERT the same as the ones labeled by S-BERT? and viceversa\n",
    "2. For the sentences labeled as \"supplies\" by BERT but NOT by S-BERT, what is the label that S-BERT gives? And viceversa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbc5fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = df.country.unique()\n",
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9b96b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 2\n",
    "n_cols = 3\n",
    "\n",
    "figure, axes = plt.subplots(n_rows, n_cols)\n",
    "country_num = 0\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        if country_num < len(countries):\n",
    "            country = countries[country_num]\n",
    "            country_df = df[df[\"country\"] == country]\n",
    "            incentives_per_country = get_incentive_counts_df(country_df, perc=True)\n",
    "            incentives_per_country.plot.bar(title=f\"Incentive type distribution for {country}\", xlabel=\"Incentive type\", ylabel=\"Incentive percentage\", ax=axes[row][col], figsize=(18,10), rot=60)\n",
    "            country_num += 1\n",
    "            \n",
    "figure.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2986e43",
   "metadata": {},
   "source": [
    "### Stats by country\n",
    "\n",
    "**Galina**\n",
    "\n",
    "Unique values / Attempt on standardization / Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f812ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['country'].value_counts())\n",
    "print(df['pub lication_source'].value_counts())\n",
    "#print(df['issuing_institution'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f704b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize dates\n",
    "# date formats - Chile (2021-07-01), El Salvador (18/05/2021), Mexico (20-01-2011),\n",
    "# India - (Acts) 2016-11-30, (Circular, Notification, Order, Ordinance, Regulation, Rule) - 08-03-2018, \n",
    "# USA - 18/05/2021\n",
    "\n",
    "#some overrides first, otherwise format not recognised\n",
    "#override\n",
    "\n",
    "df[\"date\"]=np.where((df[\"id\"]==\"863e4df1c50a88986125e1d5132791c80e4d70a5\"),\"14/12/1975\",df[\"date\"])\n",
    "\n",
    "\n",
    "df_chi = df.loc[df.country == \"Chile\"]\n",
    "df_chi[\"pub_date\"]=pd.to_datetime(df_chi[\"date\"], format=\"%Y/%m/%d\")\n",
    "df_salv = df.loc[df.country == \"El Salvador\"]\n",
    "df_salv[\"pub_date\"]=pd.to_datetime(df_salv[\"date\"], format=\"%d/%m/%Y\")\n",
    "df_mex = df.loc[df.country == \"Mexico\"]\n",
    "df_mex[\"pub_date\"]=pd.to_datetime(df_mex[\"date\"], format=\"%d-%m-%Y\")\n",
    "df_usa = df.loc[df.country == \"USA\"]\n",
    "df_usa[\"pub_date\"]=pd.to_datetime(df_usa[\"date\"], format=\"%d/%m/%Y\")\n",
    "df_ind_a = df.loc[(df['country'] == \"India\") & (df['doc_type'] == \"Act\")]\n",
    "df_ind_a[\"pub_date\"]=pd.to_datetime(df_ind_a[\"date\"], format=\"%Y/%m/%d\")\n",
    "df_ind_o=df.loc[(df['country'] == \"India\") & (df['doc_type'] != \"Act\")]\n",
    "df_ind_o[\"pub_date\"]=pd.to_datetime(df_ind_o[\"date\"], format=\"%d/%m/%Y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77756faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_salv, df_chi, df_mex, df_usa, df_ind_a, df_ind_o ])\n",
    "#df_all.info()\n",
    "df_all[\"Year\"]=df_all[\"pub_date\"].dt.year\n",
    "df_year=df_all.Year.value_counts().sort_index(ascending=False)\n",
    "\n",
    "#df_year\n",
    "df_year_country=df_all.groupby([\"country\",\"Year\"]).agg({\"id\":\"count\"})\n",
    "df_year_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e71b3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country_inst=df_all.groupby([\"country\",\"issuing_institution\"]).agg({\"id\":\"count\"})\n",
    "df_country_inst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af101a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split out doc type field - in some cases information about the category is there\n",
    "# split on digits - to take the part without the reference\n",
    "\n",
    "df_all[\"issuing_institution_clean\"]=df_all[\"issuing_institution\"].str.replace('(',';')\n",
    "\n",
    "\n",
    "type_cat=df_all[\"doc_type\"].str.split(r'(\\d+)', n=1, expand=True)\n",
    "df_all[\"type_cat\"]=type_cat[0]\n",
    "\n",
    "# replace the brackets with another sign otherwise messes up \n",
    "#df_all[\"issuing_institution_clean\"]=df_all[\"issuing_institution\"].str.replace('(',';')\n",
    "\n",
    "\n",
    "# split out institution - on set punctuation - deal with brackets separately, as listing them results in error\n",
    "inst_derived=df_all[\"issuing_institution_clean\"].str.split(\";|:|-|/\", n=1, expand=True)\n",
    "#inst_derived=df_all[\"issuing_institution\"].str.split('(', n=1, expand=True)\n",
    "#inst_derived=df_all[\"issuing_institution\"].str.split(')', n=1, expand=True)\n",
    "df_all[\"inst_derived_1\"]=inst_derived[0].str.upper()\n",
    "df_all[\"inst_derived_2\"]=inst_derived[1].str.upper()\n",
    "\n",
    "# # in cases of convocatorias the name is in the doc title - split on -\n",
    "\n",
    "doc_title_split=df_all[\"doc_title\"].str.split('-', n=1, expand=True)\n",
    "df_all[\"doc_title_p1\"]=doc_title_split[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f98aacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# different patterns for each country - do separately\n",
    "\n",
    "# El Salvador\n",
    "\n",
    "df_salv_2 = df_all.loc[df_all.country == \"El Salvador\"]\n",
    "#start with the default cause\n",
    "\n",
    "df_salv_2['inst_final']=df_salv_2[\"inst_derived_2\"]\n",
    "# then if p2 not empty, take p2\n",
    "df_salv_2['inst_final']=np.where((df_salv_2[\"inst_derived_2\"].isna()),df_salv_2[\"inst_derived_1\"],df_salv_2[\"inst_derived_2\"])\n",
    "\n",
    "# in some cases the name can be taken from the type, if part 2 empty\n",
    "df_salv_2['inst_final']=np.where(((df_salv_2[\"inst_derived_2\"].isna())&(df_salv_2[\"doc_type\"].str.upper().str.contains('MUNICIPAL'))),\"MUNICIPALIDAD\",df_salv_2['inst_final'])\n",
    "\n",
    "# trim and remove the closing brackets\n",
    "df_salv_2[\"inst_final\"]=df_salv_2[\"inst_final\"].str.replace(')','').str.strip()\n",
    "\n",
    "df_salv_2.inst_final.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867d651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map the different values\n",
    "\n",
    "\n",
    "# Initialize dictionaru with multiple keys - use fromkeys\n",
    "keys_set1 = ['ALCALDIA MUNICIPAL', 'ALCALDÍA MUNICIPAL', 'ALCALDÍAS MUNICIPALES', 'ALCLADIA MUNICIPAL','ALCADIA MUNICIPAL','ALCALDÍA MUNICIAPL','ALCALDIA MUNCIPAL','ALCALDIAS MUNICIPALES','ALCADÍA MUNICIPAL' ]\n",
    "dict_set1 ={ **dict.fromkeys(keys_set1, 'ALCALDIA MUNICIPAL')} \n",
    "#  in place\n",
    "df_salv_2.replace({\"inst_final\": dict_set1}, inplace=True)\n",
    "\n",
    "# another set\n",
    "keys_set2 = ['MINISTERIO DE MEDIO AMBIENTE Y RECURSOS NATURALES', 'MINISTERIO DEL MEDIO AMBIENTE Y RECURSOS NATURALES', 'MINISTERIO DE MINISTERIO DE MEDIO AMBIENTE Y RECURSOS NATURALES']\n",
    "dict_set2 ={ **dict.fromkeys(keys_set2, 'MINISTERIO DE MEDIO AMBIENTE Y RECURSOS NATURALES')} \n",
    "#  in place\n",
    "df_salv_2.replace({\"inst_final\": dict_set2}, inplace=True)\n",
    "\n",
    "# another set\n",
    "keys_set3 = ['MINISTERIO DE AGRICULTURA Y GANADERÍA', 'MINISTERIO DE AGRICULTURA Y GANADERIA']\n",
    "dict_set3 ={ **dict.fromkeys(keys_set3, 'MINISTERIO DE AGRICULTURA Y GANADERIA')} \n",
    "#  in place\n",
    "df_salv_2.replace({\"inst_final\": dict_set3}, inplace=True)\n",
    "\n",
    "# another set\n",
    "keys_set4 = ['MINISTERIO DE ECONOMÍA', 'MINISTERIO DE ECONOMIA']\n",
    "dict_set4 ={ **dict.fromkeys(keys_set4, 'MINISTERIO DE ECONOMIA')} \n",
    "#  in place\n",
    "df_salv_2.replace({\"inst_final\": dict_set4}, inplace=True)\n",
    "\n",
    "# another set\n",
    "keys_set5 = ['PRESIDENCIA DE LA REPÚBLICA', 'PRESIDENCIA DE LA REPUBLICA']\n",
    "dict_set5 ={ **dict.fromkeys(keys_set5, 'PRESIDENCIA DE LA REPUBLICA')} \n",
    "#  in place\n",
    "df_salv_2.replace({\"inst_final\": dict_set5}, inplace=True)\n",
    "\n",
    "# another set\n",
    "keys_set5 = ['ORGANO EJECUTIVO', 'ÓRGANO EJECUTIVO']\n",
    "dict_set5 ={ **dict.fromkeys(keys_set5, 'ORGANO EJECUTIVO')} \n",
    "#  in place\n",
    "df_salv_2.replace({\"inst_final\": dict_set5}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526e7e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now Chile\n",
    "df_chi_2 = df_all.loc[df_all.country == \"Chile\"]\n",
    "\n",
    "#start with the default cause\n",
    "df_chi_2['inst_final']=df_chi_2[\"inst_derived_1\"]\n",
    "\n",
    "# group municipalities\n",
    "df_chi_2['inst_final']=np.where((df_chi_2[\"inst_derived_1\"].str.contains('MUNICIPALIDAD')),\"MUNICIPALIDAD\",df_chi_2['inst_final'])\n",
    "df_chi_2['inst_final']=np.where((df_chi_2[\"inst_derived_1\"].str.contains('GOBIERNO REGIONAL')),\"GOBIERNO REGIONAL\",df_chi_2['inst_final'])\n",
    "\n",
    "df_chi_2.inst_final.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e7b855",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  map the different values\n",
    "\n",
    "# Initialize dictionaru with multiple keys - use fromkeys\n",
    "keys_set1 = ['MINISTERIO DE ECONOMÍA,FOMENTO Y TURISMO', 'MINISTERIO DE ECONOMÍA, FOMENTO Y TURISMO' ]\n",
    "dict_set1 ={ **dict.fromkeys(keys_set1, 'MINISTERIO DE ECONOMÍA, FOMENTO Y TURISMO')} \n",
    "#  in place\n",
    "df_chi_2.replace({\"inst_final\": dict_set1}, inplace=True)\n",
    "\n",
    "df_chi_2.inst_final.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6df214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now Mexico - in Mexico ministries are referred to as Secretarias.\n",
    "\n",
    "df_mex_2 = df_all.loc[df_all.country == \"Mexico\"]\n",
    "\n",
    "#start with the default cause\n",
    "df_mex_2['inst_final']=df_mex_2[\"inst_derived_2\"]\n",
    "\n",
    "\n",
    "# if convocatorias type, replace with doc_title\n",
    "\n",
    "# in some cases the name can be taken from the type, if part 2 empty\n",
    "df_mex_2['inst_final']=np.where(((df_mex_2[\"inst_derived_2\"].isna())&(df_mex_2[\"issuing_institution\"].str.upper().str.contains('CONVOCATORIA'))),df_mex_2[\"doc_title_p1\"].str.upper(),df_mex_2['inst_final'])\n",
    "\n",
    "\n",
    "#df_mex_2.doc_title_p1.value_counts()\n",
    "#df_mex_2.inst_derived_2.value_counts()\n",
    "df_mex_2.inst_final.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ad0ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convocatorias have lot of different sources \n",
    "# make tentative grouping - the ones mentioning estado; municipal; y riego (presumably) - they will be grouped later anyway under local\n",
    "\n",
    "df_mex_2['inst_final']=np.where((df_mex_2['inst_final'].str.contains('MUNICIP'))&(df_mex_2[\"issuing_institution\"].str.contains('CONVOCATORIA')),\"SUB-FEDERAL\",df_mex_2['inst_final'])\n",
    "\n",
    "# categorise by keyword\n",
    "df_mex_2['inst_final']=np.where((df_mex_2[\"inst_derived_1\"].str.contains('CONVOCATORIA')&df_mex_2[\"inst_final\"].str.contains(\"SANEAMIENTO\")),\"LOCAL-SANEAMIENTO\",df_mex_2['inst_final'])\n",
    "df_mex_2['inst_final']=np.where((df_mex_2[\"inst_derived_1\"].str.contains('CONVOCATORIA')&df_mex_2[\"inst_final\"].str.contains(\"RIEGO\")),\"LOCAL-RIEGO\",df_mex_2['inst_final'])\n",
    "\n",
    "# work for classifying sources still to  be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8b36c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for grouping - use lambdas with a list - group in a new field\n",
    "# has not worked well - investigate why\n",
    "\n",
    "list=['APOYOS Y SERVICIOS A LA COMERCIALIZACION AGROPECUARIA', 'BANCO DE MEXICO',\n",
    "      'CENTRO DE INFRAESTRUCTURA Y DESARROLLO PARA LAS COMUNIDADES RURALES',\n",
    "     'COLEGIO SUPERIOR AGROPECUARIO','COMISION NACIONAL FORESTAL','FONDO DE FOMENTO AGROPECUARIO','FIDEICOMISO DE FOMENTO MINERO',\n",
    "     'FINANCIERA NACIONAL DE DESARROLLO AGROPECUARIO','FINANCIERA RURAL','FONDO DE FOMENTO AGROPECUARIO',\n",
    "      'FONDO DE GARANTIA Y FOMENTO PARA LA AGRICULTURA','INSTITUTO ESTATAL DE ECOLOGIA Y DESARROLLO SUSTENTABLE',\n",
    "     'INSTITUTO NACIONAL DE INVESTIGACIONES FORESTALES','PROCURADURIA AMBIENTAL Y DEL ORDENAMIENTO TERRITORIAL',\n",
    "     'PROGRAMA NACIONAL DE FINANCIAMIENTO AL MICROEMPRESARIO Y A LA MUJER RURAL','PROMOTORA DEL DESARROLLO URBANO',\n",
    "     'SECRETARIA DE AGRICULTURA','SECRETARIA DE DESARROLLO AGROPECUARIO','SECRETARIA DE DESARROLLO URBANO',\n",
    "     'SECRETARIA DE ENERGIA RECURSOS NATURALES Y PROTECCION AMBIENTAL','SECRETARIA DE INFRAESTRUCTURA',\n",
    "     'SECRETARIA DESARROLLO URBANO Y OBRAS','SECRETARIA DE SEGURIDAD','TRIBUNAL FEDERAL DE JUSTICIA ']\n",
    "#y='AGRARIO'\n",
    "\n",
    "# remove comas\n",
    "df_mex_2['inst_final'] = df_mex_2['inst_final'].str.replace(\",\",\"\")\n",
    "\n",
    "for y in list:\n",
    "    df_mex_2['inst_final'] = df_mex_2['inst_final'].apply(lambda x: y if y in x else x)\n",
    "\n",
    "\n",
    "\n",
    "df_mex_2['inst_final'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea10d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now USA \n",
    "\n",
    "df_usa_2 = df_all.loc[df_all.country == \"USA\"]\n",
    "\n",
    "#start with the default cause\n",
    "df_usa_2['inst_final']=df_usa_2[\"issuing_institution_clean\"].str.upper()\n",
    "\n",
    "df_usa_2.inst_final.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12be7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine later - map the different values\n",
    "\n",
    "# Initialize dictionaru with multiple keys - use fromkeys\n",
    "keys_set1 = ['BUREAU OF CONSUMER FINANANCIAL PROTECTION', 'BUREAU OF CONSUMER FINANCIAL PROTECTION' ]\n",
    "dict_set1 ={ **dict.fromkeys(keys_set1, 'BUREAU OF CONSUMER FINANCIAL PROTECTION')} \n",
    "#  in place\n",
    "df_usa_2.replace({\"inst_final\": dict_set1}, inplace=True)\n",
    "\n",
    "keys_set2 = ['DEPARTMENT OF THE INTERIOR', 'DEPARTMENT OF THE INTEROR' ]\n",
    "dict_set2 ={ **dict.fromkeys(keys_set2, 'DEPARTMENT OF THE INTERIOR')} \n",
    "#  in place\n",
    "df_usa_2.replace({\"inst_final\": dict_set2}, inplace=True)\n",
    "\n",
    "keys_set3 = ['DEPARTMENT OF TRANSPORTATION', 'DEPARTMENT OF TRANSPORTATION [4910-EX-P]' ]\n",
    "dict_set3 ={ **dict.fromkeys(keys_set3, 'DEPARTMENT OF TRANSPORTATION')} \n",
    "#  in place\n",
    "df_usa_2.replace({\"inst_final\": dict_set3}, inplace=True)\n",
    "\n",
    "keys_set4 = ['ENVIRONMENTAL PROTECTION AGENCY', 'ENVIRONMENTAL PROTECTION AGENCY REGION 8','EVIRONMENTAL PROTECTION AGENCY' ]\n",
    "dict_set4 ={ **dict.fromkeys(keys_set4, 'ENVIRONMENTAL PROTECTION AGENCY')} \n",
    "#  in place\n",
    "df_usa_2.replace({\"inst_final\": dict_set4}, inplace=True)\n",
    "\n",
    "keys_set5 = ['NATIONAL AERONAUTICS AND SPACE ADMINISTRATION', 'NATIONAL AERONAUTICS AND SPACE ADMINSTRATION']\n",
    "dict_set5 ={ **dict.fromkeys(keys_set5, 'NATIONAL AERONAUTICS AND SPACE ADMINISTRATION')} \n",
    "#  in place\n",
    "df_usa_2.replace({\"inst_final\": dict_set5}, inplace=True)\n",
    "\n",
    "\n",
    "df_usa_2.inst_final.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156c9d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now India - ministry, and if not available, department. two ministries are for regions - take the department instead \n",
    "\n",
    "\n",
    "df_ind_2 = df_all.loc[df_all.country == \"India\"]\n",
    "\n",
    "#start with the default cause\n",
    "\n",
    "df_ind_2['inst_final']=df_ind_2[\"inst_derived_1\"]\n",
    "# then if p2 not empty, take p2. ISNA not recognised, as the empty cells have some value, so ==\"\"\n",
    "df_ind_2['inst_final']=np.where((df_ind_2[\"inst_derived_1\"]==\"\"),df_ind_2[\"inst_derived_2\"],df_ind_2[\"inst_derived_1\"])\n",
    "# in the cases of regional ministries take the department\n",
    "df_ind_2['inst_final']=np.where((df_ind_2[\"inst_derived_1\"].str.contains(\"MAHARASHTRA\")),df_ind_2[\"inst_derived_2\"],df_ind_2[\"inst_final\"])\n",
    "df_ind_2['inst_final']=np.where((df_ind_2[\"inst_derived_1\"].str.contains((\"ANDAMAN\"))),df_ind_2[\"inst_derived_2\"],df_ind_2[\"inst_final\"])\n",
    "\n",
    "# if empty - leave unknown and sort out later\n",
    "df_ind_2['inst_final']=np.where((df_ind_2[\"inst_final\"].isna()),\"UNKNOWN\",df_ind_2[\"inst_final\"].str.strip())\n",
    "\n",
    "\n",
    "\n",
    "df_ind_2.inst_final.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec6a9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorise by keyword the categories of interest\n",
    "\n",
    "df_ind_2['inst_final']=np.where((df_ind_2[\"inst_final\"]=='UNKNOWN')&df_ind_2[\"doc_title_p1\"].str.upper().str.contains(\"PLANT\"),\"TITLE-PLANT PROTECTION\",df_ind_2['inst_final'])\n",
    "df_ind_2['inst_final']=np.where((df_ind_2[\"inst_final\"]=='UNKNOWN')&df_ind_2[\"doc_title_p1\"].str.upper().str.contains(\"COIN\"),\"TITLE-COINAGE\",df_ind_2['inst_final'])\n",
    "df_ind_2['inst_final']=np.where((df_ind_2[\"inst_final\"]=='UNKNOWN')&df_ind_2[\"doc_title_p1\"].str.upper().str.contains(\"IRRIGATION\"),\"TITLE-IRRIGATION\",df_ind_2['inst_final'])\n",
    "df_ind_2['inst_final']=np.where((df_ind_2[\"inst_final\"]=='UNKNOWN')&df_ind_2[\"doc_title_p1\"].str.upper().str.contains(\"TEA\"),\"TITLE-TEA\",df_ind_2['inst_final'])\n",
    "df_ind_2['inst_final']=np.where((df_ind_2[\"inst_final\"]=='UNKNOWN')&df_ind_2[\"doc_title_p1\"].str.upper().str.contains(\"POLLUTION\"),\"TITLE-POLLUTION\",df_ind_2['inst_final'])\n",
    "df_ind_2['inst_final']=np.where((df_ind_2[\"inst_final\"]=='UNKNOWN')&df_ind_2[\"doc_title_p1\"].str.upper().str.contains(\"TELANGANA\"),\"TITLE-TELANGANA WOOD\",df_ind_2['inst_final'])\n",
    "df_ind_2['inst_final']=np.where((df_ind_2[\"inst_final\"]=='UNKNOWN')&df_ind_2[\"doc_title_p1\"].str.upper().str.contains(\"AFFORESTATION\"),\"TITLE-AFFORESTATION\",df_ind_2['inst_final'])\n",
    "df_ind_2['inst_final']=np.where((df_ind_2[\"inst_final\"]=='UNKNOWN')&df_ind_2[\"doc_title_p1\"].str.upper().str.contains(\"FOREST\"),\"TITLE-FOREST\",df_ind_2['inst_final'])\n",
    "df_ind_2['inst_final']=np.where((df_ind_2[\"inst_final\"]=='UNKNOWN')&df_ind_2[\"doc_title_p1\"].str.upper().str.contains(\"GREEN TRIBUNAL\"),\"TITLE-GREEN TRIBUNAL\",df_ind_2['inst_final'])\n",
    "df_ind_2['inst_final']=np.where((df_ind_2[\"inst_final\"]=='UNKNOWN')&df_ind_2[\"doc_title_p1\"].str.upper().str.contains(\"LAND ACQUISITION\"),\"TITLE-LAND ACQUISITION\",df_ind_2['inst_final'])\n",
    "df_ind_2['inst_final']=np.where((df_ind_2[\"inst_final\"]=='UNKNOWN')&df_ind_2[\"doc_title_p1\"].str.upper().str.contains(\"SPICE\"),\"TITLE-SPICE\",df_ind_2['inst_final'])\n",
    "df_ind_2['inst_final']=np.where((df_ind_2[\"inst_final\"]=='UNKNOWN')&df_ind_2[\"doc_title_p1\"].str.upper().str.contains(\"WATER\"),\"TITLE-WATER\",df_ind_2['inst_final'])\n",
    "\n",
    "\n",
    "df_ind_2['inst_final'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27400f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine values through lambdas\n",
    "\n",
    "# for grouping - use lambdas with a list - group in a new field\n",
    "\n",
    "list=['DEPARTMENT OF ADMINISTRATIVE REFORM','DEPARTMENT OF AGRICULTURE','DEPARTMENT OF ANIMAL HUSBANDRY',\n",
    "      'DEPARTMENT OF ARCHAEOLOGY','DEPARTMENT OF CULTUR','DEPARTMENT OF ENVIRONMENT','DEPARTMENT OF FOREST',\n",
    "      'DEPARTMENT OF FINANCE','DEPARTMENT OF FISHERIES','DEPARTMENT OF HOME','DEPARTMENT OF HORTICULTURE',\n",
    "      'DEPARTMENT OF HOUSING','DEPARTMENT OF INDUSTR','DEPARTMENT OF IRRIGATION','DEPARTMENT OF WATER',\n",
    "      'DEPARTMENT OF LABOUR','DEPARTMENT OF LAW','DEPARTMENT OF RURAL','DEPARTMENT OF REVENUE','DEPARTMENT OF PLANNING',\n",
    "      'DEPARTMENT OF TOURISM','DEPARTMENT OF SOCIAL WELFARE','DEPARTMENT OF URBAN','DEPARTMENT OF HEALTH'\n",
    "      'DEPARTMENT FOR WOMAN AND CHILD','DEPARTMENT FOR WOMEN CHILDREN','DEPARTMENT OF PANCHAYAT','DEPARTMENT OF PERSONNEL','DEPARTMENT OF TOWN',\n",
    "      'DEPARTMENT OF LAND ACQUISITION','DEPARTMENT OF HANDLOOMS','MINISTRY OF AGRICULTURE','MINISTRY OF ENVIRONMENT','MINISTRY OF HOME']\n",
    "\n",
    "# remove comas\n",
    "df_ind_2['inst_final'] = df_ind_2['inst_final'].str.replace(\",\",\"\")\n",
    "\n",
    "for y in list:\n",
    "    df_ind_2['inst_final'] = df_ind_2['inst_final'].apply(lambda x: y if y in x else x)\n",
    "\n",
    "\n",
    "\n",
    "df_ind_2['inst_final'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3fdfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_2 = pd.concat([df_salv_2, df_chi_2, df_mex_2, df_usa_2, df_ind_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1178be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now apply groups\n",
    "\n",
    "df_all_2['inst_group']=df_all_2['inst_final']\n",
    "\n",
    "# Use dictionary and replace - SET 1 - GENERAL PUBLIC SERVICES\n",
    "inst_set1 = ['GOBIERNO REGIONAL','MINISTERIO DE HACIENDA','MINISTERIO DE RELACIONES EXTERIORES',\n",
    "             'MINISTERIO SECRETARÍA GENERAL DE GOBIERNO','MINISTERIO SECRETARÍA GENERAL DE LA PRESIDENCIA','MUNICIPALIDAD',\n",
    "             'ALCALDIA MUNICIPAL','CONSEJO DE ALCALDES DEL ÁREA METROPOLITANA DE SAN SALVADOR','CORTE DE CUENTAS DE LA REPÚBLICA',\n",
    "             'MINISTERIO DE RELACIONES EXTERIORES','MUNICIPALIDAD','ORGANO EJECUTIVO','ORGANO LEGISLATIVO','PRESIDENCIA DE LA REPUBLICA',\n",
    "             'DEPARTMENT OF ADMINISTRATIVE REFORM','DEPARTMENT OF ANDAMAN PUBLIC WORKS DEPARTMENT A & N ADMN','DEPARTMENT OF COLLECTOR DEPARTMENT',\n",
    "             'DEPARTMENT OF COLONIZATION','DEPARTMENT OF FINANCE','DEPARTMENT OF GUWAHATI DEVELOPMENT DEPARTMENT',\n",
    "             'DEPARTMENT OF LABOUR','DEPARTMENT OF LAND ACQUISITION','DEPARTMENT OF LOCAL SELF GOVERNMENT','DEPARTMENT OF MAHUD',\n",
    "             'DEPARTMENT OF PARLIAMENTARY AFFAIRS DEPARTMENT','DEPARTMENT OF PERSONNEL','DEPARTMENT OF PHE;I&FC)',\n",
    "             'DEPARTMENT OF PWD ;B&R)','DEPARTMENT OF REVENUE','DEPARTMENT OF SUPERINTENDENT ENGINEER PWD DAMAN','MINISTRY OF FINANCE',\n",
    "             'MINISTRY OF REVENUE','TITLE-COINAGE','UNKNOWN','BANCO DE MEXICO','CAMARA DE DIPUTADOS',\n",
    "             'CONSEJO NACIONAL DE NORMALIZACION Y CERTIFICACION DE COMPETENCIAS LABORALES','INSTITUTO MEXICANO DE LA PROPIEDAD INDUSTRIAL',\n",
    "             'MEX','SECRETARIA DE GOBERNACION','SECRETARIA DE HACIENDA Y CREDITO PUBLICO','SECRETARIA DE LA FUNCION PUBLICA',\n",
    "             'SECRETARIA DE RELACIONES EXTERIORES','SERVICIO DE ADMINISTRACION Y ENAJENACION DE BIENES','SON','SUB-FEDERAL',\n",
    "             'TAB','ADMINISTRATIVE COMMITTEE OF THE FEDERAL REGISTER','ADMINISTRATIVE CONFERENCE OF THE UNITED STATES',\n",
    "             'AGENCY FOR INTERNATIONAL DEVELOPMENT','COMMODITY FUTURES TRADING COMMISSION',\n",
    "             'CORPORATION FOR NATIONAL AND COMMUNITY SERVICE','DENALI COMMISSION','DEPARTMENT OF LABOR','DEPARTMENT OF STATE',\n",
    "             'DEPARTMENT OF THE TREASURY','DEPARTMENT OF TREASURY','EXECUTIVE OFFICE OF THE PRESIDENT',\n",
    "             'FEDERAL FINANCIAL INSTITUTIONS EXAMINATION COUNCIL','FEDERAL LABOR RELATIONS AUTHORITY',\n",
    "             'FEDERAL PERMITTING IMPROVEMENT STEERING COUNCIL','FEDERAL RESERVE SYSTEM','FEDERAL TRADE COMMISSION',\n",
    "             'FINANCIAL STABILITY OVERSIGHT COUNCIL','GENERAL SERVICES ADMINISTRATION','INTERNATIONAL TRADE COMMISSION',\n",
    "             'LIBRARY OF CONGRESS','MERIT SYSTEMS PROTECTION BOARD','MILLENNIUM CHALLENGE CORPORATION',\n",
    "             'NATIONAL ARCHIVES AND RECORDS ADMINISTRATION','NATIONAL CAPITAL PLANNING COMMISSION',\n",
    "             'NATIONAL CREDIT UNION ADMINISTRATION','NATIONAL LABOR RELATIONS BOARD','OFFICE OF MANAGEMENT AND BUDGET',\n",
    "             'OFFICE OF PERSONNEL MANAGEMENT','OFFICE OF THE FEDERAL REGISTER','OFFICE OF THE UNITED STATES TRADE REPRESENTATIVE',\n",
    "             'SECURITIES AND EXCHANGE COMMISSION','TENNESSEE VALLEY AUTHORITY']\n",
    "dict_set1 ={ **dict.fromkeys(inst_set1, 'GENERAL PUBLIC SERVICES')} \n",
    "#  in place\n",
    "df_all_2.replace({\"inst_group\": dict_set1}, inplace=True)\n",
    "\n",
    "# Use dictionary and replace - SET 2 - DEFENCE\n",
    "inst_set2 = ['MINISTERIO DE DEFENSA NACIONAL','MINISTRY OF DEFENCE','SECRETARIA DE MARINA',\n",
    "             'DEFENSE NUCLEAR FACILITIES SAFETY BOARD','DEPARTMENT OF DEFENSE','DEPARTMENT OF HOMELAND SECURITY',\n",
    "             'NATIONAL AERONAUTICS AND SPACE ADMINISTRATION']\n",
    "dict_set2 ={ **dict.fromkeys(inst_set2, 'DEFENCE')} \n",
    "#  in place\n",
    "df_all_2.replace({\"inst_group\": dict_set2}, inplace=True)\n",
    "\n",
    "# Use dictionary and replace - SET 3 - PUBLIC ORDER AND SAFETY\n",
    "inst_set3 = ['MINISTERIO DE JUSTICIA','MINISTERIO DE JUSTICIA Y DERECHOS HUMANOS','MINISTERIO DEL INTERIOR Y SEGURIDAD PÚBLICA',\n",
    "             'DEPARTMENT OF HOME','DEPARTMENT OF LAW','DEPARTMENT OF POLICE DEPARTMENT','MINISTRY OF HOME','MINISTRY OF LAW AND JUSTICE',\n",
    "             'MINISTRY OF LAW DEPARTMENT','PROCURADURIA GENERAL DE LA REPUBLICA','SECRETARIA DE SEGURIDAD','SUPREMA CORTE DE JUSTICIA DE LA NACION',\n",
    "             'TRIBUNAL ELECTORAL DEL PODER JUDICIAL DE LA FEDERACION','TRIBUNAL FEDERAL DE JUSTICIA ','TRIBUNAL FEDERAL DE JUSTICIA ADMINISTRATIVA',\n",
    "             'TRIBUNAL FEDERAL DE JUSTICIA FISCAL Y ADMINISTRATIVA','TRIBUNAL SUPERIOR AGRARIO','DEPARTMENT OF INTERIOR',\n",
    "             'DEPARTMENT OF JUSTICE','DEPARTMENT OF THE INTERIOR','FEDERAL EMERGENCY MANAGEMENT AGENCY']\n",
    "dict_set3 ={ **dict.fromkeys(inst_set3, 'PUBLIC ORDER AND SAFETY')} \n",
    "#  in place\n",
    "df_all_2.replace({\"inst_group\": dict_set3}, inplace=True)\n",
    "\n",
    "# Use dictionary and replace - SET 4 - ECONOMIC AFFAIRS\n",
    "inst_set4 = ['MINISTERIO DE AGRICULTURA','MINISTERIO DE BIENES NACIONALES','MINISTERIO DE DESARROLLO SOCIAL',\n",
    "             'MINISTERIO DE ECONOMÍA, FOMENTO Y TURISMO','MINISTERIO DE ENERGÍA','MINISTERIO DE MINERÍA',\n",
    "             'MINISTERIO DE TRANSPORTES Y TELECOMUNICACIONES','MINISTERIO DE AGRICULTURA Y GANADERIA',\n",
    "             'MINISTERIO DE ECONOMIA','SUPERINTENDENCIA GENERAL DE ELECTRICIDAD Y TELECOMUNICACIONES',\n",
    "             'DEPARTMENT OF AGRICULTURE','DEPARTMENT OF ANIMAL AND SHEEP HUSBANDARY','DEPARTMENT OF ANIMAL HUSBANDRY',\n",
    "             'DEPARTMENT OF COMMERCE & INDUSTRIES DEPARTMENT','DEPARTMENT OF CO-OPERATION MARKETING AND TEXTILES DEPARTMENT',\n",
    "             'DEPARTMENT OF ECONOMICS & STATISTICS','DEPARTMENT OF ELECTRONICS AND INFORMATION TECHNOLOGY',\n",
    "             'DEPARTMENT OF FARMER WELFARE AND AGRICULTURE DEVELOPMENT DEPARTMENT','DEPARTMENT OF FISHERIES',\n",
    "             'DEPARTMENT OF FISHERY DEPARTMENT','DEPARTMENT OF FLORICULTURE','DEPARTMENT OF FOOD SECURITY AND AGRICULTURE DEVELOPMENT DEPARTMENT',\n",
    "             'DEPARTMENT OF HORTICULTURE','DEPARTMENT OF INDUSTR','DEPARTMENT OF LIVESTOCK DEVELOPMENT','DEPARTMENT OF TOURISM',\n",
    "             'DEPARTMENT OF TRANSPORT','MINISTRY OF AGRICULTURE','MINISTRY OF ANIMAL HUSBANDRY','MINISTRY OF COAL',\n",
    "             'MINISTRY OF COMMERCE AND INDUSTRY','MINISTRY OF COOPERATION','MINISTRY OF HORTICULTURE','MINISTRY OF INDUSTRIES',\n",
    "             'MINISTRY OF RAILWAYS','MINISTRY OF TEXTILES','TITLE-SPICE','TITLE-TEA','COMISION FEDERAL DE COMPETENCIA ECONOMICA',\n",
    "             'COMISION NACIONAL DE HIDROCARBUROS','COMISION REGULADORA DE ENERGIA','FIDEICOMISO DE FOMENTO MINERO',\n",
    "             'FIDEICOMISOS INSTITUIDOS EN RELACION CON LA AGRICULTURA','FINANCIERA NACIONAL DE DESARROLLO AGROPECUARIO',\n",
    "             'FINANCIERA RURAL','FONDO DE CAPITALIZACION E INVERSION DEL SECTOR RURAL ','FONDO DE FOMENTO AGROPECUARIO',\n",
    "             'FONDO DE GARANTIA Y FOMENTO PARA LA AGRICULTURA','INSTITUTO NACIONAL DE ESTADISTICA Y GEOGRAFIA','LOCAL-RIEGO',\n",
    "             'PROCURADURIA AGRARIA','SECRETARIA DE AGRICULTURA','SECRETARIA DE COMUNICACIONES Y TRANSPORTES',\n",
    "             'SECRETARIA DE DESARROLLO AGROPECUARIO','SECRETARIA DE ECONOMIA','SECRETARIA DE ENERGIA',\n",
    "             'SECRETARIA DE LA REFORMA AGRARIA','CONSUMER PRODUCT SAFETY COMMISSION','DEPARMENT OF ENERGY','DEPARTMENT OF AGRICULTURE',\n",
    "             'DEPARTMENT OF COMMERCE','DEPARTMENT OF ENERGY','DEPARTMENT OF TRANSPORTATION','EXPORT-IMPORT BANK',\n",
    "             'FARM CREDIT ADMINISTRATION','FARM CREDIT SYSTEM INSURANCE CORPORATION','FEDERAL COMMUNICATIONS COMMISSION',\n",
    "             'FEDERAL DEPOSIT INSURANCE CORPORATION','FEDERAL HIGHWAY ADMINISTRATION','FEDERAL MARITIME COMMISSION',\n",
    "             'FEDERAL MINE SAFETY AND HEALTH REVIEW COMMISSION','NATIONAL TRANSPORTATION SAFETY BOARD','NUCLEAR REGULATORY COMMISSION',\n",
    "             'PACIFIC NORTHWEST ELECTRIC POWER AND CONSERVATION PLANNING COUNCIL','POSTAL REGULATORY COMMISSION','POSTAL SERVICE',\n",
    "             'RAILROAD RETIREMENT BOARD','SMALL BUSINESS ADMINISTRATION','SURFACE TRANSPORTATION BOARD']\n",
    "dict_set4 ={ **dict.fromkeys(inst_set4, 'ECONOMIC AFFAIRS')} \n",
    "#  in place\n",
    "df_all_2.replace({\"inst_group\": dict_set4}, inplace=True)\n",
    "\n",
    "# Use dictionary and replace - SET 5 - ENVIRONMENTAL PROTECTION\n",
    "inst_set5 = ['MINISTERIO DEL MEDIO AMBIENTE','MINISTERIO DE MEDIO AMBIENTE Y RECURSOS NATURALES',\n",
    "             'MINISTERIO DEL MEDIO AMBIENTE','DEPARTMENT OF CHANDIGARH POLLUTION CONTROL COMMITTEE',\n",
    "             'DEPARTMENT OF ENVIRONMENT','DEPARTMENT OF FOREST','MINISTRY OF ENVIRONMENT','MINISTRY OF FOREST',\n",
    "             'TITLE-PLANT PROTECTION','TITLE-AFFORESTATION','TITLE-FOREST','TITLE-GREEN TRIBUNAL','TITLE-POLLUTION',\n",
    "             'TITLE-TELANGANA WOOD','COMISION NACIONAL FORESTAL','COMISION NACIONAL PARA EL DESARROLLO DE LOS PUEBLOS INDIGENAS',\n",
    "             'INSTITUTO DE IMPACTO Y RIESGO AMBIENTAL DEL ESTADO DE QUINTANA ROO ','INSTITUTO ESTATAL DE ECOLOGIA Y DESARROLLO SUSTENTABLE',\n",
    "             'INSTITUTO FEDERAL ELECTORAL','INSTITUTO NACIONAL DE ECOLOGIA Y CAMBIO CLIMATICO',\n",
    "             'INSTITUTO NACIONAL DE INVESTIGACIONES FORESTALES','INSTITUTO NACIONAL DEL SUELO SUSTENTABLE ',\n",
    "             'PROCURADURIA AMBIENTAL Y DEL ORDENAMIENTO TERRITORIAL','PROTECTORA DE BOSQUES DEL ESTADO DE MEXICO ',\n",
    "             'SECRETARIA DE ENERGIA RECURSOS NATURALES Y PROTECCION AMBIENTAL','SECRETARIA DE MEDIO AMBIENTE Y RECURSOS NATURALES',\n",
    "             'COUNCIL ON ENVIRONMENTAL QUALITY','ENVIRONMENTAL PROTECTION AGENCY','GULF COAST ECOSYSTEM RESTORATION COUNCIL',\n",
    "             'SUSQUEHANNA RIVER BASIN COMMISSION']\n",
    "dict_set5 ={ **dict.fromkeys(inst_set5, 'ENVIRONMENTAL PROTECTION')} \n",
    "#  in place\n",
    "df_all_2.replace({\"inst_group\": dict_set5}, inplace=True)\n",
    "\n",
    "# Use dictionary and replace - SET 6 - HOUSING AND COMMUNITY AMENITIES\n",
    "inst_set6 = ['MINISTERIO DE OBRAS PÚBLICAS','MINISTERIO DE VIVIENDA Y URBANISMO','DEPARTMENT OF HOUSING',\n",
    "             'DEPARTMENT OF IRRIGATION','DEPARTMENT OF NARMADA WATER RESOURCES WATER SUPPLY AND KALPSAR DEPARTMENT',\n",
    "             'DEPARTMENT OF PANCHAYAT','DEPARTMENT OF PLANNING','DEPARTMENT OF RURAL','DEPARTMENT OF SCHEDULED TRIBES DEPT',\n",
    "             'DEPARTMENT OF TOWN','DEPARTMENT OF URBAN','DEPARTMENT OF WATER','MINISTRY OF HOUSING AND URBAN AFFAIRS',\n",
    "             'MINISTRY OF PLANNING','MINISTRY OF PUBLIC WORKS','MINISTRY OF RURAL DEVELOPMENT','MINISTRY OF TOWN AND COUNTRY PLANNING',\n",
    "             'TITLE-IRRIGATION','TITLE-LAND ACQUISITION','TITLE-WATER','APOYOS Y SERVICIOS A LA COMERCIALIZACION AGROPECUARIA',\n",
    "             'CENTRO DE INFRAESTRUCTURA Y DESARROLLO PARA LAS COMUNIDADES RURALES','INSTITUTO NACIONAL PARA EL DESARROLLO DE CAPACIDADES DEL SECTOR RURAL A.C. ',\n",
    "             'LOCAL-SANEAMIENTO','PROMOTORA DEL DESARROLLO URBANO','SECRETARIA DE DESARROLLO AGRARIO TERRITORIAL Y URBANO',\n",
    "             'SECRETARIA DE DESARROLLO URBANO','SECRETARIA DE INFRAESTRUCTURA','SECRETARIA DE OBRAS PUBLICAS Y DESARROLLO URBANO ',\n",
    "             'SECRETARIA DESARROLLO URBANO Y OBRAS','DEPARTMENT OF HOUSING AND URBAN DEVELOPMENT','FEDERAL HOUSING FINANCE AGENCY',\n",
    "             'HOUSING AND URBAN DEVELOPMENT']\n",
    "dict_set6 ={ **dict.fromkeys(inst_set6, 'HOUSING AND COMMUNITY AMENITIES')} \n",
    "#  in place\n",
    "df_all_2.replace({\"inst_group\": dict_set6}, inplace=True)\n",
    "\n",
    "# Use dictionary and replace - SET 7 - HEALTH\n",
    "inst_set7 = ['MINISTERIO DE SALUD','MINISTERIO DE SALUD','DEPARTMENT OF GOVERNMENT MEDICAL COLLEGE & HOSPITAL CHANDIGARH-32',\n",
    "             'DEPARTMENT OF RELIEF AND REHABILITATION DEPARTMENT','SECRETARIA DE SALUD','SEGURIDAD ALIMENTARIA MEXICANA ','DEPARTMENT OF HEALTH AND HUMAN SERVICES',\n",
    "             'OCCUPATIONAL SAFETY AND HEALTH REVIEW COMMISSION']\n",
    "dict_set7 ={ **dict.fromkeys(inst_set7, 'HEALTH')} \n",
    "#  in place\n",
    "df_all_2.replace({\"inst_group\": dict_set7}, inplace=True)\n",
    "\n",
    "# Use dictionary and replace - SET 8 - RECREATION, CULTURE AND RELIGION\n",
    "inst_set8 = ['MINISTERIO DE LAS CULTURAS, LAS ARTES Y EL PATRIMONIO','DEPARTMENT OF ARCHAEOLOGY',\n",
    "             'DEPARTMENT OF ART CULTURE AND LANGUAGE DEPARTMENT','DEPARTMENT OF CULTUR','DEPARTMENT OF HANDLOOMS',\n",
    "             'DEPARTMENT OF KANNADA CULTURE INFORMATION & TOURISM DEPARTMENT',\n",
    "             'DEPARTMENT OF YOUTH ADVANCEMENT TOURISM AND CULTURE','MINISTRY OF CULTURE','MINISTRY OF INFORMATION AND BROADCASTING',\n",
    "             'MINISTRY OF LANGUAGE ART AND CULTURE','SECRETARIA DE CULTURA','AMERICAN BATTLE MONUMENTS COMMISSION',\n",
    "             'NATIONAL FOUNDATION ON THE ARTS AND THE HUMANITIES']\n",
    "dict_set8 ={ **dict.fromkeys(inst_set8, 'RECREATION, CULTURE AND RELIGION')} \n",
    "#  in place\n",
    "df_all_2.replace({\"inst_group\": dict_set8}, inplace=True)\n",
    "\n",
    "# Use dictionary and replace - SET 9 - EDUCATION\n",
    "inst_set9 = ['MINISTERIO DE EDUCACIÓN','DEPARTMENT OF SCIENCE & TECHNOLOGY DEPARTMENT GOVERNMENT OF GOA.',\n",
    "             'COLEGIO SUPERIOR AGROPECUARIO','SECRETARIA DE EDUCACION PUBLICA','DEPARTMENT OF EDUCATION',\n",
    "             'NATIONAL SCIENCE FOUNDATION','OFFICE OF SCIENCE AND TECHNOLOGY POLICY']\n",
    "dict_set9 ={ **dict.fromkeys(inst_set9, 'EDUCATION')} \n",
    "#  in place\n",
    "df_all_2.replace({\"inst_group\": dict_set9}, inplace=True)\n",
    "\n",
    "# Use dictionary and replace - SET 10 - SOCIAL PROTECTION\n",
    "inst_set10 = ['MINISTERIO DE DESARROLLO SOCIAL Y FAMILIA','MINISTERIO DEL TRABAJO Y PREVISIÓN SOCIAL',\n",
    "              'MINISTERIO DE TRABAJO Y PREVISIÓN SOCIAL','DEPARTMENT FOR WOMEN CHILDREN','DEPARTMENT OF EMPOWERMENT OF PERSONS WITH DISABILITIES',\n",
    "              'DEPARTMENT OF HEALTH & FAMILY WELFARE DEPARTMENT','DEPARTMENT OF SOCIAL JUSTICE EMPOWERMENT DEPARTMENT',\n",
    "              'DEPARTMENT OF SOCIAL WELFARE','DEPARTMENT OF TRIBAL WELFARE','DEPARTMENT OF WOMAN AND CHILD DEVELOPMENT',\n",
    "              'DEPARTMENT OF WOMEN AND CHILD DEVELOPMENT DEPARTMENT','INSTITUTO MEXICANO DEL SEGURO SOCIAL',\n",
    "              'INSTITUTO NACIONAL DE LOS PUEBLOS INDIGENAS','PROGRAMA NACIONAL DE FINANCIAMIENTO AL MICROEMPRESARIO Y A LA MUJER RURAL',\n",
    "              'SECRETARIA DE BIENESTAR','SECRETARIA DE DESARROLLO SOCIAL','SECRETARIA DEL TRABAJO Y PREVISION SOCIAL',\n",
    "              'BUREAU OF CONSUMER FINANCIAL PROTECTION','COMMITTEE FOR PURCHASE FROM PEOPLE WHO ARE BLIND OR SEVERELY DISABLED',\n",
    "              'CONSUMER FINANCIAL PROTECTION BUREAU','DEPARTMENT OF VETERANS AFFAIRS','NATIONAL INDIAN GAMING COMMISSION',\n",
    "              'PENSION BENEFIT GUARANTY CORPORATION','SOCIAL SECURITY ADMINISTRATION','THE BUREAU OF CONSUMER FINANCIAL PROTECTION']\n",
    "dict_set10 ={ **dict.fromkeys(inst_set10, 'SOCIAL PROTECTION')} \n",
    "#  in place\n",
    "df_all_2.replace({\"inst_group\": dict_set10}, inplace=True)\n",
    "\n",
    "df_all_2['inst_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34407387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create count markers for incentives\n",
    "# set the index first\n",
    "\n",
    "df_all_2=df_all_2.set_index(\"id\")\n",
    "\n",
    "df_all_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6156ad81",
   "metadata": {},
   "outputs": [],
   "source": [
    "### define function and apply to new fields\n",
    "\n",
    "def count_marker(x):\n",
    "    if (x)*1>0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "\n",
    "list= [\"num_incentives_sbert\", \"supplies_sbert\",\n",
    "            \"loan_sbert\", \"fine_sbert\", \"direct_payment_sbert\", \"technical_assistance_sbert\", \"tax_benefit_sbert\",\n",
    "            \"num_incentives_bert\", \"supplies_bert\", \"loan_bert\", \"fine_bert\", \"direct_payment_bert\", \"technical_assistance_bert\",\n",
    "            \"tax_benefit_bert\"]\n",
    "\n",
    "# create new columns\n",
    "for y in list:\n",
    "    df_all_2[y+'_YN'] = df_all_2[y]\n",
    "\n",
    "\n",
    "\n",
    "for y in list:\n",
    "    df_all_2[y+'_YN']=df_all_2[y+'_YN'].apply(count_marker)\n",
    "\n",
    "\n",
    "        \n",
    "df_all_2     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab365147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a marker for non-incentive document - neither bert nor sbert incentives\n",
    "\n",
    "df_all_2['non_incentive_doc'] = np.where((df_all_2['num_incentives_sbert']+df_all_2['num_incentives_bert']==0),'Yes', 'No')\n",
    "df_all_2['sber_bert_incentive_doc'] = np.where((df_all_2['num_incentives_sbert_YN']+df_all_2['num_incentives_bert_YN']==2),'Yes', 'No')\n",
    "# need another way to define the below types, as 0 not recognised as integer but as NA\n",
    "df_all_2['sbert_only_incentive_doc'] = np.where((df_all_2['num_incentives_sbert_YN']>df_all_2['num_incentives_bert_YN']),'Yes', 'No')\n",
    "df_all_2['bert_only_incentive_doc'] = np.where((df_all_2['num_incentives_bert_YN']>df_all_2['num_incentives_sbert_YN']),'Yes', 'No')\n",
    "\n",
    "#df_all_2.bert_only_incentive_doc.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8af3c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of different incentives\n",
    "\n",
    "df_all_2[\"num_unique_incentives_sbert\"]=df_all_2[\"supplies_sbert_YN\"]+df_all_2[\"loan_sbert_YN\"]+df_all_2[\"fine_sbert_YN\"]+df_all_2[\"direct_payment_sbert_YN\"]+df_all_2[\"technical_assistance_sbert_YN\"]+df_all_2[\"tax_benefit_sbert_YN\"]\n",
    "df_all_2[\"num_unique_incentives_bert\"]=df_all_2[\"supplies_bert_YN\"]+df_all_2[\"loan_bert_YN\"]+df_all_2[\"fine_bert_YN\"]+df_all_2[\"direct_payment_bert_YN\"]+df_all_2[\"technical_assistance_bert_YN\"]+df_all_2[\"tax_benefit_bert_YN\"]\n",
    "df_all_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2752d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next - visualisations\n",
    "# correlation matrix - incentives count\n",
    "# correlation matrix - juris areas count\n",
    "#time-series - incentive docs by year, incentive institution areas by year (docs with incentive only)\n",
    "# proportion of useful docs\n",
    "# sbert and bert comparison\n",
    "# etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4212e452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
