{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1558cb5",
   "metadata": {},
   "source": [
    "# Database building\n",
    "\n",
    "To gather the information spread among different files in the S3 Bucket and merge it with the metadat database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a10766e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6948d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access to S3 bucket\n",
    "\n",
    "# path = 'C:/Users/jordi/Documents/claus/'\n",
    "path = '/home/propietari/Documents/claus/'\n",
    "# path = 'C:/Users/hrpeg/Documents/claus/'\n",
    "filename = 'AWS_S3_keys_wri.json'\n",
    "file = path + filename\n",
    "with open(file, 'r') as dict:\n",
    "    credentials = json.load(dict)\n",
    "                                      \n",
    "KEY = list(credentials)[0]\n",
    "SECRET = list(credentials.values())[0]\n",
    "# s3BucketName = \"wri-testing\"\n",
    "s3BucketName = \"wri-nlp-policy\"\n",
    "# region = 'eu-central-1'\n",
    "region = \"us-east-1\"\n",
    "\n",
    "s3 = boto3.resource(\n",
    "    service_name = 's3',\n",
    "    region_name = region,\n",
    "    aws_access_key_id = KEY,\n",
    "    aws_secret_access_key = SECRET\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a4ede61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_sentences_json(s3, s3BucketName, dictionary):\n",
    "    for obj in s3.Bucket(s3BucketName).objects.all().filter(Prefix = in_prefix):#.:\n",
    "        if \".json\" in obj.key and \"ing\" not in obj.key:\n",
    "            name = obj.key.split(\"/\")[-1].split(\"_\")[0]\n",
    "            dictionary[name] = []\n",
    "            sentences = json.loads(obj.get()['Body'].read().decode('utf-8'))\n",
    "            for metadata, value in sentences[name][\"metadata\"].items():\n",
    "                if metadata != \"language\":\n",
    "                    dictionary[name].append(value)\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74b32739",
   "metadata": {},
   "outputs": [],
   "source": [
    "language = \"spanish\"\n",
    "model = \"\"\n",
    "in_prefix = f\"{language}_documents/HSSC/{model}updated_sentences/\"\n",
    "\n",
    "SBERT = {}\n",
    "SBERT = load_sentences_json(s3, s3BucketName, SBERT)\n",
    "\n",
    "\n",
    "language = \"spanish\"\n",
    "model = \"simple_transformers/\"\n",
    "in_prefix = f\"{language}_documents/HSSC/{model}updated_sentences/\"\n",
    "\n",
    "BERT = {}\n",
    "BERT = load_sentences_json(s3, s3BucketName, BERT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdc13cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/propietari/Documents/fitxers importants/WRI/Scraping_results/Final_DB_july_2021/\"\n",
    "# path = \"C:/Users/hrpeg/Documents/WRI/Scraping_results/Final_DB_july_2021/\"\n",
    "file_name = \"spanish_metadata.csv\"\n",
    "file = path + file_name\n",
    "\n",
    "metadata = {}\n",
    "with open(file, \"r\", encoding = \"Latin1\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        metadata[row [0]] = row\n",
    "\n",
    "count = 0 \n",
    "for key, value in metadata.items():\n",
    "    try:\n",
    "        metadata[key] = metadata[key] + SBERT[key] + BERT[key][4:]\n",
    "    except:\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d688ba79",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_metadata = list(metadata.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1150e993",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/propietari/Documents/fitxers importants/WRI/Scraping_results/Final_DB_july_2021/\"\n",
    "# path = \"C:/Users/hrpeg/Documents/WRI/Scraping_results/Final_DB_july_2021/\"\n",
    "file_name = \"spanish_metadata_210910.csv\"\n",
    "file = path + file_name\n",
    "with open(file, 'w',  encoding = \"Latin1\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(final_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08081cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#             incentive_counter = 0\n",
    "#             sentences_counter = 0\n",
    "#             min_sentence_length = 100000\n",
    "#             max_sentence_length = 0\n",
    "#             sum_sentence_length = 0\n",
    "#             last_sentence_position = 0\n",
    "#             incentives_dict = {'Supplies': 0,\n",
    "#                                'Loan': 0,\n",
    "#                                'Fine': 0,\n",
    "#                                'Direct payment': 0,\n",
    "#                                'Technical assistance': 0,\n",
    "#                                'Tax benefit': 0}\n",
    "#             for sentence_id in sentences[name][\"sentences\"]:\n",
    "#                 sentences_counter += 1\n",
    "#                 sentence = sentences[name][\"sentences\"][sentence_id][\"text\"]\n",
    "#                 min_sentence_length, max_sentence_length, sum_sentence_length = sentence_stats(sentence, min_sentence_length, max_sentence_length, sum_sentence_length)\n",
    "#                 incentive = sentences[name][\"sentences\"][sentence_id][\"label\"]  \n",
    "#                 if len(incentive) > 1 and incentive[0] == \"Incentive\":\n",
    "#                     incentive_counter += 1\n",
    "#                     sentence_number = sentence_id.split(\"_\")[2]\n",
    "#                     policy = sentences[name][\"sentences\"][sentence_id][\"label\"][1]\n",
    "#                     if last_sentence_position == 0:\n",
    "#                         results_list.append([])\n",
    "#                         last_sentence_position = sentence_number\n",
    "#                         sentences[name][\"sentences\"][sentence_id][\"closest_sentence\"] = 0\n",
    "#                         flag = True\n",
    "#                     else:\n",
    "#                         sentences[name][\"sentences\"][sentence_id][\"closest_sentence\"] = int(sentence_number) - int(last_sentence_position)\n",
    "#                         last_sentence_position = sentence_number\n",
    "\n",
    "#                     relative_position = int(sentence_number) / sentences[name][\"metadata\"][\"n_sentences\"]\n",
    "#                     sentences[name][\"sentences\"][sentence_id][\"relative_position\"] = round(relative_position, 2)\n",
    "#                     incentives_dict[policy] += 1\n",
    "#     #                 print(incentive, \"\\n\", sentence_id, \" ** \", last_sentence_position)\n",
    "\n",
    "#             # Updating the dictionary\n",
    "#             sentences[name][\"metadata\"][\"min_sent_length\"] = min_sentence_length\n",
    "#             sentences[name][\"metadata\"][\"max_sent_length\"] = max_sentence_length\n",
    "#             sentences[name][\"metadata\"][\"avg_sent_length\"] = int(sum_sentence_length/sentences_counter)\n",
    "#             sentences[name][\"metadata\"][\"number_of_incentives\"] = incentive_counter\n",
    "#             for key, value in incentives_dict.items():\n",
    "#                 sentences[name][\"metadata\"][key] = value\n",
    "#             s3.Object(s3BucketName, f\"{out_prefix}{name}_sents.json\").put(Body = (json.dumps(sentences, indent = 4)))\n",
    "#             # Creating the results list\n",
    "#             if flag:\n",
    "#                 documents_with_incentives += 1\n",
    "#                 results_list[documents_with_incentives].append(name)\n",
    "#                 results_list[documents_with_incentives].append(incentive_counter)\n",
    "#                 for key, value in incentives_dict.items():\n",
    "#                     results_list[documents_with_incentives].append(value)\n",
    "\n",
    "# with open(f\"../output/incentives_simple_transformers_{language}.csv\", \"w\") as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     writer.writerows(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57519894",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
