{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b268915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "from io import BytesIO;\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "c996844f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/propietari/Documents/fitxers importants/WRI/Scraping_results/\"\n",
    "\n",
    "onlyfiles = [f for f in listdir(path) if isfile(join(path, f))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f784158e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ElSalvador_20210730.csv',\n",
       " 'USFR_2_20210311.csv',\n",
       " 'USFR_20210311.csv',\n",
       " 'USFR_1_20210311.csv',\n",
       " 'USFR_20210702.csv',\n",
       " 'LeyChile_20210702.csv',\n",
       " 'Mexico_20210808.csv',\n",
       " 'India_20210310.csv',\n",
       " 'Mexico_20210703.csv',\n",
       " 'USFR_20210310.csv',\n",
       " 'India_20210703.csv',\n",
       " 'El_Salvador_no_duplicates.csv']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onlyfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e2153b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'C:/Users/jordi/Documents/claus/'\n",
    "key_path = '/home/propietari/Documents/claus/'\n",
    "filename = 'AWS_S3_keys_wri.json'\n",
    "file = key_path + filename\n",
    "with open(file, 'r') as dict:\n",
    "    credentials = json.load(dict)\n",
    "                                      \n",
    "KEY = list(credentials)[0]\n",
    "SECRET = list(credentials.values())[0]\n",
    "# s3BucketName = \"wri-testing\"\n",
    "s3BucketName = \"wri-nlp-policy\"\n",
    "# region = 'eu-central-1'\n",
    "region = \"us-east-1\"\n",
    "\n",
    "s3 = boto3.resource(\n",
    "    service_name = 's3',\n",
    "    region_name = region,\n",
    "    aws_access_key_id = KEY,\n",
    "    aws_secret_access_key = SECRET\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efa699f",
   "metadata": {},
   "source": [
    "### El Salvador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "71deb72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the csv files from scraping to be compared\n",
    "file_position = 0\n",
    "with open(path + onlyfiles[file_position], 'r', encoding = \"Latin1\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    ElSalvador_20210730 = [row[3] for row in reader]\n",
    "\n",
    "file_position = 10\n",
    "with open(path + onlyfiles[file_position], 'r', encoding = \"Latin1\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    El_Salvador_no_duplicates = [row[7] for row in reader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "36b28791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 460 items in the old file and 271 in the new one\n",
      "There are 0 duplicates in the new version\n",
      "The difference between the first scraping and the last version is of 189 entries\n",
      "There are 236 files in the old version that are not in the new version\n",
      "There are 47 files in the new version that are not in the old version\n",
      "There are 507 unique ids in the union of the files\n"
     ]
    }
   ],
   "source": [
    "ElSalvador_20210730_SET = set(ElSalvador_20210730)\n",
    "print(f\"There are {len(El_Salvador_no_duplicates)} items in the old file and {len(ElSalvador_20210730)} in the new one\")\n",
    "print(f\"There are {len(ElSalvador_20210730) - len(ElSalvador_20210730_SET)} duplicates in the new version\")\n",
    "print(f\"The difference between the first scraping and the last version is of {len(El_Salvador_no_duplicates) - len(ElSalvador_20210730)} entries\")\n",
    "not_in_newest_version = set(El_Salvador_no_duplicates) - ElSalvador_20210730_SET\n",
    "print(f\"There are {len(not_in_newest_version)} files in the old version that are not in the new version\")\n",
    "not_in_oldest_version =  ElSalvador_20210730_SET - set(El_Salvador_no_duplicates)\n",
    "print(f\"There are {len(not_in_oldest_version)} files in the new version that are not in the old version\")\n",
    "print(f\"There are {len(set(El_Salvador_no_duplicates) | ElSalvador_20210730_SET)} unique ids in the union of the files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "48947078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going to merge the two files in one. The fields were not saved in the sae order so it is necessary to rearrange them\n",
    "\n",
    "file_position = 0\n",
    "with open(path + onlyfiles[file_position], 'r', encoding = \"Latin1\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    ElSalvador_20210730 = list(reader)\n",
    "\n",
    "file_position = 10\n",
    "with open(path + onlyfiles[file_position], 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    El_Salvador_no_duplicates = list(reader)\n",
    "    \n",
    "final_list = []\n",
    "ids = {}\n",
    "for item in El_Salvador_no_duplicates:\n",
    "    if item[7] not in ids:\n",
    "        final_item = []\n",
    "        final_item.append(item[7])\n",
    "        final_item.append('El Salvador')\n",
    "        final_item.append('Diario Oficial')\n",
    "        final_item.append(item[1])\n",
    "        final_item.append(item[4])\n",
    "        final_item.append(item[2])\n",
    "        final_item.append(item[6])\n",
    "        final_item.append(item[5])\n",
    "        final_item.append(item[3])\n",
    "        final_list.append(final_item)\n",
    "        ids[item[7]] = 0\n",
    "    \n",
    "for item in ElSalvador_20210730:\n",
    "    if item[3] not in ids:\n",
    "        final_item = []\n",
    "        final_item.append(item[3])\n",
    "        final_item.append(item[1])\n",
    "        final_item.append(item[2])\n",
    "        final_item.append(item[0])\n",
    "        final_item.append(item[7])\n",
    "        final_item.append(item[6])\n",
    "        final_item.append(item[10])\n",
    "        final_item.append(item[9])\n",
    "        final_item.append(item[4])\n",
    "        final_list.append(final_item)\n",
    "        ids[item[3]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3be1a950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the differences with bucket files\n",
    "\n",
    "language = \"spanish\"\n",
    "in_prefix = f\"{language}_documents/HSSC/sentences/\"\n",
    "ids_S3 = {}\n",
    "for i, obj in enumerate(s3.Bucket(s3BucketName).objects.all().filter(Prefix = in_prefix)):\n",
    "    if \".json\" in obj.key and \"ing\" not in obj.key:\n",
    "        name = obj.key.split(\"/\")[-1].split(\"_\")[0]\n",
    "        ids_S3[name] = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7e3f19c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of scraped items that are not in sentences is 236\n"
     ]
    }
   ],
   "source": [
    "print(f\"The number of scraped items that are not in sentences is {len(ids.keys() - ids_S3.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0e185a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236\n"
     ]
    }
   ],
   "source": [
    "# Here we go and fetch the missing files and put them in the raw_pdf_updated folder\n",
    "prefix = f\"{language}_documents/raw_pdf_updated/\"\n",
    "\n",
    "\n",
    "counter = 0\n",
    "bucket = s3.Bucket(s3BucketName)\n",
    "for item in final_list:\n",
    "    if item[0] not in ids_S3:\n",
    "        counter += 1\n",
    "        key = prefix + item[0] + \".pdf\"\n",
    "        with requests.get(item[8], stream=True) as r:\n",
    "            bucket.upload_fileobj(r.raw, key)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e294c2b",
   "metadata": {},
   "source": [
    "### India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "647ba21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the csv files from scraping to be compared\n",
    "file_position = 6\n",
    "with open(path + onlyfiles[file_position], 'r', encoding = \"Latin1\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    india_old = [row[3] for row in reader]\n",
    "\n",
    "file_position = 9\n",
    "with open(path + onlyfiles[file_position], 'r', encoding = \"Latin1\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    india_new = [row[7] for row in reader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "eaf58abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_position = 6\n",
    "with open(path + onlyfiles[file_position], 'r', encoding=\"ISO-8859-1\") as f:#, encoding = \"Latin1\"\n",
    "    reader = csv.reader(f)\n",
    "    india_old = list(reader)\n",
    "\n",
    "file_position = 9\n",
    "with open(path + onlyfiles[file_position], 'r', encoding=\"ISO-8859-1\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    india_new = list(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ce2d0575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/ Department of AGRICULTURE AND MARKETING',\n",
       " 'India',\n",
       " 'India Code',\n",
       " '859644d69fdd0b1e66f1dcf5a42f2d9a3f31fe90.pdf',\n",
       " 'https://www.indiacode.nic.in/bitstream/123456789/6515/1/kishan_ayog_2016_hindi_.pdf#search=Miner OR Ore OR Pit OR Bog OR Buffer OR Corridor OR (Country planning) OR Cropland OR (Degraded land) OR Desert OR Floodplain OR Forestland OR Freshwater OR Grassland OR (Land use) OR Landowner OR Mangrove OR Marsh OR Meadow [1950 TO 2021]',\n",
       " 'Act',\n",
       " ' 2016-11-30',\n",
       " ' 201629',\n",
       " ' Uttarakhand',\n",
       " '',\n",
       " 'The Uttarakhand state farmer comission Act',\n",
       " 'https://www.indiacode.nic.in/handle/123456789/2109?view_type=search&sam_handle=123456789/1362']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "india_old[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "babc2585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'India',\n",
       " 'India Code',\n",
       " 'b6fcd452c47d5cff2bf2a492787ed56271db2e83.pdf',\n",
       " 'https://upload.indiacode.nic.in/showfile?actid=AC_CEN_16_18_00012_201638_1517807328204&type=rule&filename=caf%28ap%29_rules_2018.pdf',\n",
       " 'Rule',\n",
       " '20-11-2018',\n",
       " '',\n",
       " 'Federal',\n",
       " '',\n",
       " 'Compensatory Afforestation Fund Act 2016 Rules',\n",
       " 'https://www.indiacode.nic.in/handle/123456789/15740?view_type=search&sam_handle=123456789/2517']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "india_new[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1db7d8",
   "metadata": {},
   "source": [
    "### Chile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c96a408f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_position = 5\n",
    "with open(path + onlyfiles[file_position], 'r', encoding=\"ISO-8859-1\") as f:#, encoding = \"Latin1\"\n",
    "    reader = csv.reader(f)\n",
    "    chile = list(reader)\n",
    "    \n",
    "final_list = []\n",
    "ids = {}\n",
    "dates = {}\n",
    "for item in chile:\n",
    "    if item[3].split(\".\")[0] not in ids:\n",
    "        final_item = []\n",
    "        final_item.append(item[3].split(\".\")[0])\n",
    "        final_item.append(item[1])\n",
    "        final_item.append(item[2])\n",
    "        final_item.append(item[0])\n",
    "        final_item.append(item[5])\n",
    "        final_item.append(item[6])\n",
    "        dates[item[6]] = 0\n",
    "        final_item.append(item[10])\n",
    "        final_item.append(item[9])\n",
    "        final_item.append(item[4])\n",
    "        final_list.append(final_item)\n",
    "        ids[item[3].split(\".\")[0]] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2d0a2969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original file has 3248 data points. Without duplicates there are:860\n",
      "The earliest date is 2011-01-04 and the nearest date is 2021-07-01\n"
     ]
    }
   ],
   "source": [
    "print(f\"The original file has {len(chile)} data points. Without duplicates there are:{len(ids)}\")\n",
    "print(f\"The earliest date is {min(dates.keys())} and the nearest date is {max(dates.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d3857ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the differences with bucket files\n",
    "\n",
    "language = \"spanish\"\n",
    "in_prefix = f\"{language}_documents/HSSC/sentences/\"\n",
    "ids_S3 = {}\n",
    "for i, obj in enumerate(s3.Bucket(s3BucketName).objects.all().filter(Prefix = in_prefix)):\n",
    "    if \".json\" in obj.key and \"ing\" not in obj.key:\n",
    "        name = obj.key.split(\"/\")[-1].split(\"_\")[0]\n",
    "        ids_S3[name] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "335a3ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of scraped items that are not in sentences is 4\n"
     ]
    }
   ],
   "source": [
    "print(f\"The number of scraped items that are not in sentences is {len(ids.keys() - ids_S3.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d3b63526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# Here we go and fetch the missing files and put them in the raw_pdf_updated folder\n",
    "prefix = f\"{language}_documents/text_files/HSSC/new/\"\n",
    "\n",
    "counter = 0\n",
    "for item in final_list:\n",
    "    if item[0] not in ids_S3:\n",
    "        counter += 1\n",
    "        key = prefix + item[0] + \".txt\"\n",
    "        with requests.get(item[8], stream=True) as r:\n",
    "            s3.Object(s3BucketName, key).put(Body=r.content)\n",
    "\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cee8164",
   "metadata": {},
   "source": [
    "### Mexico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "bfe6507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_position = 6\n",
    "with open(path + onlyfiles[file_position], 'r', encoding = \"Latin1\") as f:#, encoding=\"ISO-8859-1\"\n",
    "    reader = csv.reader(f)\n",
    "    mexico = list(reader)\n",
    "    \n",
    "final_list = []\n",
    "ids = {}\n",
    "dates = {}\n",
    "for item in mexico:\n",
    "    if item[3].split(\".\")[0] not in ids:\n",
    "        final_item = []\n",
    "        final_item.append(item[3].split(\".\")[0])\n",
    "        final_item.append(item[1])\n",
    "        final_item.append(item[2])\n",
    "        final_item.append(item[0])\n",
    "        final_item.append(item[5])\n",
    "        final_item.append(item[6])\n",
    "        dates[item[6]] = 0\n",
    "        final_item.append(item[10])\n",
    "        final_item.append(item[9])\n",
    "        final_item.append(item[4])\n",
    "        final_list.append(final_item)\n",
    "        ids[item[3].split(\".\")[0]] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "77c68553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original file has 5096 data points. Without duplicates there are:5096\n",
      "The earliest date is 01-02-2011 and the nearest date is 31-12-2020\n"
     ]
    }
   ],
   "source": [
    "print(f\"The original file has {len(mexico)} data points. Without duplicates there are:{len(ids)}\")\n",
    "print(f\"The earliest date is {min(dates.keys())} and the nearest date is {max(dates.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a91b6d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['714697e02cb0b3f16cff58a1207334d942793cf2',\n",
       " 'Mexico',\n",
       " 'Diario Oficial de la Federacion',\n",
       " 'PODER EJECUTIVO/SECRETARIA DE AGRICULTURA, GANADERIA, DESARROLLO RURAL, PESCA Y ALIMENTACION',\n",
       " '',\n",
       " '04-01-2011',\n",
       " 'Aviso por el que se da a conocer información relativa a solicitudes de títulos de obtentor de variedades vegetales, correspondiente al mes de noviembre de 2010',\n",
       " '',\n",
       " 'https://www.dof.gob.mx/nota_detalle.php?codigo=5173707&fecha=26/01/2011&print=true']"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "649611ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MINISTERIO DEL MEDIO AMBIENTE; SERVICIO DE EVALUACIÓN AMBIENTAL; REGIÓN DE ÑUBLE',\n",
       " 'Chile',\n",
       " 'LeyChile',\n",
       " 'c3df19a5008129ee6de996e8027cb0eacff09b4b.txt',\n",
       " 'https://nuevo.leychile.cl/servicios/Consulta/Exportar?radioExportar=Normas&exportar_formato=txt&nombrearchivo=CHL/policy_1162116&exportar_con_notas_bcn=False&exportar_con_notas_originales=False&exportar_con_notas_al_pie=False&hddResultadoExportar=1162116.2021-07-01.0.0%23',\n",
       " 'Resolución 96 EXENTA',\n",
       " '2021-07-01',\n",
       " 'Resolución',\n",
       " 'Federal',\n",
       " 'Resolución',\n",
       " 'NOTIFICA RESOLUCIÓN DE INICIO DE PROCESO DE PARTICIPACIÓN CIUDADANA EN DECLARACIÓN DE IMPACTO AMBIENTAL PROYECTO: \"PLANTA FOTOVOLTAICA AGROVISIÓN\"',\n",
       " 'https://www.bcn.cl/leychile/navegar?idNorma=1162116']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chile[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "750b54d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/propietari/Documents/fitxers importants/WRI/Scraping_results/March2021/\"\n",
    "\n",
    "onlyfiles = [f for f in listdir(path) if isfile(join(path, f))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "coordinate-meeting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Scraped_Documents_Chile.csv',\n",
       " 'Oregon_20210218.csv',\n",
       " 'El_Salvador_no_duplicates.tsv',\n",
       " 'USFR_2_20210311.csv',\n",
       " 'Scraped_Documents_ElSalvador.csv',\n",
       " 'Mexico_20210423.csv',\n",
       " 'Scraped_Documents_ElSalvador_all_filename.csv',\n",
       " 'USFR_20210311.csv',\n",
       " 'Scraped_Documents_ElSalvador_filename.csv',\n",
       " 'USFR_1_20210311.csv',\n",
       " 'LeyChile_20210215.csv',\n",
       " 'India_20210310.csv',\n",
       " 'ElSalvador_20210215.csv',\n",
       " 'USFR_20210310.csv',\n",
       " 'Scraped_Documents_ElSalvador_agricola_energia.csv',\n",
       " 'El_Salvador_no_duplicates.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onlyfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "interior-fisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = path + \"Scraped_Documents_Chile.csv\"\n",
    "with open(file, 'r', encoding = \"Latin1\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    Chile = [row[13] for row in reader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "amino-instrument",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1150377'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Chile[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "binding-valuation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4850 entries and 4850 entries\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {len(Chile)} entries and {len(set(Chile))} entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-shark",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
