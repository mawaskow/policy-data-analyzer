{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting text from PDFs\n",
    "extract_text > make_pdfs.py\n",
    "input: onedrive_docs.zip\n",
    "output: pdf_files.json\n",
    "\n",
    "Extract into sentences\n",
    "text_preprocessing > sentence_split_local.py\n",
    "output/new> 61 json files of sentences\n",
    "label?\n",
    "\n",
    "data_augmentation > assisted_labeling.ipynb\n",
    "output/new > Embeddings and pre-tagged sentences\n",
    "now... get labels from the queries?\n",
    "whyyy are they broken into country as well? why not just topic??\n",
    "> it's because they wanted to account for dialect differences\n",
    "where are latent embeddings classifier and nli topic classifier getting used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting labelled sentences from pdfs\n",
    "extract_text > pdf_annots.py\n",
    "input: onedrive_docs.zip\n",
    "output: pdf_extract.json\n",
    "\n",
    "cleaning the raw labels from the pdfs\n",
    "text_preprocessing > cleaning_annots.py\n",
    "input: pdf_extract.json\n",
    "output: fixed_labels.json\n",
    "removing the empty labels and dictionary entriess\n",
    "input: fixed_labels.json\n",
    "output: fixed_empty.json\n",
    "\n",
    "cleaning the sentences from the highlights\n",
    "text_preprocessing > cleaning_hlts.py\n",
    "input: fixed_labels.json\n",
    "output: fixed_hlts.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
